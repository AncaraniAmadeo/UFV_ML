{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5nLhAya1JvpA"
   },
   "source": [
    "# Ensambles - Bagging\n",
    "\n",
    "A lo largo del notebook vamos a trabajar con el siguiente dataset:\n",
    "\n",
    "https://www.kaggle.com/jsphyg/weather-dataset-rattle-package\n",
    "\n",
    "El objetivo de este analisis será predecir si lloverá o no al día siguiente.\n",
    "\n",
    "## 1. EDA y Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0Hef9zJ4JvpD"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UmmNd16JvpO"
   },
   "source": [
    "1. Abrir el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "mCQgrC5OJvpT",
    "outputId": "6f214ab6-e931-4770-d321-ed21d1636a6b"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"weatherAUS.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oweAXg_nJvpb"
   },
   "source": [
    "Contamos cuántos valores no-nulos hay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "JC3UJn1PJvpd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sunshine          74377\n",
       "Evaporation       81350\n",
       "Cloud3pm          85099\n",
       "Cloud9am          88536\n",
       "Pressure9am      128179\n",
       "Pressure3pm      128212\n",
       "WindDir9am       132180\n",
       "WindGustDir      132863\n",
       "WindGustSpeed    132923\n",
       "WindDir3pm       138415\n",
       "Humidity3pm      138583\n",
       "Temp3pm          139467\n",
       "WindSpeed3pm     139563\n",
       "Humidity9am      140419\n",
       "RainToday        140787\n",
       "Rainfall         140787\n",
       "WindSpeed9am     140845\n",
       "Temp9am          141289\n",
       "MinTemp          141556\n",
       "MaxTemp          141871\n",
       "Date             142193\n",
       "Location         142193\n",
       "RISK_MM          142193\n",
       "RainTomorrow     142193\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONJ845VYJvpk"
   },
   "source": [
    "2. Tirar las columnas que no nos interesan, entre ellas las que tienen pocos datos (menos de cien mil). Además, tirar 'Location' y 'Date', ya que no nos interesa el lugar ni fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RQh_qzUQJvpm"
   },
   "outputs": [],
   "source": [
    "columnas_descartables = [COMPLETAR]\n",
    "data = data.drop(columns=columnas_descartables)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-NK0lB1Jvpt"
   },
   "source": [
    "3. Tirar todas las filas que tengan valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xFtAJxwdJvpu"
   },
   "outputs": [],
   "source": [
    "data = data.COMPLETAR()\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCaiTdARJvp2"
   },
   "source": [
    "4. Para simplificar el preprocesamiento, también tirar todas las columnas que tengan valores categóricos. (en otro momento se puede aplicar `Encorders`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ac96jl7qJvp4"
   },
   "outputs": [],
   "source": [
    "columnas_descartables = [COMPLETAR]\n",
    "data = data.drop(columns=columnas_descartables)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJEIzdGpJvp9"
   },
   "source": [
    "5. Realizar un countplot para ver cuántos casos hay de lluvia y no-lluvia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kYe4U3KkJvp-"
   },
   "outputs": [],
   "source": [
    "sns.COMPLETAR(data.COMPLETAR)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uE5WNUyDJvqE"
   },
   "source": [
    "Y hacer el `pairplot` para ver cómo se relacionan las variables. Recuerden que este gráfico puede llevar bastante tiempo. También recuerden que pueden agrandar el gráfico haciendo doble click en él."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VCg_9qpqJvqG"
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data.sample(frac = 0.1), hue = 'RainTomorrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUwv2uCOJvqN"
   },
   "source": [
    "Hay algunas que parecen *correlacionadas*. Tratamos de cuantificarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQfAuhVIJvqO"
   },
   "outputs": [],
   "source": [
    "corr = data.drop(columns = ['RainTomorrow']).corr(method='spearman') # .corr is used for find corelation\n",
    "plt.figure(figsize=(14,14))\n",
    "sns.heatmap(corr, cbar = True,  square = True, annot=True, fmt= '.2f',annot_kws={'size': 15},\n",
    "           xticklabels= data.drop(columns = ['RainTomorrow']).columns,\n",
    "           yticklabels= data.drop(columns = ['RainTomorrow']).columns,\n",
    "           cmap= 'coolwarm')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "teNYT08HJvqU"
   },
   "source": [
    "En base a la correlación, podemos descartar (o no) algunas variables. **Para pensar**, ¿por qué haríamos (o no) esto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V4r03pC2JvqX"
   },
   "outputs": [],
   "source": [
    "data = data.drop(columns=[COMPLETAR, COMPLETAR])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5NkB6JNlJvqc"
   },
   "source": [
    "6. Llevar `RainTomorrow` a una variable númerica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bHiBV7ApJvqd"
   },
   "outputs": [],
   "source": [
    "data[[COMPLETAR, COMPLETAR]] = pd.get_dummies(data[COMPLETAR])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6_iSwBXBJvqk"
   },
   "source": [
    "### Datos de entrenamiento y casos *benchmark*\n",
    "\n",
    "Generamos casos base contra los cuales comparar nuestros resultados.\n",
    "\n",
    "1. Elegir variables de entrenamiento (empezar con dos) y separar las etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4YyqzqV-Jvqk"
   },
   "outputs": [],
   "source": [
    "columnas_entrenamiento = [COMPLETAR]\n",
    "X = data[columnas_entrenamiento]\n",
    "y = data.COMPLETAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8731_NvkJvqp"
   },
   "source": [
    "2. Generar un modelo que diga siempre que NO va a llover y medir su exactitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0_-jbcCdJvqq"
   },
   "outputs": [],
   "source": [
    "#Todos Ceros\n",
    "y_pred = np.COMPLETAR(y.shape)\n",
    "accuracy_ceros = metrics.COMPLETAR(y,y_pred)\n",
    "print(accuracy_ceros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySMoGKeZJvqv"
   },
   "source": [
    "Y generar otro modelo que diga siempre que va a llover y medir su exactitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zGWQ7nglJvqw"
   },
   "outputs": [],
   "source": [
    "#Todos Unos\n",
    "y_pred = COMPLETAR\n",
    "accuracy_unos = COMPLETAR\n",
    "print(accuracy_unos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wvd3b7d4Jvq0"
   },
   "source": [
    "**3. - Challenge:**  Entrena un árbol de decisión sobre este dataset. Intenta obtener el mejor desempeño que creas posible, optimizando sus hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q8gWqes4Jvq1"
   },
   "outputs": [],
   "source": [
    "# COMPLETAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mc_mkQLyJvrC"
   },
   "source": [
    "## 2. Bagging\n",
    "\n",
    "Separamos entre train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CUISoV0dJvrD"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDdZ0iLBJvrI"
   },
   "source": [
    "Recuerden que el objetivo de bagging es entrenar distintos modelos, donde cada uno vea distintas porciones del set de entrenamiento. Entonces, vamos a entrenar distintos árboles de decisión y mostrarles distintas porciones del set de datos. Lo vamos a hacer en un `for`.\n",
    "\n",
    "1. Crear una lista vacía donde guardaremos los modelos entrenados y elegir cuántos modelos entrenar (Empezar por algún valor entre 5 y 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ztTJTETJvrJ"
   },
   "outputs": [],
   "source": [
    "lista_de_modelos = COMPLETAR\n",
    "N_modelos = COMPLETAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gaJ8I7cdJvrN"
   },
   "source": [
    "2. Entrenar cada modelo y guardar cada modelo entrenado en una lista. Para hacer el split, usar la función `train_test_split`. ¿Sobre qué conjunto van a hacer el split?¿Hay que fijar el `random_state`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A_otcyfbJvrO"
   },
   "outputs": [],
   "source": [
    "for i in range(COMPLETAR):\n",
    "    X_train_boostrap, _, y_train_boostrap, _ = train_test_split(COMPLETAR, COMPLETAR, test_size=0.5, stratify = COMPLETAR)\n",
    "    clf = DecisionTreeClassifier(max_depth = None) #Notar que lo dejamos overfitear\n",
    "    clf.fit(COMPLETAR, COMPLETAR)\n",
    "    lista_de_modelos.append(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpsPf5kFJvrR"
   },
   "source": [
    "3. Evaluar el accuracy de cada modelo usando el conjunto de held_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MsgzTND2JvrS"
   },
   "outputs": [],
   "source": [
    "for idx, modelo in enumerate(COMPLETAR):\n",
    "    y_test_pred = modelo.predict(COMPLETAR)\n",
    "    print('Accuracy Modelo ', idx, ' es ', metrics.COMPLETAR(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KdgMthaaJvrW"
   },
   "source": [
    "Parecen estar un poco overfitteados, que era lo que esperábamos.\n",
    "\n",
    "4. Evaluar el accuracy de todo el ensamble usando el conjunto de held_out. Vamos a hacerlo usando un promedio de las probabilidades que devuelven cada árbol. Si la probabilidad promedio es mayor a 0.5, clasificamos como positivo. Para ello:\n",
    "    1. Inicializar un arreglo de probabilidades del tamaño de la cantidad de instancias del conjunto de test en ceros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XUEvoz7sJvrX"
   },
   "outputs": [],
   "source": [
    "probs_test_pred = np.COMPLETAR(COMPLETAR.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVesaBT4Jvrb"
   },
   "source": [
    "B. Recorrer la lista de modelos y predecir las probabilidades. Mirar como es el `shape` de ese arreglo predicho. Elegir las probabilidades que correspondan a la clase positiva. Luego, sumarlas al vector que definieron antes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jz7Za7DZJvre"
   },
   "outputs": [],
   "source": [
    "for modelo in lista_de_modelos:\n",
    "    probs_test_pred_modelo = modelo.COMPLETAR(X_test)\n",
    "    print(probs_test_pred_modelo.shape)\n",
    "    # Cuando esten seguros de lo que quieran sumar, descomentar la linea de abajo y completar\n",
    "#     probs_test_pred +=probs_test_pred_modelo[COMPLETAR,COMPLETAR]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qmv52DebJvri"
   },
   "source": [
    "C. Dividir `probs_test_pred` por la cantidad de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9xuoE2eSJvrj"
   },
   "outputs": [],
   "source": [
    "probs_test_pred = probs_test_pred/COMPLETAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMKCvgCNJvrn"
   },
   "source": [
    "D. Crear las clases predichas (0s y 1s) a partir de comparar la probabilidad predicha con la probabilidad umbral (0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "20crY7SYJvro"
   },
   "outputs": [],
   "source": [
    "y_test_pred = probs_test_pred>COMPLETAR\n",
    "y_test_pred = y_test_pred.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6A3BvrucJvrr"
   },
   "source": [
    "Y evaluar la exactitud de todo el ensamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mFh0l13tJvrs"
   },
   "outputs": [],
   "source": [
    "print('Accuracy Ensambe ', metrics.accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APxl2HcfJvrw"
   },
   "source": [
    "5. Explorar el `BaggingClassfier` de scikit-learn y algunas de sus características. Usarlo para predecir sobre el train y test, y medir su desempeño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C1dcDvhTJvrw"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CDFRfqvLJvr0"
   },
   "outputs": [],
   "source": [
    "clf = BaggingClassifier(base_estimator=COMPLETAR, bootstrap = COMPLETAR, bootstrap_features=COMPLETAR, n_estimators = 100, n_jobs = -1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "print(metrics.accuracy_score(y_train, y_train_pred))\n",
    "print(metrics.accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAuLOo02Jvr4"
   },
   "source": [
    "6. Si usaron dos features, pueden graficar las fronteras de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9mZXUi0zJvr4"
   },
   "outputs": [],
   "source": [
    "N = 20 #para no graficar todos los puntos y saturar el grafico\n",
    "\n",
    "plt.figure(figsize = (8,6))\n",
    "\n",
    "#Grafico Clasificador Sesgado\n",
    "ax = sns.scatterplot(X_test[::N].MaxTemp, X_test[::N].Humidity3pm, hue=y_test[::N], palette='Set2')\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "xx, yy = np.meshgrid(np.linspace(*xlim, num=200),\n",
    "                      np.linspace(*ylim, num=200))\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "contours = ax.contourf(xx, yy, Z, alpha=0.3, cmap = 'Set2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pQNvu9PlJvr7"
   },
   "source": [
    "## 3. Random Forest\n",
    "\n",
    "Random Forest, además de aplicar Bagging, también selecciona features al azar, de esa manera descorrelaciona aún más los distintos modelos de árbol creados.\n",
    "\n",
    "1. Importar de scikit-learn el modelo `RandomForestClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M9XxMxz1Jvr8"
   },
   "outputs": [],
   "source": [
    "from sklearn.COMPLETAR import COMPLETAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6k1unuvJvsA"
   },
   "source": [
    "2. Investigar sus parámetros. En particular, `n_estimators`, `max_features` y `oob_score`. Luego, crear y entrenar un modelo en el conjunto de train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pPKh6si1JvsB"
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=COMPLETAR, max_features=COMPLETAR, n_jobs=-1, oob_score = True, random_state = 42)\n",
    "clf.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMLLIS0FJvsF"
   },
   "source": [
    "3. Evaluar su desempeño en el conjunto de train y de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7nw18y6MJvsG"
   },
   "outputs": [],
   "source": [
    "y_train_pred = clf.COMPLETAR(COMPLETAR)\n",
    "y_test_pred = clf.COMPLETAR(COMPLETAR)\n",
    "print(metrics.COMPLETAR(COMPLETAR, COMPLETAR))\n",
    "print(metrics.COMPLETAR(COMPLETAR, COMPLETAR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-lM5LEmxJvsJ"
   },
   "source": [
    "4. ¿Cuál es su `oob_score_`?¿Y que son `feature_importances_`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-AbWPlIKJvsJ"
   },
   "outputs": [],
   "source": [
    "clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LGgD2Xs3JvsL"
   },
   "outputs": [],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "014iW4IYJvsO"
   },
   "outputs": [],
   "source": [
    "# CORRER ESTA CELDA UNA VEZ QUE HAYAN ESTUDIADO QUE ES OOB_SCORE Y FEATURE_IMPORTANCES\n",
    "\n",
    "importances = clf.feature_importances_\n",
    "columns = X_train.columns\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize = (15,8))\n",
    "sns.barplot(columns[indices], importances[indices])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HI6jT96DJvsR"
   },
   "source": [
    "5. ¿Qué hay en la propiedad `estimators_`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zY0zWZw6JvsR"
   },
   "outputs": [],
   "source": [
    "clf.estimators_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GGv026tLJvsU"
   },
   "source": [
    "6. Elegir uno de los `estimators` y evaluar su desempeño sobre train y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F_A-3QURJvsU"
   },
   "outputs": [],
   "source": [
    "clf_tree = clf.estimators_[COMPLETAR]\n",
    "clf_tree.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KPSJnBHwJvsW"
   },
   "outputs": [],
   "source": [
    "y_train_pred = clf_tree.predict(X_train)\n",
    "y_test_pred = clf_tree.predict(X_test)\n",
    "print(metrics.accuracy_score(y_train, y_train_pred))\n",
    "print(metrics.accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2kjJIp9WJvsZ"
   },
   "source": [
    "¿Está overfiteado?¿Por qué la accuracy sobre el conjunto de train no es 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tf49sPGhJvsZ"
   },
   "source": [
    "7. Hacer y graficar la curva de validación/complejidad para un modelo Random Forest en función del número de estimadores. No usamos CV porque puede llevar bastante tiempo. Si quieren, lo pueden probar después. Además, obtener su oob_score para graficar en la curva de complejidad (No se preocupen por los mensajes de warning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZSUel6JGJvsa"
   },
   "outputs": [],
   "source": [
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "oob_scores = []\n",
    "\n",
    "N_estimadores = [1,2,3,4,5,10,25,50,100,250,500,1000]\n",
    "for estimadores in COMPLETAR:\n",
    "    print(estimadores)\n",
    "    clf = RandomForestClassifier(n_estimators=COMPLETAR, n_jobs=-1, oob_score= True, random_state = 42)\n",
    "    clf.fit(COMPLETAR,COMPLETAR)\n",
    "\n",
    "    y_train_pred = clf.predict(COMPLETAR)\n",
    "    y_test_pred = clf.predict(COMPLETAR)\n",
    "\n",
    "    train_accuracy.append(COMPLETAR)\n",
    "    test_accuracy.append(COMPLETAR)\n",
    "    oob_scores.append(clf.COMPLETAR)\n",
    "\n",
    "train_accuracy = np.array(train_accuracy)\n",
    "test_accuracy = np.array(test_accuracy)\n",
    "oob_scores = np.array(oob_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R_3U1Pw6Jvsd"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,6))\n",
    "plt.plot(N_estimadores, COMPLETAR, label = 'Train')\n",
    "plt.plot(N_estimadores, COMPLETAR, label = 'Test')\n",
    "plt.plot(N_estimadores, COMPLETAR, label = 'OOB')\n",
    "plt.xlabel('Numero de estimadores')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "# plt.xlim(0,50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ozuvMLtJJvsg"
   },
   "source": [
    "8. Hacer y graficar la curva de aprendizaje para un modelo con 250 estimadores. Puede llevar bastante tiempo, no se preocupen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w6V7waywJvsh"
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=250, n_jobs=-1, oob_score= True, random_state = 42)\n",
    "\n",
    "train_sizes, train_scores, valid_scores = learning_curve(COMPLETAR, COMPLETAR, COMPLETAR,\n",
    "                                                         train_sizes = np.linspace(0.0001,1,10),\n",
    "                                                         scoring = 'accuracy', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Siv3xPKJvsk"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,6))\n",
    "plt.plot(COMPLETAR, COMPLETAR.mean(axis = COMPLETAR), color = 'r')\n",
    "plt.plot(COMPLETAR, COMPLETAR.mean(axis = COMPLETAR), color = 'g')\n",
    "\n",
    "plt.fill_between(COMPLETAR, COMPLETAR,\n",
    "                     COMPLETAR, alpha=0.25,\n",
    "                     color=\"r\")\n",
    "plt.fill_between(COMPLETAR, COMPLETAR,\n",
    "                     COMPLETAR, alpha=0.25, color=\"g\")\n",
    "\n",
    "plt.ylim(0.5,1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H_QYSwq4Jvsm"
   },
   "source": [
    "9. Si usaron dos features, pueden graficar las fronteras de decisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xunphIRtJvsn"
   },
   "outputs": [],
   "source": [
    "N = 20 #para no graficar todos los puntos y saturar el grafico\n",
    "clf = RandomForestClassifier(n_estimators=250).fit(X_train, y_train)\n",
    "\n",
    "#COMPLETAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-pDtsL9Jvso"
   },
   "source": [
    "**Ejercicio**: elegir más features y volver a entrenar.\n",
    "\n",
    "**Para pensar**: ¿qué otras métricas utilizarían para evaluar estos modelos, dadas las características particulares del problema? Comparar con los casos *benchmark* que hicieron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YVJQovAaleG"
   },
   "source": [
    "# Ensambles - Boosting\n",
    "\n",
    "A lo largo del notebook vamos a trabajar con el siguiente dataset, que es el que utilizamos en los encuentros anteriores:\n",
    "\n",
    "https://www.kaggle.com/jsphyg/weather-dataset-rattle-package\n",
    "\n",
    "Si ya te sientes seguro/a, puedes utilizar un clasificador AdaBoost de Scikit-Learn sobre este dataset sin seguir los pasos que te dejamos más abajo. También, puedes seguirlos, pero borrando las pistas que te dejamos. ¡Anímate a probar más cosas solo/a!\n",
    "\n",
    "### Carga de datos\n",
    "\n",
    "Volvemos a cargas las librerías, importar el dataset y limpiarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gKuOvc_2amHn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uM6by7Fha58v"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"weatherAUS.csv\")\n",
    "# Columnas con muchos NaNs\n",
    "columnas_descartables = ['Sunshine','Evaporation','Cloud3pm','Cloud9am','Location','Date']\n",
    "data = data.drop(columns=columnas_descartables)\n",
    "data = data.dropna()\n",
    "\n",
    "# Columnas con variables categoricas\n",
    "columnas_descartables = ['WindGustDir','WindDir9am','WindDir3pm','RainToday']\n",
    "data = data.drop(columns=columnas_descartables)\n",
    "\n",
    "# Variables correlacionadas\n",
    "data = data.drop(columns=['Temp3pm', 'Pressure9am'])\n",
    "\n",
    "# Mapeo\n",
    "data['RainTomorrow'] = data['RainTomorrow'].map({'Yes':1,'No':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NC6rUPOaa9A3"
   },
   "source": [
    "## 1. AdaBoost\n",
    "\n",
    "El objetivo de boosting es generar un modelo fuerte a partir de entrenar sucesivamente modelos débiles y combinar sus resultados. La idea es que cada modelo débil que agrego se enfoque en las instancias que fueron clasificadas erroneamente hasta el momento. Empecemos por decidir sobre que fetures del dataset vamos a trabajar (si trabajan sobre 2, luego podrán visualizar):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dx0nH45ta-gz"
   },
   "outputs": [],
   "source": [
    "# Elegimos sobre que coolumnas queremos trabajar\n",
    "columnas_entrenamiento = ['MaxTemp', 'Humidity3pm']\n",
    "X = COMPLETAR\n",
    "y = COMPLETAR\n",
    "\n",
    "# Separamos los datos en train y test (held-out) - Utilice un 30% del dataset como test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=COMPLETAR, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9n9NpiAbBRw"
   },
   "source": [
    "Recordemos que este tipo de ensamble se enfoca en mejorar el sesgo de los modelos individuales a partir de los cuales está construido, por lo cual se suele usar modelos de alto sesgo y baja varianza.\n",
    "\n",
    "1. Empiece por importar el clasificador AdaBoostClassifier y el modelo que usaremos como estimador debil, el DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1DLqfEuYbDZW"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UbXrH4sGbGdh"
   },
   "source": [
    "2. Defina el modelo de manera que utilice 250 árboles de profundidad dos (2). Luego probaremos que sucede para mayores profundidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cu9OVtpTbH0D"
   },
   "outputs": [],
   "source": [
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=COMPLETAR), algorithm='SAMME', n_estimators=250)\n",
    "# Entrenamos el modelo\n",
    "ada_clf.fit(COMPLETAR, COMPLETAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q9qMaWXZbKxl"
   },
   "source": [
    "3. Calcule el error sobre el training set y sobre el test set. En base a estos resultados, ¿les parece que este ensamble está inclinado hacia el sesgo o hacia la varianza?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nG6Nz_X-bLLs"
   },
   "outputs": [],
   "source": [
    "y_train_pred = COMPLETAR\n",
    "y_test_pred = COMPLETAR\n",
    "print('Accuracy sobre el test set: ',COMPLETAR)\n",
    "print('Accuracy sobre el train set: ',COMPLETAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zkPNEoeTbRMW"
   },
   "source": [
    "4. Veamos ahora cómo es la distribución de los pesos de cada árbol. Para esto vamos a graficar el número del árbol vs el peso que el algoritmo le está dando para la clasificación final. Además, graficaremos también el accuracy de cada arbol sobre el training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WJ2cw189bQjn"
   },
   "outputs": [],
   "source": [
    "# Puede que el algoritmo termine antes de agregar todos los arboles\n",
    "# Tomamos entonces la cantidad de arboles que realmente tiene el ensamble\n",
    "numero_arboles = len(ada_clf)\n",
    "\n",
    "# En la variable estimator_weights_ esta el peso de cada arbol\n",
    "pesos = ada_clf.estimator_weights_[:numero_arboles]\n",
    "\n",
    "# Calculamos el accuracy DE CADA ARBOL en el ensamble. En estimator_errors_ esta el error que comete cada uno.\n",
    "errores_arboles = ada_clf.estimator_errors_[:numero_arboles]\n",
    "# Como puede calcular el accuracy de cada arbol a partir de saber el error que comete cada uno?\n",
    "accuracy_arboles = COMPLETAR\n",
    "\n",
    "# Graficamos\n",
    "plt.figure(figsize = (12,6))\n",
    "plt.subplot(121)\n",
    "# En el eje 'x' ponemos el índice (número) de cada arbol, en el 'y' los pesos\n",
    "plt.plot(range(1, numero_arboles + 1), COMPLETAR)\n",
    "plt.ylabel('Peso')\n",
    "plt.xlabel('Número de árbol')\n",
    "plt.ylim((0, pesos.max() * 1.1))\n",
    "plt.xlim((-20, numero_arboles + 20))\n",
    "plt.subplot(122)\n",
    "# En el eje 'x' ponemos el índice (número) de cada arbol, en el 'y' el accuracy de cada arbol\n",
    "plt.plot(range(1, numero_arboles + 1), COMPLETAR)\n",
    "plt.ylabel('Accuracy en trainin set')\n",
    "plt.xlabel('Número de árbol')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ba0Y_i_3btdI"
   },
   "source": [
    "5. ¿Le parece relevante la contribución de todos los árboles?¿Cómo se relaciona el accuracy de cada árbol con el peso que le damos en la clasificación final?\n",
    "\n",
    "6. Veamos cómo cambia el error en el training set y en el test set a medida que agregamos árboles. Para esto vamos a utilizar un metodo llamado `staged_predict`, que nos devuelve la predicción del ensamble en cada instancia en que fuimos agregandole un nuevo estimador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uITn-ezIbv5o"
   },
   "outputs": [],
   "source": [
    "# Definimos listas vacias donde vamos a \"appendear\" (agregar) los valores\n",
    "accuracy_test = COMPLETAR\n",
    "accuracy_train = COMPLETAR\n",
    "\n",
    "# Calculamos el accuracy sobre el test set\n",
    "for prediccion_test in ada_clf.staged_predict(X_test):\n",
    "    accuracy_test.append(metrics.accuracy_score(prediccion_test,COMPLETAR))\n",
    "\n",
    "# Calculamos el accuracy sobre el training set\n",
    "for prediccion_train in ada_clf.staged_predict(X_train):\n",
    "    accuracy_train.append(metrics.accuracy_score(prediccion_train,COMPLETAR))\n",
    "\n",
    "plt.plot(range(1, len(accuracy_test) + 1), accuracy_test, label = 'Test')\n",
    "plt.plot(range(1, len(accuracy_test) + 1), accuracy_train, label = 'Train')\n",
    "plt.legend()\n",
    "plt.ylabel('Accuracy en el test set')\n",
    "plt.xlabel('Número de árboles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nmOmNx5xbx5I"
   },
   "source": [
    "7. Grafiquemos la frontera de decisión del clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iXJuCR_ebyME"
   },
   "outputs": [],
   "source": [
    "N = 20 #para no graficar todos los puntos y saturar el grafico\n",
    "\n",
    "plt.figure(figsize = (8,6))\n",
    "\n",
    "ax = sns.scatterplot(X_test[::N].MaxTemp, X_test[::N].Humidity3pm, hue=y_test[::N], palette='Set2')\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "xx, yy = np.meshgrid(np.linspace(*xlim, num=200),\n",
    "                      np.linspace(*ylim, num=200))\n",
    "Z = ada_clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "contours = ax.contourf(xx, yy, Z, alpha=0.3, cmap = 'Set2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSLapcv0b6EE"
   },
   "source": [
    "8. Repita lo realizado hasta ahora pero utilice árboles de profundidad diez. Preste atención a las curvas de accuracy en train y test y al gráfico de la frontera. ¿Qué le parece que esta sucediendo en este caso?\n",
    "\n",
    "### 2. XGBoost\n",
    "\n",
    "Instalar y entrenar un modelo con `XGBoost` sobre este dataset. Explorar diferencias y similitudes con `Adaboost`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KPqTSWsqb6aR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "6_iSwBXBJvqk",
    "Mc_mkQLyJvrC",
    "pQNvu9PlJvr7"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "seguros_env2",
   "language": "python",
   "name": "seguros_env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
