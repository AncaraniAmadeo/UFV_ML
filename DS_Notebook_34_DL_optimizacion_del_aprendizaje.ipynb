{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimización del aprendizaje\n",
    "\n",
    "### Resumen\n",
    "En este notebook vamos a ver las posibles optimizaciones que podemos hacer para que los modelos aprendan más rápido y sean más robustos.\n",
    "Vamos a ver:\n",
    "- CallBacks\n",
    "- L2 regularización\n",
    "- Dropout\n",
    "- Data Augmentation\n",
    "- Batch Normalization\n",
    "\n",
    "Utilizaremos el dataset CIFAR 10 para comparar todas las pruebas y ver su eficacia\n",
    "\n",
    "Importamos los paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import layers, Input, regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy, MSE, MAE\n",
    "import tensorflow as tf\n",
    "from aux_func import show_history, r2_keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from time import time\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Big model = overfiting\n",
    "Veamos que fácil es hacer overfiting con una red neuronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de elementos en el dataset =  60000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "(X_train_cifar10, y_train_cifar10), (X_validation_cifar10, y_validation_cifar10) = cifar10.load_data()\n",
    "X_train_cifar10 = X_train_cifar10/255\n",
    "X_validation_cifar10 = X_validation_cifar10/255\n",
    "\n",
    "labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "print('Número de elementos en el dataset = ',X_train_cifar10.shape[0]+X_validation_cifar10.shape[0])\n",
    "plt.title(labels[int(y_train_cifar10[62])])\n",
    "plt.imshow(X_train_cifar10[62])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 32, 32, 25)        700       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 16, 16, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 16, 16, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 8, 8, 100)         45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 2000)              3202000   \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1000)              2001000   \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 5,270,110\n",
      "Trainable params: 5,270,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd0cc2b37a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd0cc2b37a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 989/1000 [============================>.] - ETA: 0s - loss: 1.3587 - accuracy: 0.5048WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd0500629e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd0500629e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 1.3560 - accuracy: 0.5061 - val_loss: 1.1249 - val_accuracy: 0.6093\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.9164 - accuracy: 0.6786 - val_loss: 0.8915 - val_accuracy: 0.6848\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7313 - accuracy: 0.7418 - val_loss: 0.8040 - val_accuracy: 0.7156\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5871 - accuracy: 0.7945 - val_loss: 0.7694 - val_accuracy: 0.7432\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.4539 - accuracy: 0.8395 - val_loss: 0.8223 - val_accuracy: 0.7446\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3320 - accuracy: 0.8825 - val_loss: 0.9252 - val_accuracy: 0.7450\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.2359 - accuracy: 0.9159 - val_loss: 0.9844 - val_accuracy: 0.7393\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1825 - accuracy: 0.9362 - val_loss: 1.0673 - val_accuracy: 0.7467\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.1426 - accuracy: 0.9514 - val_loss: 1.2113 - val_accuracy: 0.7394\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.1184 - accuracy: 0.9600 - val_loss: 1.4177 - val_accuracy: 0.7288\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1032 - accuracy: 0.9655 - val_loss: 1.4283 - val_accuracy: 0.7362\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0976 - accuracy: 0.9671 - val_loss: 1.4590 - val_accuracy: 0.7401\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0881 - accuracy: 0.9705 - val_loss: 1.5269 - val_accuracy: 0.7300\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0889 - accuracy: 0.9701 - val_loss: 1.5922 - val_accuracy: 0.7423\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0784 - accuracy: 0.9751 - val_loss: 1.7346 - val_accuracy: 0.7405\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0744 - accuracy: 0.9758 - val_loss: 1.6722 - val_accuracy: 0.7338\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0743 - accuracy: 0.9761 - val_loss: 1.5947 - val_accuracy: 0.7445\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0655 - accuracy: 0.9783 - val_loss: 1.7453 - val_accuracy: 0.7358\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0681 - accuracy: 0.9781 - val_loss: 1.8770 - val_accuracy: 0.7170\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0644 - accuracy: 0.9791 - val_loss: 1.8112 - val_accuracy: 0.7309\n"
     ]
    }
   ],
   "source": [
    "# capas de la red\n",
    "input = Input(shape=(32,32,3))\n",
    "layer = input\n",
    "layer = Conv2D(filters=25, kernel_size=3, strides=1, padding='same', activation='relu')(layer)\n",
    "layer = MaxPooling2D((2, 2))(layer)\n",
    "layer = Conv2D(filters=50, kernel_size=3, strides=1, padding='same', activation='relu')(layer)\n",
    "layer = MaxPooling2D((2, 2))(layer)\n",
    "layer = Conv2D(filters=100, kernel_size=3, strides=1, padding='same', activation='relu')(layer)\n",
    "layer = MaxPooling2D((2, 2))(layer)\n",
    "layer = Flatten()(layer)\n",
    "layer = Dense(units=2000, activation='relu')(layer)\n",
    "layer = Dense(units=1000, activation='relu')(layer)\n",
    "output = Dense(units=10, activation='softmax')(layer)\n",
    "\n",
    "# creamos el modelo\n",
    "model = Model(inputs=input, outputs=output)\n",
    "print(model.summary())\n",
    "\n",
    "# optimizador\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# función loss\n",
    "loss = SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "# métrica\n",
    "metrics = ['accuracy']\n",
    "\n",
    "# compilamos el modelo\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "history = model.fit(x=X_train_cifar10, y=y_train_cifar10, batch_size=50, epochs=20,\n",
    "                    validation_data=(X_validation_cifar10, y_validation_cifar10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claramente a partir de la epoch 5 se está produciendo overfiting y el accuracy en validación está disminuyendo poco a poco.\n",
    "El score obtenido es 73%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small model\n",
    "Una de las opciones más sencillas es la reducción del tamaño del modelo para limitar su capacidad de aprendizaje.\n",
    "Con ello podemos reducir la aparición de overfiting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 32, 32, 20)        560       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 16, 16, 20)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 16, 16, 40)        7240      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling (None, 8, 8, 40)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 8, 8, 60)          21660     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling (None, 4, 4, 60)          0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 960)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 50)                48050     \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 78,020\n",
      "Trainable params: 78,020\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fcff8284680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fcff8284680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 983/1000 [============================>.] - ETA: 0s - loss: 1.5335 - accuracy: 0.4466WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fcff8138680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fcff8138680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.5279 - accuracy: 0.4487 - val_loss: 1.2256 - val_accuracy: 0.5549\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.1291 - accuracy: 0.5997 - val_loss: 1.0970 - val_accuracy: 0.6116\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9749 - accuracy: 0.6575 - val_loss: 0.9536 - val_accuracy: 0.6698\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8799 - accuracy: 0.6926 - val_loss: 0.9161 - val_accuracy: 0.6843\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8143 - accuracy: 0.7161 - val_loss: 0.8687 - val_accuracy: 0.6974\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7560 - accuracy: 0.7359 - val_loss: 0.8612 - val_accuracy: 0.7028\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7114 - accuracy: 0.7514 - val_loss: 0.8184 - val_accuracy: 0.7161\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6648 - accuracy: 0.7683 - val_loss: 0.7972 - val_accuracy: 0.7335\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6347 - accuracy: 0.7783 - val_loss: 0.8466 - val_accuracy: 0.7174\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6043 - accuracy: 0.7890 - val_loss: 0.8627 - val_accuracy: 0.7150\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5730 - accuracy: 0.7983 - val_loss: 0.8257 - val_accuracy: 0.7194\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5457 - accuracy: 0.8079 - val_loss: 0.8155 - val_accuracy: 0.7268\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5198 - accuracy: 0.8164 - val_loss: 0.8586 - val_accuracy: 0.7201\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4893 - accuracy: 0.8269 - val_loss: 0.8797 - val_accuracy: 0.7173\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4718 - accuracy: 0.8339 - val_loss: 0.9215 - val_accuracy: 0.7094\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4484 - accuracy: 0.8408 - val_loss: 0.8916 - val_accuracy: 0.7247\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4249 - accuracy: 0.8490 - val_loss: 0.9302 - val_accuracy: 0.7180\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4127 - accuracy: 0.8536 - val_loss: 0.9261 - val_accuracy: 0.7230\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3871 - accuracy: 0.8622 - val_loss: 0.9669 - val_accuracy: 0.7230\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3725 - accuracy: 0.8661 - val_loss: 0.9656 - val_accuracy: 0.7253\n"
     ]
    }
   ],
   "source": [
    "# capas de la red\n",
    "input = Input(shape=(32,32,3))\n",
    "layer = input\n",
    "layer = Conv2D(filters=20, kernel_size=3, strides=1, padding='same', activation='relu')(layer)\n",
    "layer = MaxPooling2D((2, 2))(layer)\n",
    "layer = Conv2D(filters=40, kernel_size=3, strides=1, padding='same', activation='relu')(layer)\n",
    "layer = MaxPooling2D((2, 2))(layer)\n",
    "layer = Conv2D(filters=60, kernel_size=3, strides=1, padding='same', activation='relu')(layer)\n",
    "layer = MaxPooling2D((2, 2))(layer)\n",
    "layer = Flatten()(layer)\n",
    "layer = Dense(units=50, activation='relu')(layer)\n",
    "output = Dense(units=10, activation='softmax')(layer)\n",
    "\n",
    "# creamos el modelo\n",
    "model = Model(inputs=input, outputs=output)\n",
    "print(model.summary())\n",
    "\n",
    "# optimizador\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# función loss\n",
    "loss = SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "# métrica\n",
    "metrics = ['accuracy']\n",
    "\n",
    "# compilamos el modelo\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "history = model.fit(x=X_train_cifar10, y=y_train_cifar10, batch_size=50, epochs=20,\n",
    "                    validation_data=(X_validation_cifar10, y_validation_cifar10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ha conseguido mitigar el overfiting.\n",
    "El score obtenido es de 72.5%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Early Stopping\n",
    "Otra opción sencilla para la mitigación del overfiting es el Early Stopping.\n",
    "El Early Stopping es un callback que se utiliza durante el entrenamiento.\n",
    "Dicha función monitoriza el entrenamiento y cuando detecta que el modelo ha dejado de mejorar en el dataset de validación, parará el entrenamiento.\n",
    "Además, podemos seleccionar que nos devuelva el modelo que mejor val_score haya obtenido durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 32, 32, 25)        700       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_52 (MaxPooling (None, 16, 16, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 16, 16, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_53 (MaxPooling (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 8, 8, 100)         45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_54 (MaxPooling (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1000)              1601000   \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,668,110\n",
      "Trainable params: 1,668,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd0652c64d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd0652c64d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "   1/1000 [..............................] - ETA: 0s - loss: 2.2912 - accuracy: 0.0800WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0015s vs `on_train_batch_end` time: 0.0045s). Check your callbacks.\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1.3673 - accuracy: 0.5057WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd050536cb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd050536cb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.3669 - accuracy: 0.5058 - val_loss: 1.0620 - val_accuracy: 0.6231\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.9395 - accuracy: 0.6682 - val_loss: 0.8604 - val_accuracy: 0.7014\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7553 - accuracy: 0.7360 - val_loss: 0.7921 - val_accuracy: 0.7252\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6246 - accuracy: 0.7801 - val_loss: 0.7831 - val_accuracy: 0.7346\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5037 - accuracy: 0.8224 - val_loss: 0.7782 - val_accuracy: 0.7457\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3900 - accuracy: 0.8632 - val_loss: 0.8486 - val_accuracy: 0.7376\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2887 - accuracy: 0.8985 - val_loss: 0.8901 - val_accuracy: 0.7460\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.2097 - accuracy: 0.9263 - val_loss: 0.9694 - val_accuracy: 0.7458\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1543 - accuracy: 0.9454 - val_loss: 1.1005 - val_accuracy: 0.7445\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1167 - accuracy: 0.9592 - val_loss: 1.2249 - val_accuracy: 0.7405\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1076 - accuracy: 0.9626 - val_loss: 1.2305 - val_accuracy: 0.7392\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0905 - accuracy: 0.9695 - val_loss: 1.3611 - val_accuracy: 0.7355\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0855 - accuracy: 0.9712 - val_loss: 1.4599 - val_accuracy: 0.7339\n",
      "Epoch 14/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0809 - accuracy: 0.9721 - val_loss: 1.5343 - val_accuracy: 0.7375\n",
      "Epoch 15/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0762 - accuracy: 0.9747 - val_loss: 1.7131 - val_accuracy: 0.7323\n",
      "Epoch 16/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0722 - accuracy: 0.9763 - val_loss: 1.7121 - val_accuracy: 0.7320\n",
      "Epoch 17/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0711 - accuracy: 0.9760 - val_loss: 1.6920 - val_accuracy: 0.7396\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# capas de la red\n",
    "input = Input(shape=(32,32,3))\n",
    "layer = input\n",
    "layer = Conv2D(filters=25, kernel_size=3, strides=1, padding='same', activation='relu')(layer)\n",
    "layer = MaxPooling2D((2, 2))(layer)\n",
    "layer = Conv2D(filters=50, kernel_size=3, strides=1, padding='same', activation='relu')(layer)\n",
    "layer = MaxPooling2D((2, 2))(layer)\n",
    "layer = Conv2D(filters=100, kernel_size=3, strides=1, padding='same', activation='relu')(layer)\n",
    "layer = MaxPooling2D((2, 2))(layer)\n",
    "layer = Flatten()(layer)\n",
    "layer = Dense(units=1000, activation='relu')(layer)\n",
    "output = Dense(units=10, activation='softmax')(layer)\n",
    "\n",
    "# creamos el modelo\n",
    "model = Model(inputs=input, outputs=output)\n",
    "print(model.summary())\n",
    "\n",
    "# optimizador\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# función loss\n",
    "loss = SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "# métrica\n",
    "metrics = ['accuracy']\n",
    "\n",
    "# compilamos el modelo\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "# Podemos decidir que score queremos monitorizar, cuantas epochs esperar después del mejor score y si queremos que nos devuelva el mejor modelo.\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, mode='max', restore_best_weights=True)\n",
    "\n",
    "history = model.fit(x=X_train_cifar10, y=y_train_cifar10, batch_size=50, epochs=30,\n",
    "                    validation_data=(X_validation_cifar10, y_validation_cifar10), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Early Stopping ha parado el entrenamiento cuando ha detectado overfiting.\n",
    "El método fit nos ha devuelto el modelo que tiene mejor score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on validation data\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.8901 - accuracy: 0.7460\n",
      "val loss: 0.8900617957115173 val acc: 0.7459999918937683\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation_cifar10, y_validation_cifar10, batch_size=128)\n",
    "print('val loss:',results[0], 'val acc:', results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos obtenido un 74.5% de score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularización L2\n",
    "En las capas que deseemos podemos introducir una regularización L2 para impedir que se produzca el overfiting.\n",
    "La regularización L2 introduce una restricción en los pesos de la red. Cuanto mayor es la constante de regularización mayor es dicha restricción.\n",
    "Cuando el modelo sea entrenado, mejorará la función loss y reducirá el tamaño de los pesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 32, 32, 25)        700       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_58 (MaxPooling (None, 16, 16, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 16, 16, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_59 (MaxPooling (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 8, 8, 100)         45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_60 (MaxPooling (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 1000)              1601000   \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,668,110\n",
      "Trainable params: 1,668,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fcff82fa9e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fcff82fa9e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 996/1000 [============================>.] - ETA: 0s - loss: 1.6835 - accuracy: 0.4574WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fcff80a1680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fcff80a1680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.6826 - accuracy: 0.4578 - val_loss: 1.4237 - val_accuracy: 0.5586\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.3250 - accuracy: 0.5958 - val_loss: 1.2166 - val_accuracy: 0.6408\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.2034 - accuracy: 0.6493 - val_loss: 1.1428 - val_accuracy: 0.6802\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.1306 - accuracy: 0.6785 - val_loss: 1.1528 - val_accuracy: 0.6800\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.0755 - accuracy: 0.7025 - val_loss: 1.0764 - val_accuracy: 0.7044\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.0333 - accuracy: 0.7183 - val_loss: 1.0776 - val_accuracy: 0.7044\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.0013 - accuracy: 0.7350 - val_loss: 1.0492 - val_accuracy: 0.7187\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.9722 - accuracy: 0.7456 - val_loss: 1.0447 - val_accuracy: 0.7249\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9443 - accuracy: 0.7554 - val_loss: 1.1039 - val_accuracy: 0.6988\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.9248 - accuracy: 0.7649 - val_loss: 1.0063 - val_accuracy: 0.7422\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.9058 - accuracy: 0.7737 - val_loss: 1.0228 - val_accuracy: 0.7339\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.8879 - accuracy: 0.7818 - val_loss: 1.0505 - val_accuracy: 0.7251\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.8735 - accuracy: 0.7887 - val_loss: 0.9835 - val_accuracy: 0.7542\n",
      "Epoch 14/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.8524 - accuracy: 0.7972 - val_loss: 1.0136 - val_accuracy: 0.7460\n",
      "Epoch 15/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.8412 - accuracy: 0.8011 - val_loss: 1.0225 - val_accuracy: 0.7440\n",
      "Epoch 16/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.8293 - accuracy: 0.8088 - val_loss: 0.9796 - val_accuracy: 0.7603\n",
      "Epoch 17/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.8119 - accuracy: 0.8155 - val_loss: 1.0247 - val_accuracy: 0.7527\n",
      "Epoch 18/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.8049 - accuracy: 0.8180 - val_loss: 1.0771 - val_accuracy: 0.7321\n",
      "Epoch 19/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.7974 - accuracy: 0.8223 - val_loss: 1.0313 - val_accuracy: 0.7487\n",
      "Epoch 20/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.7845 - accuracy: 0.8270 - val_loss: 1.0204 - val_accuracy: 0.7543\n",
      "Epoch 21/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.7710 - accuracy: 0.8317 - val_loss: 1.0109 - val_accuracy: 0.7601\n",
      "Epoch 22/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.7660 - accuracy: 0.8369 - val_loss: 1.0256 - val_accuracy: 0.7541\n",
      "Epoch 23/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7538 - accuracy: 0.8409 - val_loss: 1.0277 - val_accuracy: 0.7574\n",
      "Epoch 24/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7525 - accuracy: 0.8427 - val_loss: 1.0202 - val_accuracy: 0.7574\n",
      "Epoch 25/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7432 - accuracy: 0.8458 - val_loss: 1.0235 - val_accuracy: 0.7615\n",
      "Epoch 26/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.7373 - accuracy: 0.8501 - val_loss: 1.0565 - val_accuracy: 0.7527\n",
      "Epoch 27/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7309 - accuracy: 0.8524 - val_loss: 1.0510 - val_accuracy: 0.7555\n",
      "Epoch 28/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.7252 - accuracy: 0.8567 - val_loss: 1.0183 - val_accuracy: 0.7652\n",
      "Epoch 29/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7186 - accuracy: 0.8586 - val_loss: 1.0868 - val_accuracy: 0.7513\n",
      "Epoch 30/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7174 - accuracy: 0.8594 - val_loss: 1.0663 - val_accuracy: 0.7573\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# capas de la red\n",
    "input = Input(shape=(32,32,3))\n",
    "layer = input\n",
    "layer = Conv2D(filters=25, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2(0.001))(layer)\n",
    "layer = MaxPooling2D((2, 2))(layer)\n",
    "layer = Conv2D(filters=50, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2(0.001))(layer)\n",
    "layer = MaxPooling2D((2, 2))(layer)\n",
    "layer = Conv2D(filters=100, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2(0.001))(layer)\n",
    "layer = MaxPooling2D((2, 2))(layer)\n",
    "layer = Flatten()(layer)\n",
    "layer = Dense(units=1000, activation='relu', kernel_regularizer=l2(0.001))(layer)\n",
    "output = Dense(units=10, activation='softmax')(layer)\n",
    "\n",
    "# creamos el modelo\n",
    "model = Model(inputs=input, outputs=output)\n",
    "print(model.summary())\n",
    "\n",
    "# optimizador\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# función loss\n",
    "loss = SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "# métrica\n",
    "metrics = ['accuracy']\n",
    "\n",
    "# compilamos el modelo\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "history = model.fit(x=X_train_cifar10, y=y_train_cifar10, batch_size=50, epochs=30,\n",
    "                    validation_data=(X_validation_cifar10, y_validation_cifar10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "El overfiting claramente se ha eliminado sin pérdida de eficacia del modelo.\n",
    "¿Qué pasa si ponemos una regularización L2 con constante 1?\n",
    "Observar las diferencias en loss con y sin regularización durante el training.\n",
    "Hemos obtenido un score de 75.7% de score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout\n",
    "Podemos introducir en distintas partes de la red las capas dropout para apagar de manera aleatoria las neuronas y así impedir que se produzca overfiting.\n",
    "Cuanto mayor es el ratio de dropout mayor será la regularización.\n",
    "No es necesario introducir las capas dropout en todas las capas de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_49\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_26 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_73 (Conv2D)           (None, 32, 32, 25)        700       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_73 (MaxPooling (None, 16, 16, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_74 (Conv2D)           (None, 16, 16, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_74 (MaxPooling (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_75 (Conv2D)           (None, 8, 8, 100)         45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_75 (MaxPooling (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_24 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 1000)              1601000   \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,668,110\n",
      "Trainable params: 1,668,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fcff818c710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fcff818c710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "   1/1000 [..............................] - ETA: 3s - loss: 2.3240 - accuracy: 0.0400WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0016s vs `on_train_batch_end` time: 0.0095s). Check your callbacks.\n",
      " 987/1000 [============================>.] - ETA: 0s - loss: 1.5559 - accuracy: 0.4267WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fcfe0538dd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fcfe0538dd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.5544 - accuracy: 0.4274 - val_loss: 1.2797 - val_accuracy: 0.5439\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.2348 - accuracy: 0.5569 - val_loss: 1.0646 - val_accuracy: 0.6216\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.0935 - accuracy: 0.6104 - val_loss: 0.9271 - val_accuracy: 0.6768\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.0010 - accuracy: 0.6450 - val_loss: 0.8999 - val_accuracy: 0.6904\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9413 - accuracy: 0.6667 - val_loss: 0.8277 - val_accuracy: 0.7175\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.8813 - accuracy: 0.6864 - val_loss: 0.8101 - val_accuracy: 0.7291\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.8442 - accuracy: 0.7004 - val_loss: 0.7867 - val_accuracy: 0.7319\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.8030 - accuracy: 0.7174 - val_loss: 0.7745 - val_accuracy: 0.7406\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7755 - accuracy: 0.7252 - val_loss: 0.7146 - val_accuracy: 0.7569\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7523 - accuracy: 0.7345 - val_loss: 0.7745 - val_accuracy: 0.7414\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7280 - accuracy: 0.7438 - val_loss: 0.7008 - val_accuracy: 0.7594\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7069 - accuracy: 0.7487 - val_loss: 0.7013 - val_accuracy: 0.7567\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6858 - accuracy: 0.7594 - val_loss: 0.7361 - val_accuracy: 0.7553\n",
      "Epoch 14/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6694 - accuracy: 0.7650 - val_loss: 0.7066 - val_accuracy: 0.7623\n",
      "Epoch 15/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6557 - accuracy: 0.7694 - val_loss: 0.6838 - val_accuracy: 0.7744\n",
      "Epoch 16/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6401 - accuracy: 0.7722 - val_loss: 0.6680 - val_accuracy: 0.7742\n",
      "Epoch 17/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6233 - accuracy: 0.7804 - val_loss: 0.6930 - val_accuracy: 0.7702\n",
      "Epoch 18/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6144 - accuracy: 0.7826 - val_loss: 0.6778 - val_accuracy: 0.7760\n",
      "Epoch 19/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6027 - accuracy: 0.7866 - val_loss: 0.6710 - val_accuracy: 0.7765\n",
      "Epoch 20/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5947 - accuracy: 0.7903 - val_loss: 0.6818 - val_accuracy: 0.7801\n",
      "Epoch 21/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5819 - accuracy: 0.7931 - val_loss: 0.6856 - val_accuracy: 0.7729\n",
      "Epoch 22/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5773 - accuracy: 0.7953 - val_loss: 0.6864 - val_accuracy: 0.7743\n",
      "Epoch 23/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5667 - accuracy: 0.8001 - val_loss: 0.6587 - val_accuracy: 0.7819\n",
      "Epoch 24/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5537 - accuracy: 0.8047 - val_loss: 0.6540 - val_accuracy: 0.7787\n",
      "Epoch 25/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5503 - accuracy: 0.8064 - val_loss: 0.6675 - val_accuracy: 0.7809\n",
      "Epoch 26/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5380 - accuracy: 0.8085 - val_loss: 0.6689 - val_accuracy: 0.7775\n",
      "Epoch 27/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5393 - accuracy: 0.8076 - val_loss: 0.6648 - val_accuracy: 0.7801\n",
      "Epoch 28/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5338 - accuracy: 0.8091 - val_loss: 0.6773 - val_accuracy: 0.7820\n",
      "Epoch 29/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5212 - accuracy: 0.8131 - val_loss: 0.6547 - val_accuracy: 0.7866\n",
      "Epoch 30/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5183 - accuracy: 0.8178 - val_loss: 0.6659 - val_accuracy: 0.7835\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "# capas de la red\n",
    "input = Input(shape=(32,32,3))\n",
    "layer = input\n",
    "layer = Conv2D(filters=25, kernel_size=3, strides=1, padding='same', activation='relu')(layer)\n",
    "layer = MaxPooling2D((2, 2))(layer)\n",
    "layer = Conv2D(filters=50, kernel_size=3, strides=1, padding='same', activation='relu')(layer)\n",
    "layer = MaxPooling2D((2, 2))(layer)\n",
    "layer = Conv2D(filters=100, kernel_size=3, strides=1, padding='same', activation='relu')(layer)\n",
    "layer = MaxPooling2D((2, 2))(layer)\n",
    "layer = Flatten()(layer)\n",
    "layer = Dropout(0.7)(layer)\n",
    "layer = Dense(units=1000, activation='relu')(layer)\n",
    "output = Dense(units=10, activation='softmax')(layer)\n",
    "\n",
    "# creamos el modelo\n",
    "model = Model(inputs=input, outputs=output)\n",
    "print(model.summary())\n",
    "\n",
    "# optimizador\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# función loss\n",
    "loss = SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "# métrica\n",
    "metrics = ['accuracy']\n",
    "\n",
    "# compilamos el modelo\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "history = model.fit(x=X_train_cifar10, y=y_train_cifar10, batch_size=50, epochs=30,\n",
    "                    validation_data=(X_validation_cifar10, y_validation_cifar10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEWCAYAAACEz/viAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA4nUlEQVR4nO3dd3hc9ZXw8e9R780qtizZlnHvRS7EuGBKDKH3HgjgkAak7Iaw2UA25SWNBRICS4eEUEJP6MVgwMa94F5lS5atalmS1Ufn/eOOjFwkjaQZjTRzPs9znym3zLkemKNfF1XFGGNMcAvxdwDGGGP8z5KBMcYYSwbGGGMsGRhjjMGSgTHGGCwZGGOMwZKBMV0mIk+JyK/b2V8tIkN7MiZjusqSgenzRCRPRE73dxzHUtU4Vd3V3jEiMk9ECnoqJmPaYsnAmD5MRML8HYMJDJYMTMASkUgRuU9ECt3bfSIS6d6XKiL/FpEKESkXkU9FJMS976cisk9EqkRkq4ic1s7HJIvIm+5jl4nISa0+X0VkmPv52SKyyX3cPhH5iYjEAm8Dme4qpWoRyewg7nkiUuCO8QDwpIhsEJFzW31uuIiUishk7/+rmkBlycAEsv8CZgKTgInAdODn7n0/BgqANCADuBNQERkJfB+YpqrxwNeBvHY+4wrgl0AysAP4TRvHPQ58233NccBHqnoYOAsodFcpxalqYQdxA/QHUoDBwELgGeCaVvvPBvar6pp24jbmKJYMTCC7GvgfVS1W1RKcH+1r3fsagQHAYFVtVNVP1ZmoywVEAmNEJFxV81R1Zzuf8aqqLlfVJuBZnB/wE2l0XzNBVQ+q6uouxg3QDNylqvWqWgv8HThbRBLc+68F/tbO9Y05jiUDE8gygT2tXu9xvwfwB5y/5N8TkV0icgeAqu4AbgfuBopF5HkRyaRtB1o9rwHi2jjuYpy/2PeIyCcicnIX4wYoUdW6lhfu0sTnwMUikoRT2ni2nesbcxxLBiaQFeJUpbQY5H4PVa1S1R+r6lDgPOBHLW0DqvoPVT3Ffa4Cv+tuIKq6QlXPB9KB14AXW3Z1Ju52znkap6roUmCpqu7rbswmuFgyMIEiXESiWm1hwHPAz0UkTURSgV/gVKkgIueIyDAREeAQTvVQs4iMFJH57gbbOqAWp1qmy0QkQkSuFpFEVW0EKltdswjoJyKJrU5pM+52vAZMAW7DaUMwplMsGZhA8RbOD3fLdjfwa2AlsB74Eljtfg9gOPABUA0sBf6qqotw2gvuAUpxqoDSgZ95Ib5rgTwRqQRuwWkXQFW34Pz473L3bMrsIO4TcrcdvAzkAK94IV4TZMQWtzEmMIjIL4ARqnpNhwcbcwwbsGJMABCRFOBGju51ZIzHrJrImD5ORG4G8oG3VXWxv+MxfZPPqolE5AngHKBYVce1ccw84D4gHChV1bk+CcYYY0y7fJkM5uA0zj1zomTg7g+9BFigqntFJF1Vi30SjDHGmHb5rM1AVReLyJB2DrkKeEVV97qP9ygRpKam6pAh7V3WGGPMsVatWlWqqmlt7fdnA/IInL7hHwPxwP2q2mH/6CFDhrBy5Upfx2aMMQFFRPa0t9+fySAMmAqcBkQDS0XkC1XdduyBIrIQZ0IuBg0a1KNBGmNMMPBnb6IC4F1VPayqpcBinBkaj6Oqj6hqrqrmpqW1WcoxxhjTRf5MBq8Dp4hImIjEADOAzX6MxxhjgpbPqolE5DlgHpDqXtbvLpwupKjqw6q6WUTewRly3ww8pqobuvJZjY2NFBQUUFdX1/HBxiNRUVFkZWURHh7u71CMMT3Al72JrvTgmD/gTCXcLQUFBcTHxzNkyBCcecdMd6gqZWVlFBQUkJOT4+9wjDE9ICBGINfV1dGvXz9LBF4iIvTr189KWsYEkYBIBoAlAi+zf09jgkvAJIOO1DW62H+oFldzt6amN8aYgBQ0yaChqZmSqnrqGr2fDCoqKvjrX//a6fPOPvtsKioqvB6PMcZ0VtAkg6hw51brmlxev3ZbyaCpqand89566y2SkpK8Ho8xxnRW0KxnEB4aQogI9T4oGdxxxx3s3LmTSZMmER4eTlRUFMnJyWzZsoVt27ZxwQUXkJ+fT11dHbfddhsLFy4Evppao7q6mrPOOotTTjmFJUuWMHDgQF5//XWio6O9HqsxxpxIwCWDX/5rI5sKK0+4r7bRhQBR4aGduuaYzATuOndsm/vvueceNmzYwNq1a/n444/5xje+wYYNG450y3ziiSdISUmhtraWadOmcfHFF9OvX7+jrrF9+3aee+45Hn30US677DJefvllrrnGFqwyxvSMgEsG7QkRwdXs+2U+p0+fflT//AceeIBXX30VgPz8fLZv335cMsjJyWHSpEkATJ06lby8PJ/HaYwxLQIuGbT3F3xJVT37D9UyekAC4aG+ay6JjY098vzjjz/mgw8+YOnSpcTExDBv3rwT9t+PjIw88jw0NJTa2lqfxWeMMccKmgZk+KoRub7Ru43I8fHxVFVVnXDfoUOHSE5OJiYmhi1btvDFF1949bONMcYbAq5k0J6WtoK6pmbivHjdfv36MWvWLMaNG0d0dDQZGRlH9i1YsICHH36Y0aNHM3LkSGbOnOnFTzbGGO/w2bKXvpKbm6vHLm6zefNmRo8e3eG5qsqm/ZUkRoeTlRzjqxADhqf/rsaY3k9EVqlqblv7g6qaSESICg/1ycAzY4zpy4IqGQBEhYVS3+iir5WIjDHGl4IvGYSH4FKl0WXJwBhjWgRhMnA3Inu5R5ExxvRlQZcMIsN8N0eRMcb0VUGXDMJCQwgPDfHJHEXGGNNXBV0yANw9ivxXMoiLc0Y5FBYWcskll5zwmHnz5nFsF9pj3XfffdTU1Bx5bVNiG2O6KjiTQVgIdU3Nfu9RlJmZyUsvvdTl849NBjYltjGmq4IyGUSGh6KqNDR5p6rojjvu4MEHHzzy+u677+bXv/41p512GlOmTGH8+PG8/vrrx52Xl5fHuHHjAKitreWKK65g9OjRXHjhhUfNTfSd73yH3Nxcxo4dy1133QU4k98VFhZy6qmncuqppwLOlNilpaUA3HvvvYwbN45x48Zx3333Hfm80aNHc/PNNzN27FjOPPNMmwPJGAME4nQUb98BB75s95BEVSIaXISGh0CIB/mw/3g46542d19++eXcfvvtfO973wPgxRdf5N133+XWW28lISGB0tJSZs6cyXnnndfm2sIPPfQQMTExbN68mfXr1zNlypQj+37zm9+QkpKCy+XitNNOY/369dx6663ce++9LFq0iNTU1KOutWrVKp588kmWLVuGqjJjxgzmzp1LcnKyTZVtjDmhoCwZhLh/j701m/XkyZMpLi6msLCQdevWkZycTP/+/bnzzjuZMGECp59+Ovv27aOoqKjNayxevPjIj/KECROYMGHCkX0vvvgiU6ZMYfLkyWzcuJFNmza1G89nn33GhRdeSGxsLHFxcVx00UV8+umngE2VbYw5scArGbTzF3wLAQoOVBIdHsrgfrEdHu+JSy+9lJdeeokDBw5w+eWX8+yzz1JSUsKqVasIDw9nyJAhJ5y6uiO7d+/mj3/8IytWrCA5OZnrr7++S9dpYVNlG2NOJChLBuBMS+HNOYouv/xynn/+eV566SUuvfRSDh06RHp6OuHh4SxatIg9e/a0e/6cOXP4xz/+AcCGDRtYv349AJWVlcTGxpKYmEhRURFvv/32kXPamjp79uzZvPbaa9TU1HD48GFeffVVZs+e7bV7NcYEnsArGXgoKjyUqrommlUJaaMevzPGjh1LVVUVAwcOZMCAAVx99dWce+65jB8/ntzcXEaNGtXu+d/5zne44YYbGD16NKNHj2bq1KkATJw4kcmTJzNq1Ciys7OZNWvWkXMWLlzIggULyMzMZNGiRUfenzJlCtdffz3Tp08H4KabbmLy5MlWJWSMaVNQTWHdWkVNA3vLaxieHk90ROfWRA4WNoW1MYHDprBuQ8scRfU2LYUxxgRvMogIC0FEqLUJ64wxJnCSQWeru0JEiAyzOYra0teqD40x3eOzZCAiT4hIsYhs6OC4aSLSJCInnqTHA1FRUZSVlXX6B8zpUWQlg2OpKmVlZURFRfk7FGNMD/Flb6KngL8Az7R1gIiEAr8D3uvOB2VlZVFQUEBJSUmnzquqa+RQbROug1Fe6VEUSKKiosjKyvJ3GMaYHuKzZKCqi0VkSAeH/QB4GZjWnc8KDw8nJyen0+e9t/EAC19Yxavf/RqTByV3JwRjjOnT/NZmICIDgQuBhzw4dqGIrBSRlZ396789I/vHA7Ct6PiBW8YYE0z82YB8H/BTVe2wBVdVH1HVXFXNTUtL81oA2ckxRIWHsPVAtdeuaYwxfZE/RyDnAs+7Z/FMBc4WkSZVfa2nAggJEUZkxFvJwBgT9PyWDFT1SCW/iDwF/LsnE0GLERnxfLLNe1VPxhjTF/mya+lzwFJgpIgUiMiNInKLiNziq8/sipEZ8ZRU1VN+uMHfoRhjjN/4sjfRlZ049npfxdGREa0akWcO7eevMIwxxq8CZgRyV43MsB5FxhgT9MkgIyGSxOhwth6wZGCMCV5BnwxEhJHWo8gYE+SCPhkAjOgfx9YDVTY5mzEmaFkywGk3qKxr4kBl19cWNsaYvsySAc5YA8DaDYwxQcuSAV8lA2s3MMYEK0sGQHJsBOnxkTZHkTEmaFkycBvZ33oUGWOClyUDtxEZ8WwvrsLVbD2KjDHBx5KB28iMeOoam8kvr/F3KMYY0+MsGbi1zFG01aqKjDFByJKB2/D0OAC2WfdSY0wQsmTgFhsZRnZKtJUMjDFByZJBKyMzEqxHkTEmKAVPMlCF8t3OYxtG9o9jV8lhGpo6XJbZGGMCSvAkg3XPwQOToGxnm4eMyIinqVnZXXq45+IyxpheIHiSQfYM53H3J20eMtJ6FBljglTwJIOUoRCfCXmftnnI0NQ4wkLEehQZY4JO8CQDEciZA7s/bbPdICIshJzUWCsZGGOCTvAkA4Cc2VBTCsWb2zxkRP94m8raGBN0giwZzHEedy9u85CRGfHsLa+hpqGph4Iyxhj/C65kkDQIkga3227QsrbB9iKbztoYEzyCKxmAU1WU9yk0u06423oUGWOCURAmg7lQdwgOfHnC3YNSYogMC7EeRcaYoBJ8yWDIbOexjXaD0BBh/MBEPtlWgrYzWtkYYwJJ8CWDhAHQb3i77QYXT81ie3E1a/Irei4uY4zxo+BLBuC0G+xZAq7GE+4+d2ImMRGhvLgiv4cDM8YY/wjSZDAHGqqhcO0Jd8dFhvGN8QN4Y10h1fXWxdQYE/h8lgxE5AkRKRaRDW3sv1pE1ovIlyKyREQm+iqW4xxpN2h7nqIrpmdT0+DizfWFPRSUMcb4jy9LBk8BC9rZvxuYq6rjgV8Bj/gwlqPFpkL62HbbDaYMSmZYehwvWFWRMSYI+CwZqOpioLyd/UtU9aD75RdAlq9iOaGc2bD3C2iqP+FuEeHy3GxW762wBW+MMQGvt7QZ3Ai83dZOEVkoIitFZGVJSYl3PjFnDjTVQcHKNg+5cMpAwkPFSgfGmIDn92QgIqfiJIOftnWMqj6iqrmqmpuWluadDx78NUDarSpKjYvkjDEZvLpmH/VNJx6xbIwxgcCvyUBEJgCPAeeralmPfnh0MgyY2O6kdQCX5WZTfriBDzYV91BgxhjT8/yWDERkEPAKcK2qbvNLEDmzoWAFNNS0ecjs4WlkJkbx/Iq9PRiYMcb0LF92LX0OWAqMFJECEblRRG4RkVvch/wC6Af8VUTWikjblfe+kjMXXA2Qv6zNQ0JDhEtzs/lsRykFB9tOGsYY05f5sjfRlao6QFXDVTVLVR9X1YdV9WH3/ptUNVlVJ7m3XF/F0qZBM0FC2203ALg01+no9M+VBT0RlTHG9Di/NyD7VWQ8DJzaYbtBVnIMpwxL5aVVBbiabfI6Y0zg6TAZiEiGiDwuIm+7X48RkRt9H1oPyZkN+1ZDfftjCa6YNoh9FbV8tqO0hwIzxpie40nJ4CngXSDT/XobcLuP4ul5OXNAXbBnabuHnT4mneSYcF6whmRjTADyJBmkquqLQDOAqjYBgdPpPnsGhEZAXvtVRZFhoVw0JYv3NxVRVn3iUcvGGNNXeZIMDotIP0ABRGQmcMinUfWk8GjImt5huwHA5dOyaXQpr67Z1wOBGWNMz/EkGfwIeAM4SUQ+B54BfuDTqHpazmzYvx5qD7Z72IiMeCYPSuL5Ffm2CpoxJqB0mAxUdTUwF/ga8G1grKqu93VgPSpnDqCQ93mHh14xLZsdxdWs3lvh87CMMaaneNKb6DrgKmAqMAW40v1e4Bg4FcKiOxxvAHDOhExiI0KtIdkYE1A8qSaa1mqbDdwNnOfDmHpeWKQzAM2DdoPYyDDOmZDJv9fvt1XQjDEBw5Nqoh+02m7GKR3E+T60HpYzG4o3QXXHU2Rf7l4F7d/rbBU0Y0xg6MoI5MNAjrcD8bucuc6jB1VFk7OTGJERx/O2zoExJkB40mbwLxF5w739G9gKvOr70HrYgEkQEe9RMhARLsvNZm1+BVsP2Cpoxpi+L8yDY/7Y6nkTsEdVA2/GttAwZ8EbD9oNAC6aksXv3tnCCyvy+cW5Y3wcnDHG+JYnbQaftNo+D8hE0CJnNpTtgMqO2wJSYiM4c2x/XllTQF1j4AzINsYEpzaTgYhUiUjlCbYqEansySB7TM4c53F3x1VFANfOHExFTSOPf7bbh0EZY4zvtZkMVDVeVRNOsMWrakJPBtljMsZDVFKH8xS1mDm0HwvG9ucvH+2gsKLWt7EZY4wPedybSETSRWRQy+bLoPwmJASGnOJxuwHAz88ZTbMqv3lrsw8DM8YY3/KkN9F5IrId2A18AuQBb/s4Lv/JmQMVe+FgnkeHZyXH8L1Th/Hm+v18bmsdGGP6KE9KBr8CZgLbVDUHOA34wqdR+VMn2w0AFs4ZyqCUGO56YyONrmYfBWaMMb7jSTJoVNUyIEREQlR1EdDz6xX3lLRREJsGOz/0+JSo8FB+cc4YdhRX8/SSPN/FZowxPuJJMqgQkThgMfCsiNyPMwo5MInA2Athy5tQU+7xaaePyWD+qHTu+2A7xZV1PgzQGGO8z5NkcD5QA/wQeAfYCZzry6D8bur14GqAtf/o1Gm/OGcMDU3N3PP2Ft/EZYwxPuJJMvg2MEBVm1T1aVV9wF1tFLgyxjqrn616CjqxiM2Q1FgWzhnKK2v2sSLP81KFMcb4myfJIB54T0Q+FZHvi0iGr4PqFXJvgLLtsGdJp0777qknkZkYxX+/toEma0w2xvQRnkxH8UtVHQt8DxgAfCIiH/g8Mn8bcwFEJsKqJzt1WkxEGD8/ZwxbDlTxj+W2AI4xpm/ozBTWxcABoAxI9004vUhEDEy8HDa93qmGZICzxvXnlGGp/PHdrZRV1/soQGOM8R5PBp19V0Q+Bj4E+gE3q+oEXwfWK3SxIVlEuPu8MdQ0uPj9O1t9E5sxxniRJyWDbOB2VR2rqner6iZfB9VrdLEhGWBYejzfOiWHF1bmsza/wifhGWOMt3jSZvAzVV3bA7H0Tkcakj/v9Kk/mD+M9PhIfvH6BpqbO5dMjDGmJ3Vl2UuPiMgTIlIsIhva2C8i8oCI7BCR9SIyxVexdMuRhuSnOn1qfFQ4d549mvUFh3hxpS2RaYzpvXyWDICngAXt7D8LGO7eFgIP+TCWrmvdkHy488Mrzp+UyfQhKfzunS1U1DT4IEBjjOk+TxqQY0UkxP18hHsW0/COzlPVxUB73XDOB55RxxdAkogM8DTwHtXSkLzuuU6fKiL88vyxHKpt5K43NqKdbHswxpie4EnJYDEQJSIDgfeAa3H+6u+ugUDrupMC93vHEZGFIrJSRFaWlJR44aM7qRsNyQCjByTww9NH8PraQn771mZLCMaYXseTZCCqWgNcBPxVVS8Fxvo2rKOp6iOqmququWlpaT350V/pRkMywPfnD+ObJw/m0U938/Anu7wcnDHGdI9HyUBETgauBt50vxfqhc/eh9NttUWW+73eqRsNyeBUF9117ljOm5jJ797ZwvM2OtkY04t4kgxuB34GvKqqG0VkKLDIC5/9BnCdu1fRTOCQqu73wnV9IyIGJl7R5YZkgJAQ4Y+XTmTuiDTufPVL3tnQe2/XGBNcPBln8Imqnqeqv3M3JJeq6q0dnScizwFLgZEiUiAiN4rILSJyi/uQt4BdwA7gUeC7Xb+NHjL1m11uSG4RERbCQ9dMYVJ2Erc+t5YltlSmMaYXkI4aM0XkH8AtgAtYASQA96vqH3wf3vFyc3N15cqV/vhox2NnQO1B+P4KZyGcLqqoaeDy//uCgoM1PLdwJhOykrwXozHGHENEVqlqm6tUelJNNEZVK4ELgLeBHJweRcGpmw3JLZJiInjmxukkx0Zw/ZMr2FFc7aUAjTGm8zxJBuHucQUXAG+oaiMQvH0ju9mQ3FpGQhR/v3EGIQLXPb6Mworabl/TGGO6wpNk8H9AHhALLBaRwUClL4Pq1bzQkNzakNRYnv7WdKrqmrj28WWUH7ZRysaYnudJA/IDqjpQVc92jxbeA5zaA7H1Xl5oSG5tbGYij30zl4KDtdzw5HKq65u8cl1jjPGUJ9NRJIrIvS0jgEXkTzilhODVzRHJJzJjaD/+ctUUNhRWcsvfVlHf5PLKdY0xxhOeVBM9AVQBl7m3SqBza0EGIi81JLd2xpgMfnfxBD7bUcqPXliHy6a9Nsb0EE+SwUmqepeq7nJvvwSG+jqwXq+lIXmld/PiJVOz+Pk3RvPml/v5xesbbB4jY0yP8CQZ1IrIKS0vRGQWYN1eWhqSN78Ba54FV6PXLn3T7KHcMvcknl22l/99f5vXrmuMMW0J8+CYW4BnRCTR/fog8E3fhdSHzLoV9i6F178Li38Ps38ME6+E0A5n+O7QTxeM5ODhBh74aAcpsRFcPyvHCwEbY8yJedKbaJ2qTgQmABNUdTIw3+eR9QWJWfDtxXDl8xCVBG/8AP48xWlYbupeF1ER4TcXjuPMMRnc/a9NvL62987hZ4zp+zxe6UxVK90jkQF+5KN4+h4RGHkWLPwYrnoRYlLhX7c5SWHF49BU3+VLh4WG8MCVk5k5NIUfv7iOj7cWey9uY4xppavLXnZ9Up5AJQIjvg43fwRXvwzx/eHNH8EDk2H5o9BY16XLRoWH8uh1uYzsH893/r6aVXsOejlwY4zpejKwLi5tEYHhp8ON78M1rzhVSW/9BB6YBFve7PD0E4mPCuepG6aTkRDJt55awbaiKu/GbIwJem0mAxGpEpHKE2xVQGYPxtg3icCw0+Bb78J1r0NsKrx0IxRt7NLl0uIj+duNM4gMC+G6x5dTcLDGywEbY4JZm8lAVeNVNeEEW7yqetILyYCTFIbOc6qOohLgxeugrmtTO2WnxPDMjdOpaWjiuseXU1bd9fYIY4xpravVRKaz4jPgkiehfDf869YuT2Mxqn8CT1w/jX0Vtdzw1Aqbx8gY4xWWDHrSkFlw2n/DxledRuUuyh2SwkPXTGFjYSWXPLSETYXBO4msMcY7LBn0tK/dBiMWwLt3QsGqLl9m/qgMHrsul9LqBs5/8DP+/OF2mlzNXgzUGBNMLBn0tJAQuOAhiB8A//wm1JR3+VKnjkrn/R/OYcG4Afzp/W1c9NAStltPI2NMF1gy8IeYFLjsKagugle/Dc1d/4s+OTaCP185mb9ePYWCg7V844HPePiTnTbjqTGmUywZ+MvAqfD138L29+Dz/+325c4eP4D3fjiH+aPSueftLVz68BJ2ldi6ysYYz1gy8KdpN8G4i+GjX8PuT7t9udS4SB66Zgr3XzGJnSWHOev+T3n8s900WynBGNMBSwb+JALn3g8pJ8FL34KqIi9cUjh/0kDe/+EcThmWyq/+vYkrHv2CvWU2SM0Y0zZLBv4WGQ+XPQP1VfDyjeDyzriB9IQoHvtmLn+8dCKb91ey4P7FvLK6wCvXNsYEHksGvUHGGDjnfyHvU/j4t167rIhwydQs3r19DuMHJvKjF9fxny+to7bB1lc2xhzNkkFvMelKmHIdfPon2PaeVy+dmRTNszfN4Afzh/HPVQVc8ODn7Ci2LqjGmK9YMuhNzvo99B8PL98E7/4X7F3WrW6nrYWFhvDjM0fy9A3TKa2u59w/f87Lq6zayBjjkL624Hpubq6uXLnS32H4zsE8eOs/YdcicDVAXAaM+gaMPheGzPbKkppFlXXc+twalu0u57LcLH553jiiI0K7H7sxptcSkVWqmtvmfksGvVTdIdj+Pmz+l/PYeBiiEmHk2U5iOGk+hEd3+fJNrmYe+HA7f160g+HpcTx41RSGZ8R78QaMMb2JX5OBiCwA7gdCgcdU9Z5j9g8CngaS3MfcoapvtXfNoEkGrTXWws5FTmLY+hbUVUB4DAw7HSZc7iy7GdK1v+w/3V7C7c+vpabBxa8vGMfFU7O8G7sxplfwWzIQkVBgG3AGUACsAK5U1U2tjnkEWKOqD4nIGOAtVR3S3nWDMhm05mqEvM+cxLDl386UFonZMO1GmPJNZ6qLTiqqrOO259fwxa5yLp2axS/PH0tMhC1ZYUwg6SgZ+LIBeTqwQ1V3qWoD8Dxw/jHHKJDgfp4IFPownsAQGg4nnQrn3As/3ASX/Q2Sh8AHd8O9o+H178OBLzt1yYyEKJ69aSa3njacl1YXcOofP+bpJXnUNVoXVGOChS9LBpcAC1T1Jvfra4EZqvr9VscMAN4DkoFY4HRVPW5eZxFZCCwEGDRo0NQ9e/b4JOY+rWgjLH8E1r0ATbUw6GswYyGMOqdTjc4r8sr5wztbWZ5XTkZCJN+dN4zLp2UTFW4NzMb0Zf6sJvIkGfzIHcOfRORk4HFgnKq22Z8y6KuJOlJ7ENb83Vk8p2IPxGfCtG/BlOshLs2jS6gqS3eVcd/7248khe/MPYkrpg+ypGBMH+XPZHAycLeqft39+mcAqvr/Wh2zESdh5Ltf7wJmqmpxW9e1ZOChZpczI+qy/3O6qUoIZIyFrGmQNd157HeSMz9SG44khQ+2s3y3JQVj+jJ/JoMwnAbk04B9OA3IV6nqxlbHvA28oKpPicho4ENgoLYTlCWDLijZBl/+EwpWwL5VUO9eJjM62Z0c3NvAqRCVcNzplhSM6fv83bX0bOA+nG6jT6jqb0Tkf4CVqvqGuwfRo0AcTmPyf6pqu3MxWDLopmYXlG6D/OVOcihYASVb3DsF0kbBrFth0lXHnXpsUkiLj+SaGYO5ckY26fFRbXxeM3xyD2SMgzHn+e6+jDHtskFnpmO1FVC4GvJXOOMY9q+Dix+D8Ze0ecrSnWU89MlOFm8rITxUOHv8AK47eQhTBiUhLVVPqvD2T2H5/0FoJNz0AQyY0DP3ZIw5iiUD0zmNtfD3iyF/GVz1gjOwrR27Sqr5+xd7+efKfKrqmxg3MIHrZg7hvEmZRC35Eyz6DUy9Hra96wyU+/YnzrTdxpgeZcnAdF7dIXjyG1C+E657A7KndXjK4fomXlu7j2eW7GFrURU3R3/Ef+ljHB51CbGXPQp7l8LT58DYi5xSRzsN18YY7/PnoDPTV0UlwrWvOJPk/eNSKN7S4SmxkWFcPWMw79w+m/fOLONn+jgfNk9h0rrzuOlvq/i0cQQ6707Y8BKsfroHbsIY0xmWDMyJxaXDta9CaAT87UKo2OvRabLzI0Z89iNCBs1kzG0vc8upo1ibX8G1jy/nrFXTOJB6Mvr2T+HABh/fgDGmMywZmLal5MA1r0DDYSchHC5t//iClfDCtZA2Eq58ngH9UvjxmSP5/I75/OGSCRASwjkF11HWFEX501dRUlbWM/dhjOmQJQPTvv7jnIbkQwXw7CXOWs0nUrzF2R+XBte8DNFJR3ZFhoVyaW42b982mwduPpMn+/+cxJq9LLn/On78wlo2Fh7yXfw15c6Mr65G332GMQHAkoHp2OCT4bJnYP96eP4qaKo/en9FPvz9IggJd6qW4vuf8DIiwtdOSuU/brmZyhk/5vyQz4je+BzfeOAzrnhkKe9vKqK52UsdGlThy5fgwenwtwucxw0ve23lOGMCjSUD45kRX4cL/gq7FzvLcja7ZzQ9XOpUIdVXO43OKUM9ulzygjshZw6/inia388JZ29ZDTc/s5JT//QxDy7aQVFlXddjPbjHKaW8fCMkZsF5f4awKHjpW/DoqU5JwRhzFOtaajpn6YPw7p3O2IEzfgXPnAfFm50SweCvde5aVUXw8CkQnUzTjR/yzvYqnlm6h+W7ywkROHVkOpfmZnPa6HTCQz34u8XVBMsegkW/BQRO+2+YvtBZ+KfZBetfdMY9HMqHofPg9Lshc3Ln/w2M6YNsnIHxvg9+CZ/dCwkDoeoAXPGss9paV+z6GJ65wJn+4oK/ArC79DD/XJnPS6sKKK6qJzUuggsnD+TyadkMS29jwFrhGnjjVjiwHkYsgLP/CEnZxx/XVA8rHofFf4Dachh7Icz/b2fSPmMCmCUD432q8K/bnPECFzwMk67s3vU++g0s/j1c8NBRcyI1uZpZvL2EF1cU8MHmIpqalcmDkrg8N5tzJmYSFxnmVE8t+q1TIohNg7N+D2PO73hQW90hWPJnp6TjanBWiZv7U4jP6N69GNNLWTIwvqHqlAoSBnT/Ws0ueOZ8Z0bVmxdB+qjjDimtrue1Nft4YUU+24uriQ4P5Sc5eVxTdj+Rhwsh91tw2l1H9WLySFWRk4hWPeWMqZh6g7OEqJUUTICxZGD6hsr9TvtBRAxkTgF1OQlHm51koc2gzai6qKptoKLiIINqN7O9eSAPxH6f0TPO5OIpWWQktDF7akfKdsLH98DGV6C5CU6aD9NuguFfh1BbD9r0fZYMTN+x+1N492fOmAAJcW8CEtrqtXsLCaVhyDz+HXsJz68pOtLoPG9kOpflZjF/VAYRYV3oLFdVBKufgVVPQuU+SMiC3OudaqS4dK/f8hHNLqgudrrl2rxNxgcsGZigsLv0MC+tchqdiyrrSYl1Gp0vy81mZP8uzJLqaoJt78CKx5yV4kLCnfUYpt0Eg0723g92Qw2s+4fTdlG+CxKz4aRT4aTTYOhcZwEiY7zAkoEJKq5mdTc65/PB5iIaXcqErETOHJPB/FEZjB4Q/9V6C54q3QErn4C1f3cantPHOG0Lo852xjF0xeFSZ53qFY9CTZlTNTbmPKfdZNdiqD/klIAGTnUSw0nznee+qrJqdjn3Vnuwg63CWSmvuck5p7nJXZXnfq3u95qbneeDZ8Hc/3SmKDF+ZcnABK2y6npeW1vIG2v3sa7AmfIiMzGK+aPTOW1UBief1K9zy3Y21Dizri5/1OnCCpA2Goaf4WzZMyEsov1rlO6ApX+Bdc9BUx2MPBu+9oOjSxuuJti3EnZ+BDs+dBYe0mZnNtmcuU5iyJwESYOdkkNnk1tTA5RshsK1zkJG+9dB0QYnnrZEJkJ0ovN5kQkQEubeQp1HCTnmdSg0N8Lmf0NjjbNQ0pz/hLQRnYu1L1J1qhhjUiG8i21YPmDJwBiguKqOj7eU8OGWIj7dXkpNg4vo8FBmDUvltNHpzB+V7nnjsyqUbIUd78P292DPUueHLyLeqdoZfgYMOwMSB351zt4vnK6sW950ei1NuhJmfs+zH8eactj9iZMYdn7k/NC0iIiDpEFtbIOdBYWKNsL+te4f/rVQtMmJF5wf9gETof8ESHYnl6gk57Fli0rseonkcCksecBJoE11MO4Sp6SQOrxr1+uNGuucf9v8Ze5tORwuhugUmHwN5N7g8ch8X7JkYMwx6ptcLNtVzoebi/hwSzEFB2sBGDcwgTnD05gxtB+5g5OJjfTwB7C+ypmmY/v7zlZZ4LyfPtap/89fDgXLnR/WaTfD9Ju73hitCmU7nGRUsfeYbY9ThdOWqCSnRDFgIgxwPybnQEgPzEpzuBQ+v99pg2mqg/GXOiWF1GHe/yxVOLjbSXqueqdDgqvBGXDY8vzIo/u98BiISXF+wKOTj34eneSUeFpUFTnfZ/4y2LvMSbCuBmdfcg5kz3D+nfcscZK/upyqvmk3dq93WrPLuYeImC6dbsnAmHaoKtuLq/lwczEfbSlizd4KmpqV0BBh/MBEZg7tx4yhKeQOTiY+KtyTC0LJFicp7HjfKTUkZsHJ33MG1EXE+vaGaiuOThD1lU4bx4CJTmnB3z2Vqktgyf2w/DHnh3j8ZU5JoTvjOloSZN5nsOdzyPscqgo9OFEgLNLpHNB42KmKa+u4KHcVmbq+WtsjNMKZziR7hnubfnySryx09057Cqr2O6P2p14PU65rc0JHwGlzKd/ljKwvXONUFe5fD7NuhXl3eHBvJ7gLSwbGeK6moYlVew6ybFc5X+wqY11BBY0uJzmMy0xgxtB+zByaQu6QFBI8SQ5N9c6PTU/89d2XVBe7SwqPO39VjzobUk5yRpHHpkFs6lePMalHt8U0NzsJd8/n7gSwxKmWAWd1vsGzYMgsp1E+IhZCw50f7tDIVs8jnL/2W5Jjc7OTOGvLoaalsbzcqaKrLXde15Q7yWDgVOfHf8BEJ5l4wtUE29527nfXIqddZdQ5Tmlh8ClOqe7ID/8ap9qppZQXFg0DJjiJZ+TZTlVkF1gyMKYbahtcrN57kGW7yvhiVzlr8ytocDUTGiJMGZTE3BFpzBuZzpgBCYSE2PiATqsqcpLCptecBNHcxroTUYlOcohOcUoBteXO+wlZzg//4Fkw5BSnbt7fpZ+OlO10eqet+TvUVTgz6rY03odGQMY454e/ZUsb5ZVeZJYMjPGiukYnOSzZUcYn20r4cp/TSyk1LpK5I9KYOzKNOcNTSYrpoFeROZ6q0731cCnUlMLhEvdW+tVjTakzFqPlr/+kwb3/x78tjbWw4RWnJJAx1vnhTx/TcY+0LrJkYIwPlVTVs3hbCR9vK+HT7SVU1DQSIjApO4l5I9OZOyKN8QMTrdRg/M6SgTE9xNWsrCuo4OOtJXyytZj1+w6hCmnxkZw+Op3TR2cwa1hq58Y2GOMllgyM8ZOy6noWby/hw83FfLK1hKr6JqLCQ5g9PI0zxmQwf1Q6qXEeNkAa002WDIzpBRqamlm2u4z3NxXxwaYiCg/VIQJTByVz+pgMTh+dwbD0OH+HaQKYJQNjehlVZdP+SicxbC5iwz6nC2F2SjSj+icwLD2O4elxDEuP46S0OM8HvxnTDksGxvRyhRW1fLi5iCU7y9heXE1e6WGamr/6/3JgUjQntUoQw9LjGNU/3rNBcMa4+TUZiMgC4H4gFHhMVe85wTGXAXcDCqxT1auOPaY1SwYm0DW6mtlTVsOO4ip2FFezo7ia7cXV7Cyppq7RGSUrAsPS4piUncTE7CQmZScxsn884aE2uM2cWEfJwGflTxEJBR4EzgAKgBUi8oaqbmp1zHDgZ8AsVT0oIj5cPcSYviE8NORICaC15mZlX0Ut24ur2LCvkrX5FXy0pZh/rnLmQooMC2HcwEQmZiUxaVASk7KSyE6J7vyU3SYo+bIycjqwQ1V3AYjI88D5wKZWx9wMPKiqBwFUtdiH8RjTp4WECNkpMWSnxDB/VAbgtD8UHKxlbX4F6/IrWJtfwbPL9vDE57sBSIwOZ2haLDn9YhmS6mxD3Y9x1hZhWvHlfw0DgfxWrwuAGcccMwJARD7HqUq6W1XfOfZCIrIQWAgwaNAgnwRrTF8k8lWCOHdiJuBUM20rqmJd/iE2FB4ir/QwS3eV8cqafUedmxoXSU5qDEP6xZKTFsvYzEQmD0rybM4lE3D8/adBGDAcmAdkAYtFZLyqVrQ+SFUfAR4Bp82gh2M0pk8JDw1hbGYiYzMTj3q/tsHFnvLD5JUeZlep85hXWsOirSVHqppEYFT/BHIHJ5M7JJncISkMTIr2x22YHubLZLAPyG71Osv9XmsFwDJVbQR2i8g2nOSwwodxGROUoiNCGdU/gVH9E47bV1nXyPr8Q6zcU87KvIO8srqAv32xB4ABiVHkDnGm8Z46OJnRAxIItek1Ao4vk8EKYLiI5OAkgSuAY3sKvQZcCTwpIqk41Ua7fBiTMeYEEqLCOWV4KqcMTwWgydXMlgNVrMwrZ8Weg6zYXc6/1jlrBESEhZAaG0G/uEj6xUWQEhtBalwkKbER9Gv9PC6C/glRhFkPpz7BZ8lAVZtE5PvAuzjtAU+o6kYR+R9gpaq+4d53pohsAlzAf6hqma9iMsZ4JizU6Zk0bmAi18/KQdXpybQy7yCb91dSWt1A2eF6yg83sL2omtLqeuqbjl8cJjIshFEDEhiXmcDYzETGDUxgREa8zc/UC9mgM2NMt6kqNQ0uytxJoqy6gdLqerYXV7Ox8BAbCyupqmsCICxEGJYedyQ5jM1MZExmgvVu8jG/jTMwxgQPESE2MozYyDAG9Tt+jV5VJb+8lg2Fh9hYeIgN+yr5ZFsxL692Gq5DBEYPSGDakBT3lkx6QlRP30ZQs5KBMcYvVJXiqno2Fh5ibf4hVuaVs2ZvBbWNLgAG94shd3AK03OSmTYkhZzUWBtA1w1WMjDG9EoiQkZCFBkJUUcG0TW6mtlYWMmK3eWsyCtn0davSg+pcRHkDk5hUL8YEqLCSIgOJz4qjISo8KOex0eFERcZZomjk6xkYIzptVSVnSWHWZHnJIdVew5SVFl3ZI6mtoQI9IuLZGJWIlMGJzNlUDITs5KIjgjehmsrGRhj+iwROTJP05XTv5p9oKGpmaq6RirrmqisbaSqronKusajnhdW1LEm/yAfbHZmuQkNEUYPiGfqoOQjCSIr2eZuamHJwBjT50SEhbjHOXS8UtzBww2syT/I6j0VrNpzkH+uKuDppc6AutS4SKYMSiIpJpxGl9Lgaqaxqdl5dDXT2OS819DkvBaB9Pgo0uMjSU+IIiMh0l3VFem8nxBJZFjfLH1YMjDGBLTk2Ajmj8o40i7R5Gpma1EVq/dWsHrPQdbmV1DX6CI8NITwUCE8NITIsBD36xASIsKJCBUiwkJwNSslVfUs232Y4qo6Gl3HV7MnxYSTER/FiP7xR0Ztj+of3+sH31mbgTHGdIGqcrCmkaLKOoqr6p3HyjqKKuvZf6iODfsOcaCyDoCYiFAmZSc5yWFIil8mBLQ2A2OM8QERISXWmY5j9IDj96sqhYfqWJlXzuo9B1m55yB/WbSDZnUmBByZEc+UwcmMy0wkMTqcOHcvqLjIMOd5RBixkaE9VqKwkoExxvSQw/VNrM132i5W7jnImj0Hqapvavec6PBQYiPDiI8K4+oZg7hp9tAufbaVDIwxppeIjQxj1rBUZg1zJgR0NSsHKuuormuiur6R6npX28/rm0j1oMG8qywZGGOMn4SGSK9ZL6J3N28bY4zpEZYMjDHGWDIwxhhjycAYYwyWDIwxxmDJwBhjDJYMjDHGYMnAGGMMfXA6ChEpAfZ08fRUoNSL4fQGgXZPgXY/EHj3FGj3A4F3Tye6n8GqmtbWCX0uGXSHiKxsb26OvijQ7inQ7gcC754C7X4g8O6pK/dj1UTGGGMsGRhjjAm+ZPCIvwPwgUC7p0C7Hwi8ewq0+4HAu6dO309QtRkYY4w5sWArGRhjjDkBSwbGGGOCJxmIyAIR2SoiO0TkDn/H4w0ikiciX4rIWhHpc2uBisgTIlIsIhtavZciIu+LyHb3Y7I/Y+ysNu7pbhHZ5/6e1orI2f6MsTNEJFtEFonIJhHZKCK3ud/vk99TO/fTl7+jKBFZLiLr3Pf0S/f7OSKyzP2b94KIRLR7nWBoMxCRUGAbcAZQAKwArlTVTX4NrJtEJA/IVdU+OVhGROYA1cAzqjrO/d7vgXJVvcedtJNV9af+jLMz2rinu4FqVf2jP2PrChEZAAxQ1dUiEg+sAi4ArqcPfk/t3M9l9N3vSIBYVa0WkXDgM+A24EfAK6r6vIg8DKxT1Yfauk6wlAymAztUdZeqNgDPA+f7Oaagp6qLgfJj3j4feNr9/Gmc/1H7jDbuqc9S1f2qutr9vArYDAykj35P7dxPn6WOavfLcPemwHzgJff7HX5HwZIMBgL5rV4X0Mf/A3BT4D0RWSUiC/0djJdkqOp+9/MDQIY/g/Gi74vIenc1Up+oUjmWiAwBJgPLCIDv6Zj7gT78HYlIqIisBYqB94GdQIWqNrkP6fA3L1iSQaA6RVWnAGcB33NXUQQMdeowA6Ee8yHgJGASsB/4k1+j6QIRiQNeBm5X1crW+/ri93SC++nT35GqulR1EpCFUxMyqrPXCJZksA/IbvU6y/1en6aq+9yPxcCrOP8R9HVF7nrdlvrdYj/H022qWuT+n7UZeJQ+9j2566FfBp5V1Vfcb/fZ7+lE99PXv6MWqloBLAJOBpJEJMy9q8PfvGBJBiuA4e7W9QjgCuANP8fULSIS624AQ0RigTOBDe2f1Se8AXzT/fybwOt+jMUrWn403S6kD31P7sbJx4HNqnpvq1198ntq6376+HeUJiJJ7ufROB1lNuMkhUvch3X4HQVFbyIAd1ex+4BQ4AlV/Y1/I+oeERmKUxoACAP+0dfuSUSeA+bhTLdbBNwFvAa8CAzCmar8MlXtMw2ybdzTPJzqBwXygG+3qm/v1UTkFOBT4Eug2f32nTj17H3ue2rnfq6k735HE3AaiENx/sB/UVX/x/0b8TyQAqwBrlHV+javEyzJwBhjTNuCpZrIGGNMOywZGGOMsWRgjDHGkoExxhgsGRhjjMGSgQkyIqIi8qdWr3/inkiu13HPpPkTf8dhgoMlAxNs6oGLRCTV34EY05tYMjDBpglnfdgfHrtDRIaIyEfuyco+FJFB7V3IPTnYH0Rkhfucb7vfnycii0XkTXHW0HhYRELc+64UZw2KDSLyu1bXWiAiq91z0n/Y6mPGiMjHIrJLRG71yr+AMSdgycAEoweBq0Uk8Zj3/ww8raoTgGeBBzq4zo3AIVWdBkwDbhaRHPe+6cAPgDE4E6BdJCKZwO9wphaeBEwTkQtEJA1nPpyLVXUicGmrzxgFfN19vbvc8+oY43VhHR9iTGBR1UoReQa4Fahttetk4CL3878Bv+/gUmcCE0SkZf6XRGA40AAsV9VdcGSKilOARuBjVS1xv/8sMAdwAYtVdbc7vtbTOrzpnkKgXkSKcaaKLuj8XRvTPksGJljdB6wGnuzGNQT4gaq+e9SbIvM4fkrnrs770nouGRf2/6zxEasmMkHJ/df3izhVPS2W4MxoC3A1zoRm7XkX+E5L1Y2IjHDPIAsw3T1LbghwOc5ShMuBuSKS6l6K9UrgE+ALYE5LFZOIpHT7Bo3pJPsrwwSzPwHfb/X6B8CTIvIfQAlwA4CI3AKgqg8fc/5jwBBgtXtq5BK+WlpwBfAXYBjOVMKvqmqze73gRTilijdV9XX3ZywEXnEnj2KcaYiN6TE2a6kxXuauJvqJqp7j51CM8ZhVExljjLGSgTHGGCsZGGOMwZKBMcYYLBkYY4zBkoExxhgsGRhjjAH+P6G9/Ljxldz0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conseguimos eliminar el overfiting y obtenemos un score muy alto, 78.3% de accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Data Augmentation\n",
    "El data augmentation es uno de los mejores métodos de regularización.\n",
    "Consigue aumentar virtualmente el dataset haciendo que el modelo sea muy robusto y que su performance en validation sea muy buena.\n",
    "Con ello conseguimos reducir el overfiting y además que el modelo sea robusto frente a pequeñas perturbaciones en las imágenes.\n",
    "Vamos a implementar un data augmentation que se aplicará durante el entrenamiento, para ello usaremos la clase tensorflow.data.Dataset.\n",
    "Las funciones que vamos a usar son propias de tensorflow, con ello aseguramos un máximo rendimiento y fiabilidad del entrenamiento.\n",
    "También se puede implementar usando generadores o con un generador de keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-16 19:41:00.557424: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2021-12-16 19:41:00.579759: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 19:41:00.580430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:09:00.0 name: GeForce GTX 1080 computeCapability: 6.1\n",
      "coreClock: 1.835GHz coreCount: 20 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 298.32GiB/s\n",
      "2021-12-16 19:41:00.580447: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-16 19:41:00.581712: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-16 19:41:00.582871: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-16 19:41:00.583048: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-16 19:41:00.584551: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-16 19:41:00.585428: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-12-16 19:41:00.588811: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-16 19:41:00.589054: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 19:41:00.590260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 19:41:00.591064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2021-12-16 19:41:00.591585: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-16 19:41:00.621369: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 3699535000 Hz\n",
      "2021-12-16 19:41:00.621851: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1fc32c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-12-16 19:41:00.621864: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-12-16 19:41:00.689192: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 19:41:00.689947: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4265b40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-12-16 19:41:00.689958: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080, Compute Capability 6.1\n",
      "2021-12-16 19:41:00.690081: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 19:41:00.690843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:09:00.0 name: GeForce GTX 1080 computeCapability: 6.1\n",
      "coreClock: 1.835GHz coreCount: 20 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 298.32GiB/s\n",
      "2021-12-16 19:41:00.690874: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-16 19:41:00.690901: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-16 19:41:00.690916: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-16 19:41:00.690930: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-16 19:41:00.690942: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-16 19:41:00.690953: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-12-16 19:41:00.690966: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-16 19:41:00.691025: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 19:41:00.691857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 19:41:00.692527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2021-12-16 19:41:00.692562: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-16 19:41:01.216625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-12-16 19:41:01.216661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
      "2021-12-16 19:41:01.216667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
      "2021-12-16 19:41:01.216928: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 19:41:01.217669: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 19:41:01.218507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6452 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:09:00.0, compute capability: 6.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function processing_data at 0x7f2b728d1320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function processing_data at 0x7f2b728d1320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAeEUlEQVR4nO2de4ykZ5Xen/PVpa8z3dNz88x4bAx2DIOEDZm1SJasCCzE6z/WsIo2EAX5D5RZRWspjjZSHCJlnSiKIAogpI2IhmCt2QUMCyZYK2uzjrUSQsqaHRPjy3odm2GwPZeeW/dM36vqq5M/qpy0rfc53VPdVWV4n580mur39Pt9p976Tn3V71PnHHN3CCF++SmG7YAQYjAo2IXIBAW7EJmgYBciExTsQmSCgl2ITFCwCwCAmT1gZn8c2J83sw8OziOx3VSH7YD4xcDd3z1sH8TW0J1diExQsGeImf0rMzttZgtm9qKZfbhrqpvZ17rjz5vZ0XVzTpnZr3cfP2Bm3zGzb3V/98dmdttQnozYNAr2zDCzWwHcC+BX3H0HgH8A4FTX/JsAHgYwDeBRAH8QHOpuAH8CYAbANwD8dzOr9cdrsR0o2POjBDAC4IiZ1dz9lLv/tGv7obs/5u4lgD8CEN2tn3L377h7E8AXAIwCeH9fPRdbQsGeGe7+MoD7ADwA4LyZPWxmB7vmc+t+dRnAqJmxTdxX1x2zDeA1AAfJ74q3AAr2DHH3b7j7BwDcCMABfK6Hwxx+/YGZFQCuB3BmezwU/UDBnhlmdquZfcjMRgCsAlgB0O7hUH/bzH6re+e/D8AagL/cPk/FdqNgz48RAJ8FcBGdj+37APzrHo7zfQD/CMAcgE8B+K3u3+/iLYqpeIW4VszsAQA3u/s/GbYvYvPozi5EJijYhcgEfYwXIhN0ZxciEwaa9VYf3+HjO/cmbdHnC2dWt2BOdLzIxo8ZmfiUHiZtdK5ePoz1/LR6m8hMRRFMCp5XNbgtTYzwb+lWyfmarRZ3w7iPa00+rxX47+G1mp7Yy8u8MncejaUryZNtKdjN7E4AXwJQAfDf3P2z0e+P79yLv3fPf0zaSpR0XqudloHbJb8CSue2ZnCVNoMX2i19TCPjAFAUgS04VxRInS+sXRtRkMX+V3o6ZsXSl+rE2Aidg5Jf3ntGuY+/cvMBapsZSc+7cOkinbNW5WHx0vk5aptboyY0S76Oa55+AymD17lNrp2//IN/Qef0/DHezCoA/guA3wBwBMAnzexIr8cTQvSXrfzNfgeAl939pLs30MmWunt73BJCbDdbCfZDWJcMgU4ixKE3/5KZHTOzE2Z2orGysIXTCSG2Qt934939uLsfdfej9bEd/T6dEIKwlWA/jXWZT+hkPZ3emjtCiH6xld34vwJwi5ndhE6QfwLAPw5nmAHV9K5kO9iJLcnObrvgc9rBTmYogwS2NlEFIrku2rGOdupjrl2U8XawGx/46Gj05AZ7apHMN17jO9YHdk1SW71cprbm3Hxy/NbdU3TOjj37qa0Az/V5cfYKtV1t8OuxJNe+BQvs5DWL1rfnYHf3lpndC+B/oCO9Pejuz/d6PCFEf9mSzu7ujwF4bJt8EUL0EX1dVohMULALkQkKdiEyQcEuRCYMNOvNATSJAtFoB9IbkcPaRJIDgHZQQ7EMBQr+/scy2Dw4VyjlBbUEoiSZIG8FRuZFz9gCCbMInlsRrD9T85oNLpOtBtLbK3Mr1Hb5Ms9AedfB6eT4VPCcL5w6xW0XLlDb1StL1NYqRqmN9dawsNYEuwii11IIkQUKdiEyQcEuRCYo2IXIBAW7EJkw8N14thPeDHYeS2LzItgFD3aKEZSsCjZpO4k8CSrR9niPsF31DsEOeQ+uROeKVIFqaCPHC9SJqAzTfJCP06zxne6TV9Mln1699Aqds7zC68zNBTXoVoLnZi1edo3dcsPyY+wajhQefjQhxC8TCnYhMkHBLkQmKNiFyAQFuxCZoGAXIhMGKr2ZGSq19Jf+K4GcxKSmKNklSk5BVI8tkE9YOknULihW8qIuLZHt2o8ZplT01pEJHt0riBzJ6gkCgJfBa2Y8SWYVvP3Thbm05BV1wVkKjlcWPGQsuOYq0TVH5kU16PgrI+lNiOxRsAuRCQp2ITJBwS5EJijYhcgEBbsQmTDwrDcmTlQKLq0UJMMnqkHnQfZPlBEXNlYi6kmo1kWHCyU0boukvp5q0EUnCzMLuUTVZlJZhaevlaEbPGtsBDwTrVIh7cacX28oeYsnIy3AAIQZZ5GwzF/P3uoQMrYU7GZ2CsACgBJAy92PbuV4Qoj+sR139r/v7he34ThCiD6iv9mFyIStBrsD+HMze8rMjqV+wcyOmdkJMzvRXL66xdMJIXplqx/jP+Dup81sH4DHzexv3P0H63/B3Y8DOA4AOw/efO2NxYUQ28KW7uzufrr7/3kA3wNwx3Y4JYTYfnq+s5vZBIDC3Re6jz8K4N+HcwAQJYS2VgK4ouHhnEAGsahdU/Dhg2WUhWlj0fG4LZLDoudtxJciqEQZFZUsgkvEgky0OhmfCs4VFWxsBGtcBFVCSyLLtZ1LeUUgr3kgAUYUgf9ceYsKi5LXObgUt/Ixfj+A73UvyiqAb7j7n23heEKIPtJzsLv7SQC3baMvQog+IulNiExQsAuRCQp2ITJBwS5EJgy84GS9QjLYouKRRJJpBzlqYfnKoPhfpJRRjSTSO6IMtVBCi4o5RqdLz4uknyJMoeKXSKsIMtGq6Vdg7ZUzdM7s/BVq2/+uI9RWZY3lwGXWQHlDNVjgaihFBvPIdQ8AdZJZWATSbEGecyV6nalFCPFLhYJdiExQsAuRCQp2ITJBwS5EJgx4Nx6okV3EMizIlh5uBzvn0a66k5p2HVuUuMLGe9tV77X9E4KdXZbUErU7inxsBbUB4bye3EidrOP0KJ1Tb65x2wi/VKvBLYspDVblz6sS7Mazmnbdo3KLc32oVqRr3oU76xWW8KTdeCGyR8EuRCYo2IXIBAW7EJmgYBciExTsQmTCQKW3woCRevr9pWyFDYqSo70mwkS6nEcNoJisFdV3C2uP9SjZhTYmvUV+BP4TiQcApopxahuzdO231uHr6ZzR62+ktmbwmtWDmnGsFl4lWI8yOF4oiUYEF2S1km6jVQnWnr1kUXKV7uxCZIKCXYhMULALkQkKdiEyQcEuRCYo2IXIhIHXoKvV0llDRdDqBiRjqB21fwoUkqjmWlD2i0tvQSYUk8KALdSgizLR2PnCunXcOB74f2CM++EL88nxC820JAcANjpBbbXgBa1Vgow40q7JgjZOkaQbLWScMcltjTK9Jh6sFZN024EPG97ZzexBMztvZs+tG5sxs8fN7KXu/7s2Oo4QYrhs5mP8HwK4801j9wN4wt1vAfBE92chxFuYDYO922/98puG7wbwUPfxQwA+tr1uCSG2m1436Pa7+9nu43PodHRNYmbHzOyEmZ1YXeR1wYUQ/WXLu/He2ZWguwLuftzdj7r70dHJqa2eTgjRI70G+6yZHQCA7v/nt88lIUQ/6FV6exTAPQA+2/3/+5uaZUCFFEusBNIKUy08zECKivUF73FBFUvmYiiv9ZglFR3Te8hsanu6qCEAVCPpzbi8trI8R21TSBeP3B0VejQuh6160HaJWgAjLao8WA+Lro+IKJsyKDjpJEPQ24FM2SY+blF6+yaA/wXgVjN7zcw+jU6Qf8TMXgLw692fhRBvYTa8s7v7J4npw9vsixCij+jrskJkgoJdiExQsAuRCQp2ITJhsAUnAdRZdlsRFPkjskURNXsLBJl2IPOV0dsfyZbrtahkhAVZUpWCSzJ1pKWmMSJBAcCOerrgIQDMjHCprLUaZCquLCWHpydn6JR28Jw9yIr0qOAnGY9elih5LaTX3oPkOi6ja4BUsIyel+7sQmSCgl2ITFCwC5EJCnYhMkHBLkQmKNiFyITBFpyEY5TJRkGGT6VISxBjtSATKpDXmkG9xpXADydSSJgkFfZYi4ooBkUxm2lZCwDaS1eT4zOTo3ROdSGdoQYAq3M8O2yltUxtxWojOV4ruQRo4zupbXKU10IoowxB0rfNAi3Mgl5vUVHJqE9glPVmRC4tI7mRnMoCH3RnFyITFOxCZIKCXYhMULALkQkKdiEyYcCJMI5RkN1d47u+bGO6Huxw1oIWScuN9E4xAFRJeyqAJ1xESStF4EcRJHCY8x3yS6dPUltzZSE5fvbyJTqnsbhIbTO7ebOfkWneruk9t7wzOX7m7Dk6Z5EoCQBw3U07qK0ZrOPaGqvvFtSga0f1/zhloDRMjo9T264daaXh1ddeo3OapGUUSxoDdGcXIhsU7EJkgoJdiExQsAuRCQp2ITJBwS5EJgxUeoO3UbRW06aSy2EsiWClyZNWmoHkFUkk9Xad2qq1dK22RpMfL+pNVBsZobaRCp/YCtoklWNjyfG5IDHowhKX+fYd4gkohqB23c69yfGF81wC9DZ/Xnvq/L50cWmF2hqraVu7xaW3MqhtGFUUjK6rtTJINirTMbF2dZ7OaZC1agc+bKb904Nmdt7Mnls39oCZnTazp7v/7troOEKI4bKZj/F/CODOxPgX3f327r/HttctIcR2s2Gwu/sPAFwegC9CiD6ylQ26e83sme7HfPqdSjM7ZmYnzOzE8mL6q5xCiP7Ta7B/GcA7ANwO4CyAz7NfdPfj7n7U3Y+OT/LvNwsh+ktPwe7us+5eemeb/CsA7thet4QQ201P0puZHXD3s90fPw7guej3/x/eBhppKcRLLoUwyqBeXFly+WTXJM9Auvn6tGQEAFOT6SyvZZJZBQBoBJl5RMoDgHaN+7/vyGFqe+3sbHJ8/4EDdM7lK/zPq50jvHZd1PZqlWTStda4xPr2G/nzaq3xeneXXuXZYfNL6XmtFn9dWoF81Qpq0JXBMRtLfI0P7U3LmyfPXqBz2kU6dNeC9d0w2M3smwA+CGCPmb0G4PcBfNDMbkcn4+8UgN/Z6DhCiOGyYbC7+ycTw1/tgy9CiD6ir8sKkQkKdiEyQcEuRCYo2IXIhAFnvQHeSstUZSvI5CLteFpNLjNE7X0apN0OAOyq76O2eot8azh4y6xVgwKWi1eo7fwSt81OTVJbczWdQbV3kmfzVYJ+WItL89Q2ERRRXF5NF4+0Kl+smSne/unSPF+P+XOvUtuzL6aLc1aLIGNvFy+yWQZtuS5e4Bl90xN8rXx3+stmy4EaXSUZkx5cjLqzC5EJCnYhMkHBLkQmKNiFyAQFuxCZoGAXIhMGKr2tNhp48WdpmaQZ9F9zIqNV21wyagfFKC+kazICAG679e3U9r533ZQcvzKfzjQDgJUVXmiwGZQvPAAu1Sw10/IaAOyop9dkZY3rOBM1/p5f1vgl4k1+zNEdaTnp8MGDdM7UBH9hpoJMxXrg423vfndyvFoJLv2gX9o8kTYBYG6OZ7YVwX11gazjzAyfUx9Nr0e1yp+X7uxCZIKCXYhMULALkQkKdiEyQcEuRCYMdDe+1XZcXiI7uDxvBRWyw1gYT2bwoLXSKvjO/5898wK13XDDdcnx23YfonOWwHdvG2Pcx+oqVxoWFnhSSEl2+FtBS6P5hSVqu3yV26LkpRZRV67Ocd8by/xcE0EiyY37ed3A9747bavU+fFOnubqyuLJU9Q2Ns3r9V0M2l797NUzyfGRCd56a4pcO5WgLqDu7EJkgoJdiExQsAuRCQp2ITJBwS5EJijYhciEzXSEOQzgawD2oyOQHXf3L5nZDIBvAXgbOl1hftvd5zY4GlpFWp7wIPmgJO9JrWBO1EzKwOux/egUb7lTPPJEcvyuGS6RvOvW66ltx61pKQ8Alrlih5XldAstAKjU08+t5EuFasFlvv17dlPbapDkM3cxLTXt2TVN5xzcz1tUjQfSW408ZwAYH0sn16yWXKIanwgakFa43HvmAr925i6la/IBwL696bqHo3V+rrFK+gXlr+Tm7uwtAL/n7kcAvB/A75rZEQD3A3jC3W8B8ET3ZyHEW5QNg93dz7r7j7uPFwC8AOAQgLsBPNT9tYcAfKxPPgohtoFr+pvdzN4G4L0AngSwf10n13PofMwXQrxF2XSwm9kkgO8CuM/d3/AHiHeqSyS/j2lmx8zshJmdaK7ytrtCiP6yqWA3sxo6gf51d3+kOzxrZge69gMAzqfmuvtxdz/q7kdrpLqGEKL/bBjsZmbotGh+wd2/sM70KIB7uo/vAfD97XdPCLFdbCbr7VcBfArAs2b2dHfsMwA+C+DbZvZpAD8H8NsbHajRbOHV2YtJW2FcCmF4GWSUBVle7YJLNfVA7nhi9qXk+Nwyl1U+dGKa2l5eeo3a9h+6gdr+7l13Uts+UuNtcpK3jLJA52sGLbaKIFVxhNSF2xnIWodv4M+5CGqrsQw7AGi307UIF+d4FtrKpXPUVmnyzLxqySXRg/t4S6np6XTbqyp4HUW00s85ynrbMNjd/YcArYz44Y3mCyHeGugbdEJkgoJdiExQsAuRCQp2ITJBwS5EJgy04GTZbmNhIS1TeZunZbVJ+6eJKn+vGhkPsqTGuLw2UefH3Deezm7bX/DCkVca89R26WLye0ideU1ezPHgudPU1iTS4fQ0X9/FRS4ZjYxxmXLvQZ6lNrN7T3J8fIS3eFot+XOeu8ylsqWgAOfa8mJy/JXTXPZ84efpFmUA8LNzl7ntLLe1C37NFSRXrV3y3E0WLleWuDSoO7sQmaBgFyITFOxCZIKCXYhMULALkQkKdiEyYaDSW2GG8dG0TBUlvVUqaWmiRsYBYHycSzwIer3tnuCZXO85nC6+eLDKs8YmbYLa7ngnz/K63OB+nJ1LZw4CwJW1tC/VQB5cWeWFI8cnuYQ5MzNDbWsrxI/g/jI1zQt3Li6lJTQAWF3jrye7rmbneKbipVUuAZ4JCkdeWOAS5nKD+z9NMhJX1vjr0mqnn1gzqCyqO7sQmaBgFyITFOxCZIKCXYhMULALkQkD3Y2vFAUmSRsfi952yMZ0GSROtEiNLgDYwXM7sH+K757vmUnvmraX+a7pz2Z5AsfcIp/XIG2yAGB8lC/WBFnf0SABxYL2TwtNvsN8OUhAWV1Olw2v0ApnwPXX8XZYtRG+Huev8BLlZy7Op+dcTo8DwFqL72gvLPG6cIEoAC/5a7ZGdt2XgqSWRisdFO0gJnRnFyITFOxCZIKCXYhMULALkQkKdiEyQcEuRCZsKL2Z2WEAX0OnJbMDOO7uXzKzBwD8UwAXur/6GXd/LDpWURgmxtIJGWsNLkOxunWrwZx2lBwxwZNClmq87tcpT0s8EzUuJ62U/FyX1riMM3v5ArVN1Lg0NDqS1hXrZBwAxsd4ssvEzmlqq5EWTwBQeFoCKlv8NVta4RLa2ARvn/TT0zwx6NT5+eS4G/d9pM7XamGVv2aLSzwhqgxqLFYsXZ+uKIIaiyNp/y2YsxmdvQXg99z9x2a2A8BTZvZ41/ZFd//PmziGEGLIbKbX21kAZ7uPF8zsBQCH+u2YEGJ7uaa/2c3sbQDeC+DJ7tC9ZvaMmT1oZvxzlhBi6Gw62M1sEsB3Adzn7lcBfBnAOwDcjs6d//Nk3jEzO2FmJ1pr/KuXQoj+sqlgN7MaOoH+dXd/BADcfdbdS3dvA/gKgDtSc939uLsfdfej1eD72UKI/rJhsJuZAfgqgBfc/Qvrxte3A/k4gOe23z0hxHaxmd34XwXwKQDPmtnT3bHPAPikmd2Ojhx3CsDvbHSgsiyxcGU+abt6lWdQLS4sJMfXVnhWkC9xiWexweWTM3/DJZKdO0lrpakddM7kDm6bnuY13MbqvB4bjPt/dTn9p1LjCl/fZpPLfNU6l7WKgkuO0zvTWWrjo/ySWwtkrdpYUDNuiculK57O6CMdxQAArQY/XkHaawHACJGVAaAs+XOrVkn7Jz4FViHSW1DMcTO78T8EknmJoaYuhHhroW/QCZEJCnYhMkHBLkQmKNiFyAQFuxCZMNCCk61WExfPzyZtaw2epdZukyJ6LS6RWCCfoMnlicU1Pm+ZHHP2Is92qtfmqG1i5Ay1jY9yiWd8F5fziCKDZlA4Mir2WQ0KGDrJbAOAJpGaxkZ4ccsri3wdR3gdUBSB8dJcev1bQZukSrAe0XVaBnqet7nt6kJ6rYIp8CJ9LargpBBCwS5ELijYhcgEBbsQmaBgFyITFOxCZMJApTdvOxrLaXmlbVxnKEhW0MQUL44zMsXltet28Yyywrm0Mj83nxxfvMplrXaQ7bTa4jLJwjzP8tpZ8LWamEzLUM0ml5oi6a3W5tmDAD8mKumijU3WuA/guiFiH8sgPYwVelwNJLSo4KRVuCTaDApmtppc0q1V0897bJxLim0i81mQiag7uxCZoGAXIhMU7EJkgoJdiExQsAuRCQp2ITJhoNIb3OFMgggy2JiljCSjoJ9b6dx2w+ED1Hbr37opOX7xUlDMMci+a7W4ZHTxMi/02AaX+tYaaflnKehDVqtyOWk1yAIM2ooBREq1Ku8rVw30tZUV/pyrYz30bSt49p0HfdnawWtWDaTDeo3LeZUK94XBfIwKaerOLkQmKNiFyAQFuxCZoGAXIhMU7EJkgnm0fQfAzEYB/ADACDq7999x9983s5sAPAxgN4CnAHzKPcgiAWDVccf0LWljkJgA1q6pHXSFrQZJGkFyylSQJHPdwfROfW2MJyyMjqTbIAFALdihLYOlXGnyunazs5fSc5Z40k2jwa8B1poIACpBQk59JL0zXQ9q60W72VEiTxncs65eTbcIWyu575XAj1qtNwEreq3bTp5bEJqszdPSz59FubqYNG7mzr4G4EPufhs67ZnvNLP3A/gcgC+6+80A5gB8ehPHEkIMiQ2D3Tssdn+sdf85gA8B+E53/CEAH+uHg0KI7WGz/dkr3Q6u5wE8DuCnAObd/fXPw68BONQXD4UQ28Kmgt3dS3e/HcD1AO4A8M7NnsDMjpnZCTM7AQ960Aoh+so17ca7+zyAvwDwdwBMm9nruxXXAzhN5hx396PufhQ22G/nCiH+PxsGu5ntNbPp7uMxAB8B8AI6Qf8Pu792D4Dv98lHIcQ2sJlb7QEAD5lZBZ03h2+7+5+a2V8DeNjM/gOA/w3gqxsdaNeunfjoxz6StLVWea2zNkkmcZoiA7Q9aP8UJDoURNLonC9NJahZtm//PmrbvXs3te2a4RIgKlyWWyQtlJYWrn0OAJQlX8cogaNWJ3XVxngSUqQCLy7y+m7NoJYfa6HUDNo/Ofg1UK9x6bAIMoMigZvK32G5vvTaP/LQK3TOhsHu7s8AeG9i/CQ6f78LIX4B0DfohMgEBbsQmaBgFyITFOxCZIKCXYhM2DDrbVtPZnYBwM+7P+4BwAutDQ758Ubkxxv5RfPjRnffmzIMNNjfcGKzE+5+dCgnlx/yI0M/9DFeiExQsAuRCcMM9uNDPPd65McbkR9v5JfGj6H9zS6EGCz6GC9EJijYhciEoQS7md1pZi+a2ctmdv8wfOj6ccrMnjWzp83sxADP+6CZnTez59aNzZjZ42b2Uvf/XUPy4wEzO91dk6fN7K4B+HHYzP7CzP7azJ43s3/eHR/omgR+DHRNzGzUzH5kZj/p+vHvuuM3mdmT3bj5lpnx3OoU7j7QfwAq6NSwezuAOoCfADgyaD+6vpwCsGcI5/01AO8D8Ny6sf8E4P7u4/sBfG5IfjwA4F8OeD0OAHhf9/EOAP8HwJFBr0ngx0DXBIABmOw+rgF4EsD7AXwbwCe64/8VwD+7luMO485+B4CX3f2kd+rMPwzg7iH4MTTc/QcALr9p+G50qvQCA6rWS/wYOO5+1t1/3H28gE4lpEMY8JoEfgwU77DtFZ2HEeyHALy67udhVqZ1AH9uZk+Z2bEh+fA6+939bPfxOQD7h+jLvWb2TPdjft//nFiPmb0NnWIpT2KIa/ImP4ABr0k/KjrnvkH3AXd/H4DfAPC7ZvZrw3YI6LyzI65k1E++DOAd6DQEOQvg84M6sZlNAvgugPvc/ep62yDXJOHHwNfEt1DRmTGMYD8N4PC6n2ll2n7j7qe7/58H8D0Mt8zWrJkdAIDu/+eH4YS7z3YvtDaAr2BAa2JmNXQC7Ovu/kh3eOBrkvJjWGvSPfc8rrGiM2MYwf5XAG7p7izWAXwCwKODdsLMJsxsx+uPAXwUwHPxrL7yKDpVeoEhVut9Pbi6fBwDWBPrNC77KoAX3P0L60wDXRPmx6DXpG8VnQe1w/im3ca70Nnp/CmAfzMkH96OjhLwEwDPD9IPAN9E5+NgE52/vT6NToPMJwC8BOB/ApgZkh9/BOBZAM+gE2wHBuDHB9D5iP4MgKe7/+4a9JoEfgx0TQC8B52Kzc+g88byb9ddsz8C8DKAPwEwci3H1ddlhciE3DfohMgGBbsQmaBgFyITFOxCZIKCXYhMULALkQkKdiEy4f8CE20WyPa04P0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.data import Dataset\n",
    "\n",
    "# Creamos un Dataset utilizando numpys\n",
    "train_ds = Dataset.from_tensor_slices((X_train_cifar10, y_train_cifar10))\n",
    "val_ds = Dataset.from_tensor_slices((X_validation_cifar10, y_validation_cifar10))\n",
    "\n",
    "# Seleccionamos el batch_size que\n",
    "batch_size = 50\n",
    "\n",
    "# Creamos una función que perturbará de forma aleatoria las imágenes.\n",
    "# Las etiquetas quedan invariantes\n",
    "def processing_data(image, label):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, 0.2)\n",
    "    image = tf.image.random_contrast(image, 0.8, 1.2)\n",
    "    image = tf.image.random_saturation(image, 0.8, 1.2)\n",
    "    image = tf.image.random_hue(image, 0.05)\n",
    "    image = tf.image.resize(image, (40,40), method='nearest',antialias=False)\n",
    "    image = tf.image.random_crop(image, (32,32,3))\n",
    "    return image, label\n",
    "\n",
    "\n",
    "# Esta función hará las modificaciones pertinentes al dataset para poder usarlo durante el entrenamiento\n",
    "def data_aug(ds: Dataset, shuffle=False, augment=False):\n",
    "    # Hacemos que el dataset se repita de manera indefinida\n",
    "    ds = ds.repeat()\n",
    "\n",
    "    # Aleatorizamos el dataset usando un buffer de 5000\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(5000)\n",
    "\n",
    "    # Aplicamos las transformaciones pertinentes\n",
    "    if augment:\n",
    "        ds = ds.map(processing_data,num_parallel_calls=4)\n",
    "\n",
    "    # Hacemos que el dataset este formado por batches\n",
    "    ds = ds.batch(batch_size)\n",
    "\n",
    "    # Devolvemos el dataset precargándolo\n",
    "    return ds.prefetch(buffer_size=4)\n",
    "\n",
    "# Aplicamos la función data_aug a nuestro dataset\n",
    "train_ds = data_aug(train_ds, shuffle=True, augment=True)\n",
    "# Al dataset de validación no le aplicamos perturbaciones\n",
    "val_ds = data_aug(val_ds)\n",
    "\n",
    "\n",
    "# Visualizemos unos ejemplos de como la función processing_data modifica las imágenes\n",
    "plt.title(labels[int(y_train_cifar10[62])])\n",
    "plt.imshow(X_train_cifar10[62])\n",
    "plt.show()\n",
    "for _ in range(5):\n",
    "    image_mod = np.array(processing_data(X_train_cifar10[62], 0)[0])\n",
    "    plt.imshow(image_mod)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 32, 32, 25)        700       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 16, 16, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 16, 16, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 8, 8, 100)         45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1000)              1601000   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,668,110\n",
      "Trainable params: 1,668,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f553c15acb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f553c15acb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 996/1000 [============================>.] - ETA: 0s - loss: 1.5881 - accuracy: 0.4188WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f55af689f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f55af689f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.5868 - accuracy: 0.4192 - val_loss: 1.3272 - val_accuracy: 0.5155\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.2285 - accuracy: 0.5625 - val_loss: 1.0709 - val_accuracy: 0.6174\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.0715 - accuracy: 0.6186 - val_loss: 0.9657 - val_accuracy: 0.6597\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.9620 - accuracy: 0.6633 - val_loss: 0.9432 - val_accuracy: 0.6858\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.9059 - accuracy: 0.6837 - val_loss: 0.8422 - val_accuracy: 0.7092\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.8496 - accuracy: 0.7027 - val_loss: 0.8161 - val_accuracy: 0.7162\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.8095 - accuracy: 0.7175 - val_loss: 0.8393 - val_accuracy: 0.7138\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.7793 - accuracy: 0.7286 - val_loss: 0.8182 - val_accuracy: 0.7268\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.7479 - accuracy: 0.7386 - val_loss: 0.7531 - val_accuracy: 0.7447\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.7221 - accuracy: 0.7498 - val_loss: 0.7527 - val_accuracy: 0.7460\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.7008 - accuracy: 0.7560 - val_loss: 0.7616 - val_accuracy: 0.7464\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.6807 - accuracy: 0.7637 - val_loss: 0.7031 - val_accuracy: 0.7626\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.6490 - accuracy: 0.7736 - val_loss: 0.7394 - val_accuracy: 0.7583\n",
      "Epoch 14/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.6458 - accuracy: 0.7729 - val_loss: 0.6963 - val_accuracy: 0.7662\n",
      "Epoch 15/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.6219 - accuracy: 0.7841 - val_loss: 0.6931 - val_accuracy: 0.7682\n",
      "Epoch 16/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.6137 - accuracy: 0.7857 - val_loss: 0.6859 - val_accuracy: 0.7740\n",
      "Epoch 17/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5982 - accuracy: 0.7906 - val_loss: 0.6697 - val_accuracy: 0.7757\n",
      "Epoch 18/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5845 - accuracy: 0.7946 - val_loss: 0.7121 - val_accuracy: 0.7645\n",
      "Epoch 19/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5704 - accuracy: 0.8023 - val_loss: 0.6942 - val_accuracy: 0.7707\n",
      "Epoch 20/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5596 - accuracy: 0.8023 - val_loss: 0.6661 - val_accuracy: 0.7784\n",
      "Epoch 21/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5454 - accuracy: 0.8093 - val_loss: 0.7258 - val_accuracy: 0.7701\n",
      "Epoch 22/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5376 - accuracy: 0.8126 - val_loss: 0.7167 - val_accuracy: 0.7745\n",
      "Epoch 23/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5310 - accuracy: 0.8155 - val_loss: 0.6863 - val_accuracy: 0.7827\n",
      "Epoch 24/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5203 - accuracy: 0.8164 - val_loss: 0.7353 - val_accuracy: 0.7732\n",
      "Epoch 25/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5072 - accuracy: 0.8233 - val_loss: 0.6925 - val_accuracy: 0.7828\n",
      "Epoch 26/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5084 - accuracy: 0.8229 - val_loss: 0.7200 - val_accuracy: 0.7649\n",
      "Epoch 27/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.4942 - accuracy: 0.8275 - val_loss: 0.6810 - val_accuracy: 0.7821\n",
      "Epoch 28/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.4994 - accuracy: 0.8253 - val_loss: 0.6990 - val_accuracy: 0.7835\n",
      "Epoch 29/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.4779 - accuracy: 0.8311 - val_loss: 0.7054 - val_accuracy: 0.7790\n",
      "Epoch 30/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.4768 - accuracy: 0.8342 - val_loss: 0.7145 - val_accuracy: 0.7843\n"
     ]
    }
   ],
   "source": [
    "# capas de la red\n",
    "input = Input(shape=(32,32,3))\n",
    "layer = input\n",
    "layer = Conv2D(filters=25, kernel_size=3, strides=1, padding='same', activation='relu')(layer)\n",
    "layer = MaxPooling2D((2, 2))(layer)\n",
    "layer = Conv2D(filters=50, kernel_size=3, strides=1, padding='same', activation='relu')(layer)\n",
    "layer = MaxPooling2D((2, 2))(layer)\n",
    "layer = Conv2D(filters=100, kernel_size=3, strides=1, padding='same', activation='relu')(layer)\n",
    "layer = MaxPooling2D((2, 2))(layer)\n",
    "layer = Flatten()(layer)\n",
    "layer = Dense(units=1000, activation='relu')(layer)\n",
    "output = Dense(units=10, activation='softmax')(layer)\n",
    "\n",
    "# creamos el modelo\n",
    "model = Model(inputs=input, outputs=output)\n",
    "print(model.summary())\n",
    "\n",
    "# optimizador\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# función loss\n",
    "loss = SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "# métrica\n",
    "metrics = ['accuracy']\n",
    "\n",
    "# compilamos el modelo\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "# Usamos los dataset creados con tensorflow.data.Dataset para entrenar nuesto modelo\n",
    "history = model.fit(train_ds, batch_size=50, epochs=30,\n",
    "                    steps_per_epoch=1000, validation_data=val_ds, validation_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claramente se ha reducido el overfiting y hemos obtenido unos buenos resultados durante el entrenamiento.\n",
    "Hemos obtenido un score de 78.4%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Batch size correcto\n",
    "Con el Batch size modificamos:\n",
    "- La calidad de aprendizaje\n",
    "- La velocidad de aprendizaje\n",
    "- La duración del aprendizaje\n",
    "\n",
    "Por tanto es importante seleccionar un buen Batch Size para que el entrenamiento sea lo más eficiente posible.\n",
    "En muchas ocasiones el tamaño del Batch Size está limitado superiormente por la memoria de la GPU que estemos usando. En muchos modelos el Batch Size que podemos usar es menor a 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 32, 32, 25)        700       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 16, 16, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 16, 16, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 8, 8, 100)         45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1000)              1601000   \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,668,110\n",
      "Trainable params: 1,668,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2a5c524050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2a5c524050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "50000/50000 [==============================] - ETA: 0s - loss: 1.6037 - accuracy: 0.4114WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2a5c46fdd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2a5c46fdd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "50000/50000 [==============================] - 425s 8ms/step - loss: 1.6037 - accuracy: 0.4114 - val_loss: 1.4209 - val_accuracy: 0.4885\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 313s 6ms/step - loss: 1.3917 - accuracy: 0.5011 - val_loss: 1.3747 - val_accuracy: 0.5072\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 810s 16ms/step - loss: 1.3274 - accuracy: 0.5291 - val_loss: 1.4047 - val_accuracy: 0.5180\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 676s 14ms/step - loss: 1.2992 - accuracy: 0.5436 - val_loss: 1.2973 - val_accuracy: 0.5481\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 202s 4ms/step - loss: 1.2888 - accuracy: 0.5468 - val_loss: 1.2949 - val_accuracy: 0.5461\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 224s 4ms/step - loss: 1.2833 - accuracy: 0.5507 - val_loss: 1.3905 - val_accuracy: 0.5147\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 382s 8ms/step - loss: 1.2840 - accuracy: 0.5504 - val_loss: 1.3707 - val_accuracy: 0.5299\n",
      " 1/79 [..............................] - ETA: 0s - loss: 1.3004 - accuracy: 0.5391WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0064s). Check your callbacks.\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 1.2973 - accuracy: 0.5481\n",
      "Model: \"functional_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 32, 32, 25)        700       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 16, 16, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 16, 16, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 8, 8, 100)         45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1000)              1601000   \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,668,110\n",
      "Trainable params: 1,668,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2a5c2d2ef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2a5c2d2ef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "24993/25000 [============================>.] - ETA: 0s - loss: 1.4933 - accuracy: 0.4556WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2a5c217710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2a5c217710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "25000/25000 [==============================] - 221s 9ms/step - loss: 1.4933 - accuracy: 0.4556 - val_loss: 1.3726 - val_accuracy: 0.5138\n",
      "Epoch 2/30\n",
      "25000/25000 [==============================] - 268s 11ms/step - loss: 1.1988 - accuracy: 0.5738 - val_loss: 1.1924 - val_accuracy: 0.5821\n",
      "Epoch 3/30\n",
      "25000/25000 [==============================] - 161s 6ms/step - loss: 1.0998 - accuracy: 0.6118 - val_loss: 1.1801 - val_accuracy: 0.5899\n",
      "Epoch 4/30\n",
      "25000/25000 [==============================] - 150s 6ms/step - loss: 1.0325 - accuracy: 0.6401 - val_loss: 1.0998 - val_accuracy: 0.6206\n",
      "Epoch 5/30\n",
      "25000/25000 [==============================] - 248s 10ms/step - loss: 0.9763 - accuracy: 0.6560 - val_loss: 1.1414 - val_accuracy: 0.6133\n",
      "Epoch 6/30\n",
      "25000/25000 [==============================] - 237s 9ms/step - loss: 0.9366 - accuracy: 0.6730 - val_loss: 1.1574 - val_accuracy: 0.6159\n",
      "Epoch 7/30\n",
      "25000/25000 [==============================] - 236s 9ms/step - loss: 0.9092 - accuracy: 0.6845 - val_loss: 1.2030 - val_accuracy: 0.6111\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0998 - accuracy: 0.6206\n",
      "Model: \"functional_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 32, 32, 25)        700       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 16, 16, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 16, 16, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_64 (Conv2D)           (None, 8, 8, 100)         45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1000)              1601000   \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,668,110\n",
      "Trainable params: 1,668,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2a5c132170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2a5c132170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "16666/16667 [============================>.] - ETA: 0s - loss: 1.4452 - accuracy: 0.4777WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2a3c7be830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2a3c7be830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "16667/16667 [==============================] - 173s 10ms/step - loss: 1.4453 - accuracy: 0.4777 - val_loss: 1.2460 - val_accuracy: 0.5621\n",
      "Epoch 2/30\n",
      "16667/16667 [==============================] - 177s 11ms/step - loss: 1.1016 - accuracy: 0.6120 - val_loss: 1.1504 - val_accuracy: 0.6058\n",
      "Epoch 3/30\n",
      "16667/16667 [==============================] - 58s 3ms/step - loss: 0.9719 - accuracy: 0.6594 - val_loss: 1.0209 - val_accuracy: 0.6457\n",
      "Epoch 4/30\n",
      "16667/16667 [==============================] - 39s 2ms/step - loss: 0.8839 - accuracy: 0.6932 - val_loss: 1.0319 - val_accuracy: 0.6516\n",
      "Epoch 5/30\n",
      "16667/16667 [==============================] - 40s 2ms/step - loss: 0.8122 - accuracy: 0.7195 - val_loss: 1.0446 - val_accuracy: 0.6521\n",
      "Epoch 6/30\n",
      "16667/16667 [==============================] - 30s 2ms/step - loss: 0.7462 - accuracy: 0.7430 - val_loss: 1.1313 - val_accuracy: 0.6577\n",
      "Epoch 7/30\n",
      "16667/16667 [==============================] - 36s 2ms/step - loss: 0.6924 - accuracy: 0.7618 - val_loss: 1.0964 - val_accuracy: 0.6513\n",
      "Epoch 8/30\n",
      "16667/16667 [==============================] - 37s 2ms/step - loss: 0.6428 - accuracy: 0.7804 - val_loss: 1.2316 - val_accuracy: 0.6600\n",
      "Epoch 9/30\n",
      "16667/16667 [==============================] - 35s 2ms/step - loss: 0.5924 - accuracy: 0.7997 - val_loss: 1.3788 - val_accuracy: 0.6455\n",
      "Epoch 10/30\n",
      "16667/16667 [==============================] - 36s 2ms/step - loss: 0.5614 - accuracy: 0.8104 - val_loss: 1.3581 - val_accuracy: 0.6464\n",
      "Epoch 11/30\n",
      "16667/16667 [==============================] - 40s 2ms/step - loss: 0.5216 - accuracy: 0.8264 - val_loss: 1.5941 - val_accuracy: 0.6460\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.2316 - accuracy: 0.6600\n",
      "Model: \"functional_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_65 (Conv2D)           (None, 32, 32, 25)        700       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling (None, 16, 16, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_66 (Conv2D)           (None, 16, 16, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_67 (Conv2D)           (None, 8, 8, 100)         45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1000)              1601000   \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,668,110\n",
      "Trainable params: 1,668,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2a3c6df170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2a3c6df170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "12476/12500 [============================>.] - ETA: 0s - loss: 1.3907 - accuracy: 0.4960WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2bba067200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2bba067200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "12500/12500 [==============================] - 26s 2ms/step - loss: 1.3904 - accuracy: 0.4962 - val_loss: 1.1230 - val_accuracy: 0.5918\n",
      "Epoch 2/30\n",
      "12500/12500 [==============================] - 26s 2ms/step - loss: 1.0324 - accuracy: 0.6365 - val_loss: 1.1170 - val_accuracy: 0.6074\n",
      "Epoch 3/30\n",
      "12500/12500 [==============================] - 31s 2ms/step - loss: 0.8838 - accuracy: 0.6903 - val_loss: 1.0015 - val_accuracy: 0.6547\n",
      "Epoch 4/30\n",
      "12500/12500 [==============================] - 32s 3ms/step - loss: 0.7923 - accuracy: 0.7244 - val_loss: 0.9659 - val_accuracy: 0.6771\n",
      "Epoch 5/30\n",
      "12500/12500 [==============================] - 30s 2ms/step - loss: 0.7067 - accuracy: 0.7543 - val_loss: 0.9914 - val_accuracy: 0.6804\n",
      "Epoch 6/30\n",
      "12500/12500 [==============================] - 29s 2ms/step - loss: 0.6366 - accuracy: 0.7794 - val_loss: 1.0346 - val_accuracy: 0.6860\n",
      "Epoch 7/30\n",
      "12500/12500 [==============================] - 27s 2ms/step - loss: 0.5721 - accuracy: 0.8049 - val_loss: 1.0874 - val_accuracy: 0.6857\n",
      "Epoch 8/30\n",
      "12500/12500 [==============================] - 27s 2ms/step - loss: 0.5199 - accuracy: 0.8229 - val_loss: 1.3171 - val_accuracy: 0.6674\n",
      "Epoch 9/30\n",
      "12500/12500 [==============================] - 27s 2ms/step - loss: 0.4805 - accuracy: 0.8374 - val_loss: 1.4797 - val_accuracy: 0.6524\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.0346 - accuracy: 0.6860\n",
      "Model: \"functional_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_68 (Conv2D)           (None, 32, 32, 25)        700       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_48 (MaxPooling (None, 16, 16, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_69 (Conv2D)           (None, 16, 16, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_70 (Conv2D)           (None, 8, 8, 100)         45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1000)              1601000   \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,668,110\n",
      "Trainable params: 1,668,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2bd2923ef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2bd2923ef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 9994/10000 [============================>.] - ETA: 0s - loss: 1.3399 - accuracy: 0.5168WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2ab05b8950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2ab05b8950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 1.3396 - accuracy: 0.5168 - val_loss: 1.0741 - val_accuracy: 0.6264\n",
      "Epoch 2/30\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 0.9828 - accuracy: 0.6514 - val_loss: 1.0026 - val_accuracy: 0.6597\n",
      "Epoch 3/30\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 0.8377 - accuracy: 0.7062 - val_loss: 0.9336 - val_accuracy: 0.6812\n",
      "Epoch 4/30\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 0.7333 - accuracy: 0.7447 - val_loss: 0.9277 - val_accuracy: 0.6834\n",
      "Epoch 5/30\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 0.6425 - accuracy: 0.7760 - val_loss: 0.9733 - val_accuracy: 0.6907\n",
      "Epoch 6/30\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 0.5563 - accuracy: 0.8069 - val_loss: 0.9756 - val_accuracy: 0.7013\n",
      "Epoch 7/30\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 0.4895 - accuracy: 0.8307 - val_loss: 1.1729 - val_accuracy: 0.6715\n",
      "Epoch 8/30\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 0.4337 - accuracy: 0.8500 - val_loss: 1.3095 - val_accuracy: 0.6665\n",
      "Epoch 9/30\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 0.3849 - accuracy: 0.8700 - val_loss: 1.3021 - val_accuracy: 0.6700\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.9756 - accuracy: 0.7013\n",
      "Model: \"functional_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_71 (Conv2D)           (None, 32, 32, 25)        700       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 16, 16, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_72 (Conv2D)           (None, 16, 16, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_52 (MaxPooling (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_73 (Conv2D)           (None, 8, 8, 100)         45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_53 (MaxPooling (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1000)              1601000   \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,668,110\n",
      "Trainable params: 1,668,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2a5c217950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2a5c217950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "8317/8334 [============================>.] - ETA: 0s - loss: 1.3567 - accuracy: 0.5107WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2bd2823320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2bd2823320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "8334/8334 [==============================] - 19s 2ms/step - loss: 1.3564 - accuracy: 0.5109 - val_loss: 1.0736 - val_accuracy: 0.6216\n",
      "Epoch 2/30\n",
      "8334/8334 [==============================] - 17s 2ms/step - loss: 0.9637 - accuracy: 0.6594 - val_loss: 0.9270 - val_accuracy: 0.6784\n",
      "Epoch 3/30\n",
      "8334/8334 [==============================] - 17s 2ms/step - loss: 0.8007 - accuracy: 0.7185 - val_loss: 0.8914 - val_accuracy: 0.6924\n",
      "Epoch 4/30\n",
      "8334/8334 [==============================] - 18s 2ms/step - loss: 0.6832 - accuracy: 0.7609 - val_loss: 0.8950 - val_accuracy: 0.7053\n",
      "Epoch 5/30\n",
      "8334/8334 [==============================] - 18s 2ms/step - loss: 0.5777 - accuracy: 0.7975 - val_loss: 1.0033 - val_accuracy: 0.6852\n",
      "Epoch 6/30\n",
      "8334/8334 [==============================] - 18s 2ms/step - loss: 0.4895 - accuracy: 0.8291 - val_loss: 1.0159 - val_accuracy: 0.7045\n",
      "Epoch 7/30\n",
      "8334/8334 [==============================] - 18s 2ms/step - loss: 0.4084 - accuracy: 0.8595 - val_loss: 1.1394 - val_accuracy: 0.6975\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.8950 - accuracy: 0.7053\n",
      "Model: \"functional_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_74 (Conv2D)           (None, 32, 32, 25)        700       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_54 (MaxPooling (None, 16, 16, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_75 (Conv2D)           (None, 16, 16, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_55 (MaxPooling (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_76 (Conv2D)           (None, 8, 8, 100)         45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_56 (MaxPooling (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1000)              1601000   \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,668,110\n",
      "Trainable params: 1,668,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2bba3e6710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2bba3e6710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "7117/7143 [============================>.] - ETA: 0s - loss: 1.3302 - accuracy: 0.5213WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2ab0153f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2ab0153f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "7143/7143 [==============================] - 16s 2ms/step - loss: 1.3288 - accuracy: 0.5219 - val_loss: 1.0478 - val_accuracy: 0.6254\n",
      "Epoch 2/30\n",
      "7143/7143 [==============================] - 15s 2ms/step - loss: 0.9417 - accuracy: 0.6705 - val_loss: 0.9184 - val_accuracy: 0.6807\n",
      "Epoch 3/30\n",
      "7143/7143 [==============================] - 16s 2ms/step - loss: 0.7822 - accuracy: 0.7244 - val_loss: 0.8694 - val_accuracy: 0.7065\n",
      "Epoch 4/30\n",
      "7143/7143 [==============================] - 16s 2ms/step - loss: 0.6579 - accuracy: 0.7691 - val_loss: 0.8629 - val_accuracy: 0.7090\n",
      "Epoch 5/30\n",
      "7143/7143 [==============================] - 16s 2ms/step - loss: 0.5486 - accuracy: 0.8075 - val_loss: 0.9634 - val_accuracy: 0.6998\n",
      "Epoch 6/30\n",
      "7143/7143 [==============================] - 15s 2ms/step - loss: 0.4555 - accuracy: 0.8397 - val_loss: 1.0151 - val_accuracy: 0.6995\n",
      "Epoch 7/30\n",
      "7143/7143 [==============================] - 14s 2ms/step - loss: 0.3755 - accuracy: 0.8688 - val_loss: 1.1358 - val_accuracy: 0.7024\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.8629 - accuracy: 0.7090\n",
      "Model: \"functional_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_77 (Conv2D)           (None, 32, 32, 25)        700       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_57 (MaxPooling (None, 16, 16, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_78 (Conv2D)           (None, 16, 16, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_58 (MaxPooling (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_79 (Conv2D)           (None, 8, 8, 100)         45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_59 (MaxPooling (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 1000)              1601000   \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,668,110\n",
      "Trainable params: 1,668,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2abc08f680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2abc08f680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "6246/6250 [============================>.] - ETA: 0s - loss: 1.3578 - accuracy: 0.5070WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2bba3f88c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2bba3f88c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "6250/6250 [==============================] - 12s 2ms/step - loss: 1.3576 - accuracy: 0.5070 - val_loss: 1.1433 - val_accuracy: 0.5966\n",
      "Epoch 2/30\n",
      "6250/6250 [==============================] - 11s 2ms/step - loss: 0.9741 - accuracy: 0.6560 - val_loss: 1.0082 - val_accuracy: 0.6550\n",
      "Epoch 3/30\n",
      "6250/6250 [==============================] - 11s 2ms/step - loss: 0.8099 - accuracy: 0.7151 - val_loss: 0.8935 - val_accuracy: 0.6943\n",
      "Epoch 4/30\n",
      "6250/6250 [==============================] - 11s 2ms/step - loss: 0.6878 - accuracy: 0.7584 - val_loss: 0.9109 - val_accuracy: 0.6901\n",
      "Epoch 5/30\n",
      "6250/6250 [==============================] - 11s 2ms/step - loss: 0.5784 - accuracy: 0.7962 - val_loss: 0.9016 - val_accuracy: 0.7124\n",
      "Epoch 6/30\n",
      "6250/6250 [==============================] - 11s 2ms/step - loss: 0.4825 - accuracy: 0.8291 - val_loss: 0.9926 - val_accuracy: 0.7097\n",
      "Epoch 7/30\n",
      "6250/6250 [==============================] - 11s 2ms/step - loss: 0.3907 - accuracy: 0.8626 - val_loss: 1.0849 - val_accuracy: 0.7089\n",
      "Epoch 8/30\n",
      "6250/6250 [==============================] - 11s 2ms/step - loss: 0.3334 - accuracy: 0.8846 - val_loss: 1.1948 - val_accuracy: 0.7061\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.9016 - accuracy: 0.7124\n",
      "Model: \"functional_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_80 (Conv2D)           (None, 32, 32, 25)        700       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_60 (MaxPooling (None, 16, 16, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_81 (Conv2D)           (None, 16, 16, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_61 (MaxPooling (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_82 (Conv2D)           (None, 8, 8, 100)         45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_62 (MaxPooling (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1000)              1601000   \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,668,110\n",
      "Trainable params: 1,668,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2a3c7be710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2a3c7be710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5551/5556 [============================>.] - ETA: 0s - loss: 1.3184 - accuracy: 0.5230WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2a5c723dd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2a5c723dd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5556/5556 [==============================] - 11s 2ms/step - loss: 1.3180 - accuracy: 0.5231 - val_loss: 1.0897 - val_accuracy: 0.6121\n",
      "Epoch 2/30\n",
      "5556/5556 [==============================] - 11s 2ms/step - loss: 0.9291 - accuracy: 0.6737 - val_loss: 0.9531 - val_accuracy: 0.6749\n",
      "Epoch 3/30\n",
      "5556/5556 [==============================] - 11s 2ms/step - loss: 0.7609 - accuracy: 0.7322 - val_loss: 0.9037 - val_accuracy: 0.7005\n",
      "Epoch 4/30\n",
      "5556/5556 [==============================] - 11s 2ms/step - loss: 0.6304 - accuracy: 0.7773 - val_loss: 0.8534 - val_accuracy: 0.7214\n",
      "Epoch 5/30\n",
      "5556/5556 [==============================] - 11s 2ms/step - loss: 0.5033 - accuracy: 0.8218 - val_loss: 0.9374 - val_accuracy: 0.7161\n",
      "Epoch 6/30\n",
      "5556/5556 [==============================] - 11s 2ms/step - loss: 0.4015 - accuracy: 0.8592 - val_loss: 0.9586 - val_accuracy: 0.7282\n",
      "Epoch 7/30\n",
      "5556/5556 [==============================] - 11s 2ms/step - loss: 0.3189 - accuracy: 0.8887 - val_loss: 1.1396 - val_accuracy: 0.7140\n",
      "Epoch 8/30\n",
      "5556/5556 [==============================] - 11s 2ms/step - loss: 0.2666 - accuracy: 0.9063 - val_loss: 1.4073 - val_accuracy: 0.7045\n",
      "Epoch 9/30\n",
      "5556/5556 [==============================] - 11s 2ms/step - loss: 0.2263 - accuracy: 0.9237 - val_loss: 1.5100 - val_accuracy: 0.7040\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.9586 - accuracy: 0.7282\n",
      "Model: \"functional_43\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_22 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_83 (Conv2D)           (None, 32, 32, 25)        700       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_63 (MaxPooling (None, 16, 16, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_84 (Conv2D)           (None, 16, 16, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_64 (MaxPooling (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_85 (Conv2D)           (None, 8, 8, 100)         45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_65 (MaxPooling (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1000)              1601000   \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,668,110\n",
      "Trainable params: 1,668,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2a5c2430e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2a5c2430e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "4970/5000 [============================>.] - ETA: 0s - loss: 1.3205 - accuracy: 0.5225WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2bba4acf80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2bba4acf80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 1.3180 - accuracy: 0.5234 - val_loss: 1.0502 - val_accuracy: 0.6302\n",
      "Epoch 2/30\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 0.9345 - accuracy: 0.6700 - val_loss: 1.1210 - val_accuracy: 0.6227\n",
      "Epoch 3/30\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 0.7680 - accuracy: 0.7320 - val_loss: 0.8702 - val_accuracy: 0.7049\n",
      "Epoch 4/30\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 0.6408 - accuracy: 0.7734 - val_loss: 0.8664 - val_accuracy: 0.7057\n",
      "Epoch 5/30\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 0.5244 - accuracy: 0.8152 - val_loss: 0.9670 - val_accuracy: 0.6992\n",
      "Epoch 6/30\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 0.4206 - accuracy: 0.8508 - val_loss: 0.9996 - val_accuracy: 0.7175\n",
      "Epoch 7/30\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 0.3399 - accuracy: 0.8821 - val_loss: 1.0815 - val_accuracy: 0.7165\n",
      "Epoch 8/30\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 0.2845 - accuracy: 0.9016 - val_loss: 1.2080 - val_accuracy: 0.7092\n",
      "Epoch 9/30\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 0.2408 - accuracy: 0.9176 - val_loss: 1.3753 - val_accuracy: 0.7004\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.9996 - accuracy: 0.7175\n",
      "Model: \"functional_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_23 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_86 (Conv2D)           (None, 32, 32, 25)        700       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_66 (MaxPooling (None, 16, 16, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_87 (Conv2D)           (None, 16, 16, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_67 (MaxPooling (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_88 (Conv2D)           (None, 8, 8, 100)         45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_68 (MaxPooling (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 1000)              1601000   \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,668,110\n",
      "Trainable params: 1,668,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2bba4ac4d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2bba4ac4d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "4527/4546 [============================>.] - ETA: 0s - loss: 1.3649 - accuracy: 0.5064WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2bba353830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2bba353830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "4546/4546 [==============================] - 9s 2ms/step - loss: 1.3638 - accuracy: 0.5068 - val_loss: 1.1341 - val_accuracy: 0.5876\n",
      "Epoch 2/30\n",
      "4546/4546 [==============================] - 9s 2ms/step - loss: 0.9542 - accuracy: 0.6622 - val_loss: 0.9064 - val_accuracy: 0.6809\n",
      "Epoch 3/30\n",
      "4546/4546 [==============================] - 9s 2ms/step - loss: 0.7825 - accuracy: 0.7259 - val_loss: 0.8543 - val_accuracy: 0.7051\n",
      "Epoch 4/30\n",
      "4546/4546 [==============================] - 10s 2ms/step - loss: 0.6535 - accuracy: 0.7677 - val_loss: 0.8743 - val_accuracy: 0.7010\n",
      "Epoch 5/30\n",
      "4546/4546 [==============================] - 9s 2ms/step - loss: 0.5428 - accuracy: 0.8088 - val_loss: 0.8594 - val_accuracy: 0.7161\n",
      "Epoch 6/30\n",
      "4546/4546 [==============================] - 9s 2ms/step - loss: 0.4367 - accuracy: 0.8441 - val_loss: 0.9655 - val_accuracy: 0.7148\n",
      "Epoch 7/30\n",
      "4546/4546 [==============================] - 9s 2ms/step - loss: 0.3462 - accuracy: 0.8770 - val_loss: 1.0575 - val_accuracy: 0.7130\n",
      "Epoch 8/30\n",
      "4546/4546 [==============================] - 9s 2ms/step - loss: 0.2799 - accuracy: 0.9032 - val_loss: 1.1365 - val_accuracy: 0.7177\n",
      "Epoch 9/30\n",
      "4546/4546 [==============================] - 9s 2ms/step - loss: 0.2393 - accuracy: 0.9169 - val_loss: 1.3528 - val_accuracy: 0.7119\n",
      "Epoch 10/30\n",
      "4546/4546 [==============================] - 9s 2ms/step - loss: 0.2121 - accuracy: 0.9273 - val_loss: 1.5073 - val_accuracy: 0.7045\n",
      "Epoch 11/30\n",
      "4546/4546 [==============================] - 9s 2ms/step - loss: 0.1866 - accuracy: 0.9362 - val_loss: 1.5744 - val_accuracy: 0.7060\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.1365 - accuracy: 0.7177\n",
      "Model: \"functional_47\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_24 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_89 (Conv2D)           (None, 32, 32, 25)        700       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_69 (MaxPooling (None, 16, 16, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_90 (Conv2D)           (None, 16, 16, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_70 (MaxPooling (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_91 (Conv2D)           (None, 8, 8, 100)         45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_71 (MaxPooling (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 1000)              1601000   \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,668,110\n",
      "Trainable params: 1,668,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2bba4b9290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2bba4b9290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "4152/4167 [============================>.] - ETA: 0s - loss: 1.3150 - accuracy: 0.5247WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2ab03e49e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2ab03e49e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "4167/4167 [==============================] - 9s 2ms/step - loss: 1.3137 - accuracy: 0.5252 - val_loss: 1.0396 - val_accuracy: 0.6330\n",
      "Epoch 2/30\n",
      "4167/4167 [==============================] - 9s 2ms/step - loss: 0.9034 - accuracy: 0.6821 - val_loss: 0.8939 - val_accuracy: 0.6950\n",
      "Epoch 3/30\n",
      "4167/4167 [==============================] - 9s 2ms/step - loss: 0.7242 - accuracy: 0.7453 - val_loss: 0.8569 - val_accuracy: 0.7044\n",
      "Epoch 4/30\n",
      "4167/4167 [==============================] - 9s 2ms/step - loss: 0.5925 - accuracy: 0.7918 - val_loss: 0.8844 - val_accuracy: 0.7067\n",
      "Epoch 5/30\n",
      "4167/4167 [==============================] - 9s 2ms/step - loss: 0.4703 - accuracy: 0.8340 - val_loss: 0.8765 - val_accuracy: 0.7260\n",
      "Epoch 6/30\n",
      "4167/4167 [==============================] - 9s 2ms/step - loss: 0.3682 - accuracy: 0.8699 - val_loss: 0.9792 - val_accuracy: 0.7231\n",
      "Epoch 7/30\n",
      "4167/4167 [==============================] - 9s 2ms/step - loss: 0.2831 - accuracy: 0.9011 - val_loss: 1.1457 - val_accuracy: 0.7280\n",
      "Epoch 8/30\n",
      "4167/4167 [==============================] - 9s 2ms/step - loss: 0.2341 - accuracy: 0.9196 - val_loss: 1.2710 - val_accuracy: 0.7230\n",
      "Epoch 9/30\n",
      "4167/4167 [==============================] - 9s 2ms/step - loss: 0.2065 - accuracy: 0.9292 - val_loss: 1.3911 - val_accuracy: 0.7160\n",
      "Epoch 10/30\n",
      "4167/4167 [==============================] - 9s 2ms/step - loss: 0.1781 - accuracy: 0.9400 - val_loss: 1.6981 - val_accuracy: 0.7008\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.1457 - accuracy: 0.7280\n",
      "Model: \"functional_49\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_25 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_92 (Conv2D)           (None, 32, 32, 25)        700       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_72 (MaxPooling (None, 16, 16, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_93 (Conv2D)           (None, 16, 16, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_73 (MaxPooling (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_94 (Conv2D)           (None, 8, 8, 100)         45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_74 (MaxPooling (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_24 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1000)              1601000   \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,668,110\n",
      "Trainable params: 1,668,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2bba4ac200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2bba4ac200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "3830/3847 [============================>.] - ETA: 0s - loss: 1.3087 - accuracy: 0.5268WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2ab0773710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2ab0773710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "3847/3847 [==============================] - 8s 2ms/step - loss: 1.3071 - accuracy: 0.5275 - val_loss: 1.0478 - val_accuracy: 0.6311\n",
      "Epoch 2/30\n",
      "3847/3847 [==============================] - 8s 2ms/step - loss: 0.8909 - accuracy: 0.6880 - val_loss: 0.8819 - val_accuracy: 0.6946\n",
      "Epoch 3/30\n",
      "3847/3847 [==============================] - 8s 2ms/step - loss: 0.7208 - accuracy: 0.7461 - val_loss: 0.8038 - val_accuracy: 0.7226\n",
      "Epoch 4/30\n",
      "3847/3847 [==============================] - 8s 2ms/step - loss: 0.5870 - accuracy: 0.7933 - val_loss: 0.8056 - val_accuracy: 0.7326\n",
      "Epoch 5/30\n",
      "3847/3847 [==============================] - 8s 2ms/step - loss: 0.4651 - accuracy: 0.8361 - val_loss: 0.8761 - val_accuracy: 0.7309\n",
      "Epoch 6/30\n",
      "3847/3847 [==============================] - 8s 2ms/step - loss: 0.3593 - accuracy: 0.8739 - val_loss: 0.9354 - val_accuracy: 0.7283\n",
      "Epoch 7/30\n",
      "3847/3847 [==============================] - 8s 2ms/step - loss: 0.2740 - accuracy: 0.9038 - val_loss: 1.0843 - val_accuracy: 0.7233\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.8056 - accuracy: 0.7326\n",
      "Model: \"functional_51\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_26 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 32, 32, 25)        700       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_75 (MaxPooling (None, 16, 16, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_96 (Conv2D)           (None, 16, 16, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_76 (MaxPooling (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_97 (Conv2D)           (None, 8, 8, 100)         45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_77 (MaxPooling (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_25 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 1000)              1601000   \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,668,110\n",
      "Trainable params: 1,668,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2ab028c950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2ab028c950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "3563/3572 [============================>.] - ETA: 0s - loss: 1.3330 - accuracy: 0.5201WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2bd287b050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2bd287b050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "3572/3572 [==============================] - 8s 2ms/step - loss: 1.3324 - accuracy: 0.5203 - val_loss: 1.0160 - val_accuracy: 0.6411\n",
      "Epoch 2/30\n",
      "3572/3572 [==============================] - 8s 2ms/step - loss: 0.9218 - accuracy: 0.6761 - val_loss: 0.9041 - val_accuracy: 0.6821\n",
      "Epoch 3/30\n",
      "3572/3572 [==============================] - 8s 2ms/step - loss: 0.7475 - accuracy: 0.7375 - val_loss: 0.8646 - val_accuracy: 0.6957\n",
      "Epoch 4/30\n",
      "3572/3572 [==============================] - 8s 2ms/step - loss: 0.6053 - accuracy: 0.7881 - val_loss: 0.8482 - val_accuracy: 0.7103\n",
      "Epoch 5/30\n",
      "3572/3572 [==============================] - 8s 2ms/step - loss: 0.4702 - accuracy: 0.8334 - val_loss: 0.9232 - val_accuracy: 0.7143\n",
      "Epoch 6/30\n",
      "3572/3572 [==============================] - 8s 2ms/step - loss: 0.3538 - accuracy: 0.8756 - val_loss: 1.0124 - val_accuracy: 0.7155\n",
      "Epoch 7/30\n",
      "3572/3572 [==============================] - 8s 2ms/step - loss: 0.2693 - accuracy: 0.9053 - val_loss: 1.1370 - val_accuracy: 0.7160\n",
      "Epoch 8/30\n",
      "3572/3572 [==============================] - 8s 2ms/step - loss: 0.2161 - accuracy: 0.9251 - val_loss: 1.3011 - val_accuracy: 0.7084\n",
      "Epoch 9/30\n",
      "3572/3572 [==============================] - 8s 2ms/step - loss: 0.1813 - accuracy: 0.9381 - val_loss: 1.4676 - val_accuracy: 0.7097\n",
      "Epoch 10/30\n",
      "3572/3572 [==============================] - 8s 2ms/step - loss: 0.1633 - accuracy: 0.9434 - val_loss: 1.4965 - val_accuracy: 0.7080\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.1370 - accuracy: 0.7160\n",
      "Model: \"functional_53\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_27 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_98 (Conv2D)           (None, 32, 32, 25)        700       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_78 (MaxPooling (None, 16, 16, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_99 (Conv2D)           (None, 16, 16, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_79 (MaxPooling (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_100 (Conv2D)          (None, 8, 8, 100)         45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_80 (MaxPooling (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_26 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 1000)              1601000   \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,668,110\n",
      "Trainable params: 1,668,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2bd29274d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2bd29274d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "3330/3334 [============================>.] - ETA: 0s - loss: 1.3529 - accuracy: 0.5110WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2bd2b02200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2bd2b02200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "3334/3334 [==============================] - 7s 2ms/step - loss: 1.3531 - accuracy: 0.5110 - val_loss: 1.1059 - val_accuracy: 0.6101\n",
      "Epoch 2/30\n",
      "3334/3334 [==============================] - 7s 2ms/step - loss: 0.9442 - accuracy: 0.6680 - val_loss: 0.9500 - val_accuracy: 0.6663\n",
      "Epoch 3/30\n",
      "3334/3334 [==============================] - 7s 2ms/step - loss: 0.7679 - accuracy: 0.7298 - val_loss: 0.8289 - val_accuracy: 0.7085\n",
      "Epoch 4/30\n",
      "3334/3334 [==============================] - 7s 2ms/step - loss: 0.6241 - accuracy: 0.7810 - val_loss: 0.8899 - val_accuracy: 0.7036\n",
      "Epoch 5/30\n",
      "3334/3334 [==============================] - 7s 2ms/step - loss: 0.5056 - accuracy: 0.8237 - val_loss: 0.8617 - val_accuracy: 0.7117\n",
      "Epoch 6/30\n",
      "3334/3334 [==============================] - 7s 2ms/step - loss: 0.3946 - accuracy: 0.8609 - val_loss: 0.9385 - val_accuracy: 0.7274\n",
      "Epoch 7/30\n",
      "3334/3334 [==============================] - 7s 2ms/step - loss: 0.3032 - accuracy: 0.8913 - val_loss: 1.0178 - val_accuracy: 0.7222\n",
      "Epoch 8/30\n",
      "3334/3334 [==============================] - 7s 2ms/step - loss: 0.2395 - accuracy: 0.9163 - val_loss: 1.1866 - val_accuracy: 0.7183\n",
      "Epoch 9/30\n",
      "3334/3334 [==============================] - 7s 2ms/step - loss: 0.2022 - accuracy: 0.9296 - val_loss: 1.3978 - val_accuracy: 0.7116\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.9385 - accuracy: 0.7274\n",
      "Model: \"functional_55\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_28 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_101 (Conv2D)          (None, 32, 32, 25)        700       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_81 (MaxPooling (None, 16, 16, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_102 (Conv2D)          (None, 16, 16, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_82 (MaxPooling (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_103 (Conv2D)          (None, 8, 8, 100)         45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_83 (MaxPooling (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_27 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 1000)              1601000   \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,668,110\n",
      "Trainable params: 1,668,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2ab00cf050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2ab00cf050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "3117/3125 [============================>.] - ETA: 0s - loss: 1.3185 - accuracy: 0.5245WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2a5c737a70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2a5c737a70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 1.3185 - accuracy: 0.5245 - val_loss: 1.1613 - val_accuracy: 0.5979\n",
      "Epoch 2/30\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.9045 - accuracy: 0.6817 - val_loss: 0.8644 - val_accuracy: 0.6995\n",
      "Epoch 3/30\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.7156 - accuracy: 0.7481 - val_loss: 0.8546 - val_accuracy: 0.7091\n",
      "Epoch 4/30\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.5774 - accuracy: 0.7981 - val_loss: 0.7925 - val_accuracy: 0.7398\n",
      "Epoch 5/30\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.4464 - accuracy: 0.8427 - val_loss: 0.7994 - val_accuracy: 0.7459\n",
      "Epoch 6/30\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.3330 - accuracy: 0.8820 - val_loss: 0.8961 - val_accuracy: 0.7433\n",
      "Epoch 7/30\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.2478 - accuracy: 0.9123 - val_loss: 1.1010 - val_accuracy: 0.7282\n",
      "Epoch 8/30\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.2036 - accuracy: 0.9285 - val_loss: 1.1709 - val_accuracy: 0.7266\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.7994 - accuracy: 0.7459\n",
      "Model: \"functional_57\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_29 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_104 (Conv2D)          (None, 32, 32, 25)        700       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_84 (MaxPooling (None, 16, 16, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_105 (Conv2D)          (None, 16, 16, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_85 (MaxPooling (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_106 (Conv2D)          (None, 8, 8, 100)         45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_86 (MaxPooling (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_28 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 1000)              1601000   \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,668,110\n",
      "Trainable params: 1,668,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2a3c75e4d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2a3c75e4d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2941/2942 [============================>.] - ETA: 0s - loss: 1.3333 - accuracy: 0.5177WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2a5c7bf560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2a5c7bf560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2942/2942 [==============================] - 7s 2ms/step - loss: 1.3333 - accuracy: 0.5177 - val_loss: 1.0430 - val_accuracy: 0.6373\n",
      "Epoch 2/30\n",
      "2942/2942 [==============================] - 7s 2ms/step - loss: 0.9059 - accuracy: 0.6794 - val_loss: 0.9010 - val_accuracy: 0.6848\n",
      "Epoch 3/30\n",
      "2942/2942 [==============================] - 6s 2ms/step - loss: 0.7215 - accuracy: 0.7464 - val_loss: 0.8580 - val_accuracy: 0.7034\n",
      "Epoch 4/30\n",
      "2942/2942 [==============================] - 6s 2ms/step - loss: 0.5802 - accuracy: 0.7957 - val_loss: 0.8667 - val_accuracy: 0.7153\n",
      "Epoch 5/30\n",
      "2942/2942 [==============================] - 7s 2ms/step - loss: 0.4463 - accuracy: 0.8423 - val_loss: 0.9088 - val_accuracy: 0.7230\n",
      "Epoch 6/30\n",
      "2942/2942 [==============================] - 6s 2ms/step - loss: 0.3323 - accuracy: 0.8816 - val_loss: 0.9650 - val_accuracy: 0.7299\n",
      "Epoch 7/30\n",
      "2942/2942 [==============================] - 6s 2ms/step - loss: 0.2507 - accuracy: 0.9118 - val_loss: 1.0586 - val_accuracy: 0.7290\n",
      "Epoch 8/30\n",
      "2942/2942 [==============================] - 6s 2ms/step - loss: 0.1965 - accuracy: 0.9318 - val_loss: 1.1534 - val_accuracy: 0.7374\n",
      "Epoch 9/30\n",
      "2942/2942 [==============================] - 6s 2ms/step - loss: 0.1643 - accuracy: 0.9426 - val_loss: 1.2851 - val_accuracy: 0.7328\n",
      "Epoch 10/30\n",
      "2942/2942 [==============================] - 6s 2ms/step - loss: 0.1501 - accuracy: 0.9485 - val_loss: 1.5492 - val_accuracy: 0.7239\n",
      "Epoch 11/30\n",
      "2942/2942 [==============================] - 6s 2ms/step - loss: 0.1333 - accuracy: 0.9547 - val_loss: 1.6744 - val_accuracy: 0.7150\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.1534 - accuracy: 0.7374\n",
      "Model: \"functional_59\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_30 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_107 (Conv2D)          (None, 32, 32, 25)        700       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_87 (MaxPooling (None, 16, 16, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_108 (Conv2D)          (None, 16, 16, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_88 (MaxPooling (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_109 (Conv2D)          (None, 8, 8, 100)         45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_89 (MaxPooling (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_29 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 1000)              1601000   \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,668,110\n",
      "Trainable params: 1,668,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2a5c50c440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2a5c50c440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2770/2778 [============================>.] - ETA: 0s - loss: 1.3129 - accuracy: 0.5250WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2a5c4b7950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2a5c4b7950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2778/2778 [==============================] - 6s 2ms/step - loss: 1.3122 - accuracy: 0.5252 - val_loss: 1.0648 - val_accuracy: 0.6245\n",
      "Epoch 2/30\n",
      "2778/2778 [==============================] - 6s 2ms/step - loss: 0.8808 - accuracy: 0.6908 - val_loss: 0.8469 - val_accuracy: 0.7075\n",
      "Epoch 3/30\n",
      "2778/2778 [==============================] - 6s 2ms/step - loss: 0.7038 - accuracy: 0.7536 - val_loss: 0.8566 - val_accuracy: 0.7075\n",
      "Epoch 4/30\n",
      "2778/2778 [==============================] - 6s 2ms/step - loss: 0.5659 - accuracy: 0.8030 - val_loss: 0.8380 - val_accuracy: 0.7187\n",
      "Epoch 5/30\n",
      "2778/2778 [==============================] - 6s 2ms/step - loss: 0.4422 - accuracy: 0.8441 - val_loss: 0.8843 - val_accuracy: 0.7236\n",
      "Epoch 6/30\n",
      "2778/2778 [==============================] - 6s 2ms/step - loss: 0.3360 - accuracy: 0.8824 - val_loss: 0.9249 - val_accuracy: 0.7370\n",
      "Epoch 7/30\n",
      "2778/2778 [==============================] - 6s 2ms/step - loss: 0.2541 - accuracy: 0.9121 - val_loss: 0.9982 - val_accuracy: 0.7313\n",
      "Epoch 8/30\n",
      "2778/2778 [==============================] - 6s 2ms/step - loss: 0.1956 - accuracy: 0.9326 - val_loss: 1.1397 - val_accuracy: 0.7330\n",
      "Epoch 9/30\n",
      "2778/2778 [==============================] - 6s 2ms/step - loss: 0.1669 - accuracy: 0.9423 - val_loss: 1.2702 - val_accuracy: 0.7398\n",
      "Epoch 10/30\n",
      "2778/2778 [==============================] - 6s 2ms/step - loss: 0.1407 - accuracy: 0.9506 - val_loss: 1.4703 - val_accuracy: 0.7303\n",
      "Epoch 11/30\n",
      "2778/2778 [==============================] - 6s 2ms/step - loss: 0.1368 - accuracy: 0.9543 - val_loss: 1.5530 - val_accuracy: 0.7241\n",
      "Epoch 12/30\n",
      "2778/2778 [==============================] - 6s 2ms/step - loss: 0.1246 - accuracy: 0.9586 - val_loss: 1.6478 - val_accuracy: 0.7228\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.2702 - accuracy: 0.7398\n",
      "Model: \"functional_61\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_31 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_110 (Conv2D)          (None, 32, 32, 25)        700       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_90 (MaxPooling (None, 16, 16, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_111 (Conv2D)          (None, 16, 16, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_91 (MaxPooling (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_112 (Conv2D)          (None, 8, 8, 100)         45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_92 (MaxPooling (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_30 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 1000)              1601000   \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,668,110\n",
      "Trainable params: 1,668,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2a3c7209e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2a3c7209e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2622/2632 [============================>.] - ETA: 0s - loss: 1.3056 - accuracy: 0.5300WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2a5c07e170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2a5c07e170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2632/2632 [==============================] - 6s 2ms/step - loss: 1.3048 - accuracy: 0.5303 - val_loss: 1.0267 - val_accuracy: 0.6381\n",
      "Epoch 2/30\n",
      "2632/2632 [==============================] - 6s 2ms/step - loss: 0.8986 - accuracy: 0.6838 - val_loss: 0.9161 - val_accuracy: 0.6814\n",
      "Epoch 3/30\n",
      "2632/2632 [==============================] - 6s 2ms/step - loss: 0.7164 - accuracy: 0.7500 - val_loss: 0.8149 - val_accuracy: 0.7176\n",
      "Epoch 4/30\n",
      "2632/2632 [==============================] - 6s 2ms/step - loss: 0.5796 - accuracy: 0.7949 - val_loss: 0.7974 - val_accuracy: 0.7331\n",
      "Epoch 5/30\n",
      "2632/2632 [==============================] - 6s 2ms/step - loss: 0.4524 - accuracy: 0.8411 - val_loss: 0.8204 - val_accuracy: 0.7435\n",
      "Epoch 6/30\n",
      "2632/2632 [==============================] - 6s 2ms/step - loss: 0.3403 - accuracy: 0.8798 - val_loss: 0.9871 - val_accuracy: 0.7280\n",
      "Epoch 7/30\n",
      "2632/2632 [==============================] - 6s 2ms/step - loss: 0.2528 - accuracy: 0.9111 - val_loss: 1.0380 - val_accuracy: 0.7373\n",
      "Epoch 8/30\n",
      "2632/2632 [==============================] - 6s 2ms/step - loss: 0.1976 - accuracy: 0.9303 - val_loss: 1.1196 - val_accuracy: 0.7382\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.8204 - accuracy: 0.7435\n",
      "Model: \"functional_63\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_32 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_113 (Conv2D)          (None, 32, 32, 25)        700       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_93 (MaxPooling (None, 16, 16, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_114 (Conv2D)          (None, 16, 16, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_94 (MaxPooling (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_115 (Conv2D)          (None, 8, 8, 100)         45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_95 (MaxPooling (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_31 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 1000)              1601000   \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,668,110\n",
      "Trainable params: 1,668,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2a3c7c4b90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2a3c7c4b90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2480/2500 [============================>.] - ETA: 0s - loss: 1.3329 - accuracy: 0.5178WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2a3c6674d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2a3c6674d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.3313 - accuracy: 0.5184 - val_loss: 1.0785 - val_accuracy: 0.6181\n",
      "Epoch 2/30\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9151 - accuracy: 0.6783 - val_loss: 0.9027 - val_accuracy: 0.6823\n",
      "Epoch 3/30\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.7352 - accuracy: 0.7426 - val_loss: 0.8280 - val_accuracy: 0.7176\n",
      "Epoch 4/30\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.5903 - accuracy: 0.7923 - val_loss: 0.8306 - val_accuracy: 0.7196\n",
      "Epoch 5/30\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.4610 - accuracy: 0.8378 - val_loss: 0.8844 - val_accuracy: 0.7141\n",
      "Epoch 6/30\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.3500 - accuracy: 0.8763 - val_loss: 0.9558 - val_accuracy: 0.7287\n",
      "Epoch 7/30\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.2571 - accuracy: 0.9099 - val_loss: 1.0320 - val_accuracy: 0.7248\n",
      "Epoch 8/30\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.2022 - accuracy: 0.9282 - val_loss: 1.1785 - val_accuracy: 0.7299\n",
      "Epoch 9/30\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1598 - accuracy: 0.9437 - val_loss: 1.2813 - val_accuracy: 0.7266\n",
      "Epoch 10/30\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1444 - accuracy: 0.9506 - val_loss: 1.4813 - val_accuracy: 0.7119\n",
      "Epoch 11/30\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1318 - accuracy: 0.9556 - val_loss: 1.5943 - val_accuracy: 0.7221\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.1785 - accuracy: 0.7299\n",
      "Model: \"functional_65\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_33 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_116 (Conv2D)          (None, 32, 32, 25)        700       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_96 (MaxPooling (None, 16, 16, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_117 (Conv2D)          (None, 16, 16, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_97 (MaxPooling (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_118 (Conv2D)          (None, 8, 8, 100)         45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_98 (MaxPooling (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_32 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 1000)              1601000   \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,668,110\n",
      "Trainable params: 1,668,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2bba5d9290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2bba5d9290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2363/2381 [============================>.] - ETA: 0s - loss: 1.3121 - accuracy: 0.5260WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2a3c451050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2a3c451050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2381/2381 [==============================] - 6s 2ms/step - loss: 1.3106 - accuracy: 0.5266 - val_loss: 1.0014 - val_accuracy: 0.6410\n",
      "Epoch 2/30\n",
      "2381/2381 [==============================] - 6s 2ms/step - loss: 0.8903 - accuracy: 0.6877 - val_loss: 0.8666 - val_accuracy: 0.6940\n",
      "Epoch 3/30\n",
      "2381/2381 [==============================] - 6s 2ms/step - loss: 0.7133 - accuracy: 0.7490 - val_loss: 0.8048 - val_accuracy: 0.7215\n",
      "Epoch 4/30\n",
      "2381/2381 [==============================] - 6s 2ms/step - loss: 0.5670 - accuracy: 0.8017 - val_loss: 0.7818 - val_accuracy: 0.7341\n",
      "Epoch 5/30\n",
      "2381/2381 [==============================] - 6s 2ms/step - loss: 0.4393 - accuracy: 0.8451 - val_loss: 0.8557 - val_accuracy: 0.7310\n",
      "Epoch 6/30\n",
      "2381/2381 [==============================] - 6s 2ms/step - loss: 0.3137 - accuracy: 0.8884 - val_loss: 0.9337 - val_accuracy: 0.7354\n",
      "Epoch 7/30\n",
      "2381/2381 [==============================] - 5s 2ms/step - loss: 0.2397 - accuracy: 0.9157 - val_loss: 1.0190 - val_accuracy: 0.7322\n",
      "Epoch 8/30\n",
      "2381/2381 [==============================] - 6s 2ms/step - loss: 0.1817 - accuracy: 0.9354 - val_loss: 1.1764 - val_accuracy: 0.7330\n",
      "Epoch 9/30\n",
      "2381/2381 [==============================] - 5s 2ms/step - loss: 0.1435 - accuracy: 0.9510 - val_loss: 1.3708 - val_accuracy: 0.7261\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.9337 - accuracy: 0.7354\n",
      "Model: \"functional_67\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_34 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_119 (Conv2D)          (None, 32, 32, 25)        700       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_99 (MaxPooling (None, 16, 16, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_120 (Conv2D)          (None, 16, 16, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_100 (MaxPoolin (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_121 (Conv2D)          (None, 8, 8, 100)         45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_101 (MaxPoolin (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_33 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 1000)              1601000   \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,668,110\n",
      "Trainable params: 1,668,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2a3c7c4ef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2a3c7c4ef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2264/2273 [============================>.] - ETA: 0s - loss: 1.3048 - accuracy: 0.5289WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2a5c07ea70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2a5c07ea70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2273/2273 [==============================] - 5s 2ms/step - loss: 1.3039 - accuracy: 0.5292 - val_loss: 1.0958 - val_accuracy: 0.6087\n",
      "Epoch 2/30\n",
      "2273/2273 [==============================] - 5s 2ms/step - loss: 0.8933 - accuracy: 0.6844 - val_loss: 0.8886 - val_accuracy: 0.6880\n",
      "Epoch 3/30\n",
      "2273/2273 [==============================] - 5s 2ms/step - loss: 0.7134 - accuracy: 0.7497 - val_loss: 0.8120 - val_accuracy: 0.7187\n",
      "Epoch 4/30\n",
      "2273/2273 [==============================] - 5s 2ms/step - loss: 0.5672 - accuracy: 0.8019 - val_loss: 0.8218 - val_accuracy: 0.7244\n",
      "Epoch 5/30\n",
      "2273/2273 [==============================] - 5s 2ms/step - loss: 0.4361 - accuracy: 0.8461 - val_loss: 0.8462 - val_accuracy: 0.7433\n",
      "Epoch 6/30\n",
      "2273/2273 [==============================] - 5s 2ms/step - loss: 0.3139 - accuracy: 0.8912 - val_loss: 0.9352 - val_accuracy: 0.7350\n",
      "Epoch 7/30\n",
      "2273/2273 [==============================] - 5s 2ms/step - loss: 0.2307 - accuracy: 0.9196 - val_loss: 1.0639 - val_accuracy: 0.7298\n",
      "Epoch 8/30\n",
      "2273/2273 [==============================] - 5s 2ms/step - loss: 0.1734 - accuracy: 0.9393 - val_loss: 1.1806 - val_accuracy: 0.7384\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.8462 - accuracy: 0.7433\n",
      "Model: \"functional_69\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_35 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_122 (Conv2D)          (None, 32, 32, 25)        700       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_102 (MaxPoolin (None, 16, 16, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_123 (Conv2D)          (None, 16, 16, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_103 (MaxPoolin (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_124 (Conv2D)          (None, 8, 8, 100)         45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_104 (MaxPoolin (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_34 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 1000)              1601000   \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,668,110\n",
      "Trainable params: 1,668,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2a5c50c0e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2a5c50c0e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2153/2174 [============================>.] - ETA: 0s - loss: 1.3448 - accuracy: 0.5114WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2a5c7cae60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2a5c7cae60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2174/2174 [==============================] - 5s 2ms/step - loss: 1.3417 - accuracy: 0.5129 - val_loss: 1.0064 - val_accuracy: 0.6436\n",
      "Epoch 2/30\n",
      "2174/2174 [==============================] - 5s 2ms/step - loss: 0.9240 - accuracy: 0.6745 - val_loss: 0.8671 - val_accuracy: 0.6969\n",
      "Epoch 3/30\n",
      "2174/2174 [==============================] - 5s 2ms/step - loss: 0.7476 - accuracy: 0.7360 - val_loss: 0.8352 - val_accuracy: 0.7067\n",
      "Epoch 4/30\n",
      "2174/2174 [==============================] - 5s 2ms/step - loss: 0.6099 - accuracy: 0.7855 - val_loss: 0.8011 - val_accuracy: 0.7288\n",
      "Epoch 5/30\n",
      "2174/2174 [==============================] - 5s 2ms/step - loss: 0.4933 - accuracy: 0.8244 - val_loss: 0.8203 - val_accuracy: 0.7388\n",
      "Epoch 6/30\n",
      "2174/2174 [==============================] - 5s 2ms/step - loss: 0.3845 - accuracy: 0.8652 - val_loss: 0.8735 - val_accuracy: 0.7377\n",
      "Epoch 7/30\n",
      "2174/2174 [==============================] - 5s 2ms/step - loss: 0.2921 - accuracy: 0.8977 - val_loss: 0.9715 - val_accuracy: 0.7335\n",
      "Epoch 8/30\n",
      "2174/2174 [==============================] - 5s 2ms/step - loss: 0.2182 - accuracy: 0.9228 - val_loss: 1.1449 - val_accuracy: 0.7338\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.8203 - accuracy: 0.7388\n",
      "Model: \"functional_71\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_36 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_125 (Conv2D)          (None, 32, 32, 25)        700       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_105 (MaxPoolin (None, 16, 16, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_126 (Conv2D)          (None, 16, 16, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_106 (MaxPoolin (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_127 (Conv2D)          (None, 8, 8, 100)         45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_107 (MaxPoolin (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_35 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 1000)              1601000   \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,668,110\n",
      "Trainable params: 1,668,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2bd29234d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2bd29234d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2067/2084 [============================>.] - ETA: 0s - loss: 1.3578 - accuracy: 0.5099WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2ab05b8830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2ab05b8830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2084/2084 [==============================] - 5s 2ms/step - loss: 1.3558 - accuracy: 0.5108 - val_loss: 1.0346 - val_accuracy: 0.6297\n",
      "Epoch 2/30\n",
      "2084/2084 [==============================] - 5s 2ms/step - loss: 0.9269 - accuracy: 0.6745 - val_loss: 0.9073 - val_accuracy: 0.6874\n",
      "Epoch 3/30\n",
      "2084/2084 [==============================] - 5s 2ms/step - loss: 0.7495 - accuracy: 0.7376 - val_loss: 0.8316 - val_accuracy: 0.7145\n",
      "Epoch 4/30\n",
      "2084/2084 [==============================] - 5s 2ms/step - loss: 0.6099 - accuracy: 0.7867 - val_loss: 0.8310 - val_accuracy: 0.7202\n",
      "Epoch 5/30\n",
      "2084/2084 [==============================] - 5s 2ms/step - loss: 0.4827 - accuracy: 0.8292 - val_loss: 0.8462 - val_accuracy: 0.7285\n",
      "Epoch 6/30\n",
      "2084/2084 [==============================] - 5s 2ms/step - loss: 0.3708 - accuracy: 0.8694 - val_loss: 0.8889 - val_accuracy: 0.7367\n",
      "Epoch 7/30\n",
      "2084/2084 [==============================] - 5s 2ms/step - loss: 0.2719 - accuracy: 0.9033 - val_loss: 0.9794 - val_accuracy: 0.7339\n",
      "Epoch 8/30\n",
      "2084/2084 [==============================] - 5s 2ms/step - loss: 0.2088 - accuracy: 0.9260 - val_loss: 1.1048 - val_accuracy: 0.7360\n",
      "Epoch 9/30\n",
      "2084/2084 [==============================] - 5s 2ms/step - loss: 0.1581 - accuracy: 0.9450 - val_loss: 1.2701 - val_accuracy: 0.7354\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.8889 - accuracy: 0.7367\n",
      "Model: \"functional_73\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_37 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_128 (Conv2D)          (None, 32, 32, 25)        700       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_108 (MaxPoolin (None, 16, 16, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_129 (Conv2D)          (None, 16, 16, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_109 (MaxPoolin (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_130 (Conv2D)          (None, 8, 8, 100)         45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_110 (MaxPoolin (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_36 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 1000)              1601000   \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,668,110\n",
      "Trainable params: 1,668,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2bd296e5f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2bd296e5f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1983/2000 [============================>.] - ETA: 0s - loss: 1.3274 - accuracy: 0.5195WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2abc08f950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2abc08f950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 1.3251 - accuracy: 0.5205 - val_loss: 1.0601 - val_accuracy: 0.6167\n",
      "Epoch 2/30\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.9194 - accuracy: 0.6755 - val_loss: 0.8903 - val_accuracy: 0.6899\n",
      "Epoch 3/30\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.7441 - accuracy: 0.7371 - val_loss: 0.8437 - val_accuracy: 0.7040\n",
      "Epoch 4/30\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.5991 - accuracy: 0.7886 - val_loss: 0.8535 - val_accuracy: 0.7182\n",
      "Epoch 5/30\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.4621 - accuracy: 0.8367 - val_loss: 0.8688 - val_accuracy: 0.7309\n",
      "Epoch 6/30\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3430 - accuracy: 0.8788 - val_loss: 0.9101 - val_accuracy: 0.7341\n",
      "Epoch 7/30\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2457 - accuracy: 0.9132 - val_loss: 1.0714 - val_accuracy: 0.7222\n",
      "Epoch 8/30\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1836 - accuracy: 0.9359 - val_loss: 1.1832 - val_accuracy: 0.7276\n",
      "Epoch 9/30\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1539 - accuracy: 0.9471 - val_loss: 1.3403 - val_accuracy: 0.7348\n",
      "Epoch 10/30\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1347 - accuracy: 0.9534 - val_loss: 1.4061 - val_accuracy: 0.7319\n",
      "Epoch 11/30\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1192 - accuracy: 0.9599 - val_loss: 1.5101 - val_accuracy: 0.7253\n",
      "Epoch 12/30\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1119 - accuracy: 0.9625 - val_loss: 1.6599 - val_accuracy: 0.7233\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.3403 - accuracy: 0.7348\n",
      "Model: \"functional_75\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_38 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_131 (Conv2D)          (None, 32, 32, 25)        700       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_111 (MaxPoolin (None, 16, 16, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_132 (Conv2D)          (None, 16, 16, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_112 (MaxPoolin (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_133 (Conv2D)          (None, 8, 8, 100)         45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_113 (MaxPoolin (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_37 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 1000)              1601000   \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,668,110\n",
      "Trainable params: 1,668,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2bd28ce560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2bd28ce560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1910/1924 [============================>.] - ETA: 0s - loss: 1.3918 - accuracy: 0.4956WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2bba3e6320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2bba3e6320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1924/1924 [==============================] - 5s 2ms/step - loss: 1.3900 - accuracy: 0.4962 - val_loss: 1.1083 - val_accuracy: 0.5974\n",
      "Epoch 2/30\n",
      "1924/1924 [==============================] - 5s 2ms/step - loss: 0.9566 - accuracy: 0.6601 - val_loss: 0.9393 - val_accuracy: 0.6748\n",
      "Epoch 3/30\n",
      "1924/1924 [==============================] - 5s 2ms/step - loss: 0.7800 - accuracy: 0.7259 - val_loss: 0.8644 - val_accuracy: 0.6940\n",
      "Epoch 4/30\n",
      "1924/1924 [==============================] - 5s 2ms/step - loss: 0.6441 - accuracy: 0.7745 - val_loss: 0.8040 - val_accuracy: 0.7286\n",
      "Epoch 5/30\n",
      "1924/1924 [==============================] - 5s 2ms/step - loss: 0.5280 - accuracy: 0.8148 - val_loss: 0.8403 - val_accuracy: 0.7223\n",
      "Epoch 6/30\n",
      "1924/1924 [==============================] - 5s 2ms/step - loss: 0.4166 - accuracy: 0.8513 - val_loss: 0.8428 - val_accuracy: 0.7353\n",
      "Epoch 7/30\n",
      "1924/1924 [==============================] - 5s 2ms/step - loss: 0.3196 - accuracy: 0.8867 - val_loss: 0.9314 - val_accuracy: 0.7358\n",
      "Epoch 8/30\n",
      "1924/1924 [==============================] - 5s 2ms/step - loss: 0.2412 - accuracy: 0.9153 - val_loss: 1.0855 - val_accuracy: 0.7260\n",
      "Epoch 9/30\n",
      "1924/1924 [==============================] - 5s 2ms/step - loss: 0.1907 - accuracy: 0.9327 - val_loss: 1.1780 - val_accuracy: 0.7336\n",
      "Epoch 10/30\n",
      "1924/1924 [==============================] - 5s 2ms/step - loss: 0.1603 - accuracy: 0.9441 - val_loss: 1.4326 - val_accuracy: 0.7118\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.9314 - accuracy: 0.7358\n",
      "Model: \"functional_77\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_39 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_134 (Conv2D)          (None, 32, 32, 25)        700       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_114 (MaxPoolin (None, 16, 16, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_135 (Conv2D)          (None, 16, 16, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_115 (MaxPoolin (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_136 (Conv2D)          (None, 8, 8, 100)         45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_116 (MaxPoolin (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_38 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 1000)              1601000   \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,668,110\n",
      "Trainable params: 1,668,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2a5c7aed40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2a5c7aed40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1834/1852 [============================>.] - ETA: 0s - loss: 1.3341 - accuracy: 0.5196WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2bba7eb3b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2bba7eb3b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1852/1852 [==============================] - 5s 3ms/step - loss: 1.3303 - accuracy: 0.5209 - val_loss: 1.0089 - val_accuracy: 0.6437\n",
      "Epoch 2/30\n",
      "1852/1852 [==============================] - 4s 2ms/step - loss: 0.9070 - accuracy: 0.6795 - val_loss: 0.8913 - val_accuracy: 0.6853\n",
      "Epoch 3/30\n",
      "1852/1852 [==============================] - 4s 2ms/step - loss: 0.7350 - accuracy: 0.7410 - val_loss: 0.8661 - val_accuracy: 0.7003\n",
      "Epoch 4/30\n",
      "1852/1852 [==============================] - 4s 2ms/step - loss: 0.5942 - accuracy: 0.7899 - val_loss: 0.7634 - val_accuracy: 0.7457\n",
      "Epoch 5/30\n",
      "1852/1852 [==============================] - 4s 2ms/step - loss: 0.4746 - accuracy: 0.8331 - val_loss: 0.7821 - val_accuracy: 0.7489\n",
      "Epoch 6/30\n",
      "1852/1852 [==============================] - 4s 2ms/step - loss: 0.3629 - accuracy: 0.8735 - val_loss: 0.8432 - val_accuracy: 0.7468\n",
      "Epoch 7/30\n",
      "1852/1852 [==============================] - 4s 2ms/step - loss: 0.2672 - accuracy: 0.9062 - val_loss: 0.9253 - val_accuracy: 0.7498\n",
      "Epoch 8/30\n",
      "1852/1852 [==============================] - 4s 2ms/step - loss: 0.1978 - accuracy: 0.9300 - val_loss: 1.0383 - val_accuracy: 0.7411\n",
      "Epoch 9/30\n",
      "1852/1852 [==============================] - 4s 2ms/step - loss: 0.1542 - accuracy: 0.9466 - val_loss: 1.2322 - val_accuracy: 0.7346\n",
      "Epoch 10/30\n",
      "1852/1852 [==============================] - 4s 2ms/step - loss: 0.1338 - accuracy: 0.9536 - val_loss: 1.3162 - val_accuracy: 0.7342\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.9253 - accuracy: 0.7498\n",
      "Model: \"functional_79\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_40 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_137 (Conv2D)          (None, 32, 32, 25)        700       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_117 (MaxPoolin (None, 16, 16, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_138 (Conv2D)          (None, 16, 16, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_118 (MaxPoolin (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_139 (Conv2D)          (None, 8, 8, 100)         45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_119 (MaxPoolin (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_39 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 1000)              1601000   \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,668,110\n",
      "Trainable params: 1,668,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2bba4cab00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2bba4cab00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1769/1786 [============================>.] - ETA: 0s - loss: 1.3550 - accuracy: 0.5099WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2bba76a170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2bba76a170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1786/1786 [==============================] - 4s 2ms/step - loss: 1.3518 - accuracy: 0.5109 - val_loss: 1.0560 - val_accuracy: 0.6311\n",
      "Epoch 2/30\n",
      "1786/1786 [==============================] - 4s 2ms/step - loss: 0.9270 - accuracy: 0.6720 - val_loss: 0.9104 - val_accuracy: 0.6856\n",
      "Epoch 3/30\n",
      "1786/1786 [==============================] - 4s 2ms/step - loss: 0.7427 - accuracy: 0.7410 - val_loss: 0.7793 - val_accuracy: 0.7260\n",
      "Epoch 4/30\n",
      "1786/1786 [==============================] - 4s 2ms/step - loss: 0.5992 - accuracy: 0.7901 - val_loss: 0.7940 - val_accuracy: 0.7328\n",
      "Epoch 5/30\n",
      "1786/1786 [==============================] - 4s 2ms/step - loss: 0.4661 - accuracy: 0.8374 - val_loss: 0.8305 - val_accuracy: 0.7284\n",
      "Epoch 6/30\n",
      "1786/1786 [==============================] - 4s 2ms/step - loss: 0.3485 - accuracy: 0.8762 - val_loss: 0.8964 - val_accuracy: 0.7374\n",
      "Epoch 7/30\n",
      "1786/1786 [==============================] - 4s 2ms/step - loss: 0.2551 - accuracy: 0.9116 - val_loss: 0.9940 - val_accuracy: 0.7387\n",
      "Epoch 8/30\n",
      "1786/1786 [==============================] - 4s 2ms/step - loss: 0.1880 - accuracy: 0.9344 - val_loss: 1.1299 - val_accuracy: 0.7374\n",
      "Epoch 9/30\n",
      "1786/1786 [==============================] - 4s 2ms/step - loss: 0.1471 - accuracy: 0.9487 - val_loss: 1.2314 - val_accuracy: 0.7418\n",
      "Epoch 10/30\n",
      "1786/1786 [==============================] - 4s 2ms/step - loss: 0.1329 - accuracy: 0.9537 - val_loss: 1.3176 - val_accuracy: 0.7417\n",
      "Epoch 11/30\n",
      "1786/1786 [==============================] - 4s 2ms/step - loss: 0.1182 - accuracy: 0.9593 - val_loss: 1.4544 - val_accuracy: 0.7286\n",
      "Epoch 12/30\n",
      "1786/1786 [==============================] - 4s 2ms/step - loss: 0.1010 - accuracy: 0.9652 - val_loss: 1.5605 - val_accuracy: 0.7321\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.2314 - accuracy: 0.7418\n",
      "Model: \"functional_81\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_41 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_140 (Conv2D)          (None, 32, 32, 25)        700       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_120 (MaxPoolin (None, 16, 16, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_141 (Conv2D)          (None, 16, 16, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_121 (MaxPoolin (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_142 (Conv2D)          (None, 8, 8, 100)         45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_122 (MaxPoolin (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_40 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 1000)              1601000   \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,668,110\n",
      "Trainable params: 1,668,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2bba7a8d40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2bba7a8d40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1717/1725 [============================>.] - ETA: 0s - loss: 1.3874 - accuracy: 0.4962WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2bba4039e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2bba4039e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1725/1725 [==============================] - 4s 2ms/step - loss: 1.3862 - accuracy: 0.4967 - val_loss: 1.1247 - val_accuracy: 0.5993\n",
      "Epoch 2/30\n",
      "1725/1725 [==============================] - 4s 2ms/step - loss: 0.9634 - accuracy: 0.6599 - val_loss: 0.9728 - val_accuracy: 0.6595\n",
      "Epoch 3/30\n",
      "1725/1725 [==============================] - 4s 2ms/step - loss: 0.7744 - accuracy: 0.7284 - val_loss: 0.8347 - val_accuracy: 0.7127\n",
      "Epoch 4/30\n",
      "1725/1725 [==============================] - 4s 2ms/step - loss: 0.6289 - accuracy: 0.7802 - val_loss: 0.7708 - val_accuracy: 0.7374\n",
      "Epoch 5/30\n",
      "1725/1725 [==============================] - 4s 2ms/step - loss: 0.5019 - accuracy: 0.8232 - val_loss: 0.8335 - val_accuracy: 0.7237\n",
      "Epoch 6/30\n",
      "1725/1725 [==============================] - 4s 2ms/step - loss: 0.3891 - accuracy: 0.8629 - val_loss: 0.8594 - val_accuracy: 0.7364\n",
      "Epoch 7/30\n",
      "1725/1725 [==============================] - 4s 2ms/step - loss: 0.2813 - accuracy: 0.9014 - val_loss: 0.9389 - val_accuracy: 0.7334\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.7708 - accuracy: 0.7374\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "epochs_train = []\n",
    "for bs in range(1,30):\n",
    "    # capas de la red\n",
    "    input = Input(shape=(32,32,3))\n",
    "    layer = input\n",
    "    layer = Conv2D(filters=25, kernel_size=3, strides=1, padding='same', activation='relu')(layer)\n",
    "    layer = MaxPooling2D((2, 2))(layer)\n",
    "    layer = Conv2D(filters=50, kernel_size=3, strides=1, padding='same', activation='relu')(layer)\n",
    "    layer = MaxPooling2D((2, 2))(layer)\n",
    "    layer = Conv2D(filters=100, kernel_size=3, strides=1, padding='same', activation='relu')(layer)\n",
    "    layer = MaxPooling2D((2, 2))(layer)\n",
    "    layer = Flatten()(layer)\n",
    "    layer = Dense(units=1000, activation='relu')(layer)\n",
    "    output = Dense(units=10, activation='softmax')(layer)\n",
    "\n",
    "    # creamos el modelo\n",
    "    model = Model(inputs=input, outputs=output)\n",
    "    print(model.summary())\n",
    "\n",
    "    # optimizador\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "    # función loss\n",
    "    loss = SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "    # métrica\n",
    "    metrics = ['accuracy']\n",
    "\n",
    "    # compilamos el modelo\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, mode='max', restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(x=X_train_cifar10, y=y_train_cifar10, batch_size=bs, epochs=30,\n",
    "                    validation_data=(X_validation_cifar10, y_validation_cifar10), callbacks=[early_stopping])\n",
    "    scores.append(model.evaluate(X_validation_cifar10, y_validation_cifar10, batch_size=128)[1])\n",
    "    epochs_train.append(len(history.history['loss']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(scores)\n",
    "plt.title('Select correct Batch Size')\n",
    "plt.ylabel('Accuracy value (%)')\n",
    "plt.xlabel('Batch Size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claramente observamos que deberíamos elegir un Batch Size mayor de 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Batch Normalization\n",
    "Podemos añadir capas de Batch Normalization en cualquier parte de la red excepto en la última.\n",
    "Con ello conseguimos que en todo momento los inputs de las layers estén en los rangos deseados.\n",
    "Veamos un ejemplo de red profunda sin BN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_113\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_57 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_188 (Conv2D)          (None, 32, 32, 10)        280       \n",
      "_________________________________________________________________\n",
      "conv2d_189 (Conv2D)          (None, 32, 32, 10)        910       \n",
      "_________________________________________________________________\n",
      "conv2d_190 (Conv2D)          (None, 32, 32, 10)        910       \n",
      "_________________________________________________________________\n",
      "conv2d_191 (Conv2D)          (None, 32, 32, 10)        910       \n",
      "_________________________________________________________________\n",
      "conv2d_192 (Conv2D)          (None, 32, 32, 10)        910       \n",
      "_________________________________________________________________\n",
      "conv2d_193 (Conv2D)          (None, 32, 32, 10)        910       \n",
      "_________________________________________________________________\n",
      "conv2d_194 (Conv2D)          (None, 32, 32, 10)        910       \n",
      "_________________________________________________________________\n",
      "conv2d_195 (Conv2D)          (None, 32, 32, 10)        910       \n",
      "_________________________________________________________________\n",
      "conv2d_196 (Conv2D)          (None, 32, 32, 10)        910       \n",
      "_________________________________________________________________\n",
      "conv2d_197 (Conv2D)          (None, 32, 32, 10)        910       \n",
      "_________________________________________________________________\n",
      "conv2d_198 (Conv2D)          (None, 32, 32, 10)        910       \n",
      "_________________________________________________________________\n",
      "conv2d_199 (Conv2D)          (None, 32, 32, 10)        910       \n",
      "_________________________________________________________________\n",
      "conv2d_200 (Conv2D)          (None, 32, 32, 10)        910       \n",
      "_________________________________________________________________\n",
      "conv2d_201 (Conv2D)          (None, 32, 32, 10)        910       \n",
      "_________________________________________________________________\n",
      "conv2d_202 (Conv2D)          (None, 32, 32, 10)        910       \n",
      "_________________________________________________________________\n",
      "conv2d_203 (Conv2D)          (None, 32, 32, 10)        910       \n",
      "_________________________________________________________________\n",
      "conv2d_204 (Conv2D)          (None, 32, 32, 10)        910       \n",
      "_________________________________________________________________\n",
      "conv2d_205 (Conv2D)          (None, 32, 32, 10)        910       \n",
      "_________________________________________________________________\n",
      "conv2d_206 (Conv2D)          (None, 32, 32, 10)        910       \n",
      "_________________________________________________________________\n",
      "conv2d_207 (Conv2D)          (None, 32, 32, 10)        910       \n",
      "_________________________________________________________________\n",
      "conv2d_208 (Conv2D)          (None, 32, 32, 25)        2275      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_168 (MaxPoolin (None, 16, 16, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_209 (Conv2D)          (None, 16, 16, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_169 (MaxPoolin (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_210 (Conv2D)          (None, 8, 8, 100)         45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_170 (MaxPoolin (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_56 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 1000)              1601000   \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,687,255\n",
      "Trainable params: 1,687,255\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f54d01583b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f54d01583b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 996/1000 [============================>.] - ETA: 0s - loss: 2.3028 - accuracy: 0.0991WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f54a85cc8c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f54a85cc8c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 2.3028 - accuracy: 0.0991 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 2.3027 - accuracy: 0.0987 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 2.3027 - accuracy: 0.0988 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 2.3028 - accuracy: 0.0974 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 2.3027 - accuracy: 0.0983 - val_loss: 2.3026 - val_accuracy: 0.1000\n"
     ]
    }
   ],
   "source": [
    "# capas de la red\n",
    "input = Input(shape=(32,32,3))\n",
    "layer = input\n",
    "for _ in range(20):\n",
    "    layer = Conv2D(filters=10, kernel_size=3, strides=1, padding='same', activation='relu')(layer)\n",
    "layer = Conv2D(filters=25, kernel_size=3, strides=1, padding='same', activation='relu')(layer)\n",
    "layer = MaxPooling2D((2, 2))(layer)\n",
    "layer = Conv2D(filters=50, kernel_size=3, strides=1, padding='same', activation='relu')(layer)\n",
    "layer = MaxPooling2D((2, 2))(layer)\n",
    "layer = Conv2D(filters=100, kernel_size=3, strides=1, padding='same', activation='relu')(layer)\n",
    "layer = MaxPooling2D((2, 2))(layer)\n",
    "layer = Flatten()(layer)\n",
    "layer = Dense(units=1000, activation='relu')(layer)\n",
    "output = Dense(units=10, activation='softmax')(layer)\n",
    "\n",
    "# creamos el modelo\n",
    "model = Model(inputs=input, outputs=output)\n",
    "print(model.summary())\n",
    "\n",
    "# optimizador\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# función loss\n",
    "loss = SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "# métrica\n",
    "metrics = ['accuracy']\n",
    "\n",
    "# compilamos el modelo\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "history = model.fit(x=X_train_cifar10, y=y_train_cifar10, batch_size=50, epochs=5,\n",
    "                    validation_data=(X_validation_cifar10, y_validation_cifar10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claramente el modelo no aprende nada ya que el gradiente no se ha podido propagar a través de las capas.\n",
    "Probemos ahora añadiendo capas de BN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 32, 32, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 32, 32, 10)        40        \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 32, 32, 10)        910       \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 32, 32, 10)        40        \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 32, 32, 10)        910       \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 32, 32, 10)        40        \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 32, 32, 10)        910       \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 32, 32, 10)        40        \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 32, 32, 10)        910       \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 32, 32, 10)        40        \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 32, 32, 10)        910       \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 32, 32, 10)        40        \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 32, 32, 10)        910       \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 32, 32, 10)        40        \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 32, 32, 10)        910       \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 32, 32, 10)        40        \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 32, 32, 10)        910       \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 32, 32, 10)        40        \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 32, 32, 10)        910       \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 32, 32, 10)        40        \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 32, 32, 10)        910       \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 32, 32, 10)        40        \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 32, 32, 10)        910       \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 32, 32, 10)        40        \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 32, 32, 10)        910       \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 32, 32, 10)        40        \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 32, 32, 10)        910       \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 32, 32, 10)        40        \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 32, 32, 10)        910       \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 32, 32, 10)        40        \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 32, 32, 10)        910       \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 32, 32, 10)        40        \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 32, 32, 10)        910       \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 32, 32, 10)        40        \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 32, 32, 10)        910       \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 32, 32, 10)        40        \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 32, 32, 10)        910       \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 32, 32, 10)        40        \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 32, 32, 10)        910       \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 32, 32, 10)        40        \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 32, 32, 25)        2275      \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 32, 32, 25)        100       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 16, 16, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 16, 16, 50)        11300     \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 16, 16, 50)        200       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 8, 8, 100)         45100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 8, 8, 100)         400       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1000)              1601000   \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,688,755\n",
      "Trainable params: 1,688,005\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2a5c7e1f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2a5c7e1f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1.9262 - accuracy: 0.3039WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2bba3f87a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2bba3f87a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 1.9261 - accuracy: 0.3040 - val_loss: 1.6999 - val_accuracy: 0.4130\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 1.4024 - accuracy: 0.4915 - val_loss: 1.3727 - val_accuracy: 0.5126\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 1.1612 - accuracy: 0.5864 - val_loss: 1.1822 - val_accuracy: 0.5712\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.9908 - accuracy: 0.6476 - val_loss: 1.1388 - val_accuracy: 0.6076\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.8629 - accuracy: 0.6947 - val_loss: 0.9749 - val_accuracy: 0.6655\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.7512 - accuracy: 0.7363 - val_loss: 0.9698 - val_accuracy: 0.6774\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.6402 - accuracy: 0.7756 - val_loss: 0.9201 - val_accuracy: 0.6899\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.5494 - accuracy: 0.8063 - val_loss: 0.9436 - val_accuracy: 0.6942\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.4481 - accuracy: 0.8436 - val_loss: 1.0599 - val_accuracy: 0.6912\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.3527 - accuracy: 0.8763 - val_loss: 1.0443 - val_accuracy: 0.7080\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2790 - accuracy: 0.9018 - val_loss: 1.0371 - val_accuracy: 0.7146\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.2093 - accuracy: 0.9262 - val_loss: 1.1288 - val_accuracy: 0.7254\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.1755 - accuracy: 0.9382 - val_loss: 1.2560 - val_accuracy: 0.7062\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.1502 - accuracy: 0.9474 - val_loss: 1.3175 - val_accuracy: 0.7134\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.1245 - accuracy: 0.9576 - val_loss: 1.3925 - val_accuracy: 0.7026\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.1121 - accuracy: 0.9606 - val_loss: 1.4569 - val_accuracy: 0.7107\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0989 - accuracy: 0.9661 - val_loss: 1.5094 - val_accuracy: 0.7148\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.1016 - accuracy: 0.9659 - val_loss: 1.5693 - val_accuracy: 0.7035\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0952 - accuracy: 0.9682 - val_loss: 1.6411 - val_accuracy: 0.7029\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0752 - accuracy: 0.9748 - val_loss: 1.6614 - val_accuracy: 0.7133\n"
     ]
    }
   ],
   "source": [
    "# capas de la red\n",
    "input = Input(shape=(32,32,3))\n",
    "layer = input\n",
    "for _ in range(20):\n",
    "    layer = Conv2D(filters=10, kernel_size=3, strides=1, padding='same', activation='relu')(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "layer = Conv2D(filters=25, kernel_size=3, strides=1, padding='same', activation='relu')(layer)\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = MaxPooling2D((2, 2))(layer)\n",
    "layer = Conv2D(filters=50, kernel_size=3, strides=1, padding='same', activation='relu')(layer)\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = MaxPooling2D((2, 2))(layer)\n",
    "layer = Conv2D(filters=100, kernel_size=3, strides=1, padding='same', activation='relu')(layer)\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = MaxPooling2D((2, 2))(layer)\n",
    "layer = Flatten()(layer)\n",
    "layer = Dense(units=1000, activation='relu')(layer)\n",
    "output = Dense(units=10, activation='softmax')(layer)\n",
    "\n",
    "# creamos el modelo\n",
    "model = Model(inputs=input, outputs=output)\n",
    "print(model.summary())\n",
    "\n",
    "# optimizador\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# función loss\n",
    "loss = SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "# métrica\n",
    "metrics = ['accuracy']\n",
    "\n",
    "# compilamos el modelo\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "history = model.fit(x=X_train_cifar10, y=y_train_cifar10, batch_size=50, epochs=20,\n",
    "                    validation_data=(X_validation_cifar10, y_validation_cifar10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso el modelo se ha entrenado correctamente, obteniendo un score de 71.3%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Seleccionar tamaño correcto del modelo\n",
    "En muchas ocasiones es preferible tener un modelo de peor calidad pero que sea más rápido y de menor tamaño.\n",
    "Veamos como varía la velocidad de predicción vs el tamaño del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-16 16:18:49.218570: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2021-12-16 16:18:49.242281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 16:18:49.242954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:09:00.0 name: GeForce GTX 1080 computeCapability: 6.1\n",
      "coreClock: 1.835GHz coreCount: 20 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 298.32GiB/s\n",
      "2021-12-16 16:18:49.242978: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-16 16:18:49.243880: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-16 16:18:49.245380: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-16 16:18:49.245663: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-16 16:18:49.246696: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-16 16:18:49.247302: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-12-16 16:18:49.249553: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-16 16:18:49.249715: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 16:18:49.250504: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 16:18:49.251117: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2021-12-16 16:18:49.251414: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-16 16:18:49.273344: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 3699535000 Hz\n",
      "2021-12-16 16:18:49.273757: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3836ce0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-12-16 16:18:49.273781: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-12-16 16:18:49.346323: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 16:18:49.347037: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5885790 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-12-16 16:18:49.347064: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080, Compute Capability 6.1\n",
      "2021-12-16 16:18:49.347287: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 16:18:49.348041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:09:00.0 name: GeForce GTX 1080 computeCapability: 6.1\n",
      "coreClock: 1.835GHz coreCount: 20 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 298.32GiB/s\n",
      "2021-12-16 16:18:49.348074: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-16 16:18:49.348100: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-16 16:18:49.348116: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-16 16:18:49.348131: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-16 16:18:49.348145: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-16 16:18:49.348159: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-12-16 16:18:49.348176: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-16 16:18:49.348237: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 16:18:49.349083: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 16:18:49.349822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2021-12-16 16:18:49.349855: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-16 16:18:49.883927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-12-16 16:18:49.883958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
      "2021-12-16 16:18:49.883963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
      "2021-12-16 16:18:49.884169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 16:18:49.884866: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 16:18:49.885511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6400 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:09:00.0, compute capability: 6.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 1)         28        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 2)         20        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 2)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 2)           38        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 2)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 40)                1320      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                410       \n",
      "=================================================================\n",
      "Total params: 1,816\n",
      "Trainable params: 1,816\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8b24168e60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8b24168e60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-16 16:18:50.792858: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-16 16:18:51.008102: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 993/1000 [============================>.] - ETA: 0s - loss: 1.9688 - accuracy: 0.2739WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8c0ff220e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8c0ff220e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.9683 - accuracy: 0.2742 - val_loss: 1.8286 - val_accuracy: 0.3286\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.7968 - accuracy: 0.3367 - val_loss: 1.7692 - val_accuracy: 0.3424\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.7546 - accuracy: 0.3540 - val_loss: 1.7447 - val_accuracy: 0.3504\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.7311 - accuracy: 0.3646 - val_loss: 1.7247 - val_accuracy: 0.3686\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.7113 - accuracy: 0.3724 - val_loss: 1.7038 - val_accuracy: 0.3752\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.6979 - accuracy: 0.3767 - val_loss: 1.6876 - val_accuracy: 0.3803\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.6847 - accuracy: 0.3842 - val_loss: 1.7076 - val_accuracy: 0.3705\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.6748 - accuracy: 0.3882 - val_loss: 1.6768 - val_accuracy: 0.3867\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.6649 - accuracy: 0.3927 - val_loss: 1.6613 - val_accuracy: 0.3941\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.6579 - accuracy: 0.3964 - val_loss: 1.6639 - val_accuracy: 0.3944\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.6505 - accuracy: 0.3967 - val_loss: 1.6531 - val_accuracy: 0.3979\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.6446 - accuracy: 0.4006 - val_loss: 1.6537 - val_accuracy: 0.3965\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.6390 - accuracy: 0.4025 - val_loss: 1.6528 - val_accuracy: 0.3996\n",
      "Epoch 14/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.6332 - accuracy: 0.4061 - val_loss: 1.6449 - val_accuracy: 0.4025\n",
      "Epoch 15/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.6282 - accuracy: 0.4070 - val_loss: 1.6328 - val_accuracy: 0.4046\n",
      "Epoch 16/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.6242 - accuracy: 0.4074 - val_loss: 1.6392 - val_accuracy: 0.4049\n",
      "Epoch 17/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.6189 - accuracy: 0.4102 - val_loss: 1.6347 - val_accuracy: 0.4054\n",
      "Epoch 18/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.6154 - accuracy: 0.4115 - val_loss: 1.6280 - val_accuracy: 0.4094\n",
      "Epoch 19/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.6143 - accuracy: 0.4138 - val_loss: 1.6281 - val_accuracy: 0.4108\n",
      "Epoch 20/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.6110 - accuracy: 0.4158 - val_loss: 1.6263 - val_accuracy: 0.4125\n",
      "Epoch 21/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.6056 - accuracy: 0.4187 - val_loss: 1.6177 - val_accuracy: 0.4111\n",
      "Epoch 22/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.6028 - accuracy: 0.4185 - val_loss: 1.6192 - val_accuracy: 0.4082\n",
      "Epoch 23/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.6015 - accuracy: 0.4183 - val_loss: 1.6211 - val_accuracy: 0.4121\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.6263 - accuracy: 0.4125\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.6263 - accuracy: 0.4125\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.6263 - accuracy: 0.4125\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.6263 - accuracy: 0.4125\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.6263 - accuracy: 0.4125\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.6263 - accuracy: 0.4125\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.6263 - accuracy: 0.4125\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.6263 - accuracy: 0.4125\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.6263 - accuracy: 0.4125\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.6263 - accuracy: 0.4125\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.6263 - accuracy: 0.4125\n",
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 2)         56        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 2)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 4)         76        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 4)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 4)           148       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 4)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 80)                5200      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                810       \n",
      "=================================================================\n",
      "Total params: 6,290\n",
      "Trainable params: 6,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8c0ff22290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8c0ff22290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 972/1000 [============================>.] - ETA: 0s - loss: 1.9075 - accuracy: 0.3097WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf57e1560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf57e1560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.9025 - accuracy: 0.3115 - val_loss: 1.7024 - val_accuracy: 0.3929\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.6674 - accuracy: 0.4057 - val_loss: 1.6134 - val_accuracy: 0.4272\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.5964 - accuracy: 0.4296 - val_loss: 1.5938 - val_accuracy: 0.4324\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.5534 - accuracy: 0.4455 - val_loss: 1.5860 - val_accuracy: 0.4370\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.5189 - accuracy: 0.4572 - val_loss: 1.5007 - val_accuracy: 0.4629\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.4891 - accuracy: 0.4686 - val_loss: 1.4953 - val_accuracy: 0.4653\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.4687 - accuracy: 0.4758 - val_loss: 1.4750 - val_accuracy: 0.4700\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.4501 - accuracy: 0.4820 - val_loss: 1.4584 - val_accuracy: 0.4738\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.4348 - accuracy: 0.4896 - val_loss: 1.4422 - val_accuracy: 0.4857\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.4209 - accuracy: 0.4928 - val_loss: 1.4168 - val_accuracy: 0.4933\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.4094 - accuracy: 0.4981 - val_loss: 1.4206 - val_accuracy: 0.4921\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.3981 - accuracy: 0.5018 - val_loss: 1.4238 - val_accuracy: 0.4871\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.3887 - accuracy: 0.5064 - val_loss: 1.4056 - val_accuracy: 0.5037\n",
      "Epoch 14/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.3778 - accuracy: 0.5102 - val_loss: 1.3830 - val_accuracy: 0.5086\n",
      "Epoch 15/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.3717 - accuracy: 0.5128 - val_loss: 1.3874 - val_accuracy: 0.5018\n",
      "Epoch 16/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.3664 - accuracy: 0.5143 - val_loss: 1.3771 - val_accuracy: 0.5043\n",
      "Epoch 17/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.3587 - accuracy: 0.5179 - val_loss: 1.3708 - val_accuracy: 0.5099\n",
      "Epoch 18/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.3508 - accuracy: 0.5187 - val_loss: 1.3631 - val_accuracy: 0.5110\n",
      "Epoch 19/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.3436 - accuracy: 0.5232 - val_loss: 1.3622 - val_accuracy: 0.5172\n",
      "Epoch 20/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.3367 - accuracy: 0.5276 - val_loss: 1.3675 - val_accuracy: 0.5095\n",
      "Epoch 21/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.3319 - accuracy: 0.5272 - val_loss: 1.3593 - val_accuracy: 0.5156\n",
      "Epoch 22/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.3268 - accuracy: 0.5294 - val_loss: 1.3603 - val_accuracy: 0.5158\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.3622 - accuracy: 0.5172\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.3622 - accuracy: 0.5172\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.3622 - accuracy: 0.5172\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.3622 - accuracy: 0.5172\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.3622 - accuracy: 0.5172\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.3622 - accuracy: 0.5172\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.3622 - accuracy: 0.5172\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.3622 - accuracy: 0.5172\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.3622 - accuracy: 0.5172\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.3622 - accuracy: 0.5172\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.3622 - accuracy: 0.5172\n",
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 3)         84        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 16, 16, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 16, 16, 6)         168       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 8, 8, 6)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 8, 8, 6)           330       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 6)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 120)               11640     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1210      \n",
      "=================================================================\n",
      "Total params: 13,432\n",
      "Trainable params: 13,432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf46acc20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf46acc20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 968/1000 [============================>.] - ETA: 0s - loss: 1.8242 - accuracy: 0.3435WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf4639e60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf4639e60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.8181 - accuracy: 0.3461 - val_loss: 1.5747 - val_accuracy: 0.4364\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.5241 - accuracy: 0.4557 - val_loss: 1.4646 - val_accuracy: 0.4758\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.4470 - accuracy: 0.4829 - val_loss: 1.4254 - val_accuracy: 0.4904\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.3995 - accuracy: 0.5030 - val_loss: 1.3919 - val_accuracy: 0.4943\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.3617 - accuracy: 0.5135 - val_loss: 1.3633 - val_accuracy: 0.5094\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.3251 - accuracy: 0.5280 - val_loss: 1.3812 - val_accuracy: 0.5063\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.2973 - accuracy: 0.5395 - val_loss: 1.3080 - val_accuracy: 0.5321\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.2736 - accuracy: 0.5473 - val_loss: 1.2955 - val_accuracy: 0.5339\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.2522 - accuracy: 0.5576 - val_loss: 1.2983 - val_accuracy: 0.5340\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.2378 - accuracy: 0.5628 - val_loss: 1.2895 - val_accuracy: 0.5389\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.2197 - accuracy: 0.5692 - val_loss: 1.2440 - val_accuracy: 0.5527\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.2071 - accuracy: 0.5722 - val_loss: 1.2518 - val_accuracy: 0.5518\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1926 - accuracy: 0.5781 - val_loss: 1.2346 - val_accuracy: 0.5567\n",
      "Epoch 14/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1796 - accuracy: 0.5818 - val_loss: 1.2178 - val_accuracy: 0.5689\n",
      "Epoch 15/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1674 - accuracy: 0.5862 - val_loss: 1.2303 - val_accuracy: 0.5655\n",
      "Epoch 16/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1561 - accuracy: 0.5906 - val_loss: 1.1998 - val_accuracy: 0.5753\n",
      "Epoch 17/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1446 - accuracy: 0.5940 - val_loss: 1.2380 - val_accuracy: 0.5624\n",
      "Epoch 18/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1363 - accuracy: 0.5993 - val_loss: 1.1976 - val_accuracy: 0.5743\n",
      "Epoch 19/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1273 - accuracy: 0.6003 - val_loss: 1.2046 - val_accuracy: 0.5721\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1998 - accuracy: 0.5753\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1998 - accuracy: 0.5753\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1998 - accuracy: 0.5753\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1998 - accuracy: 0.5753\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1998 - accuracy: 0.5753\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1998 - accuracy: 0.5753\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1998 - accuracy: 0.5753\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1998 - accuracy: 0.5753\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1998 - accuracy: 0.5753\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1998 - accuracy: 0.5753\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1998 - accuracy: 0.5753\n",
      "Model: \"functional_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 4)         112       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 16, 16, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 8)         296       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 8, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 8, 8, 8)           584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 4, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 160)               20640     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1610      \n",
      "=================================================================\n",
      "Total params: 23,242\n",
      "Trainable params: 23,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf43d9050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf43d9050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 1.7253 - accuracy: 0.3760WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf44d4710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf44d4710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.7248 - accuracy: 0.3761 - val_loss: 1.5246 - val_accuracy: 0.4458\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.4788 - accuracy: 0.4681 - val_loss: 1.4128 - val_accuracy: 0.4841\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.3853 - accuracy: 0.5010 - val_loss: 1.4233 - val_accuracy: 0.4918\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.3285 - accuracy: 0.5260 - val_loss: 1.3291 - val_accuracy: 0.5168\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.2853 - accuracy: 0.5422 - val_loss: 1.3029 - val_accuracy: 0.5276\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.2467 - accuracy: 0.5565 - val_loss: 1.2412 - val_accuracy: 0.5536\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.2144 - accuracy: 0.5696 - val_loss: 1.2240 - val_accuracy: 0.5606\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1874 - accuracy: 0.5791 - val_loss: 1.1944 - val_accuracy: 0.5723\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1570 - accuracy: 0.5896 - val_loss: 1.1940 - val_accuracy: 0.5769\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1345 - accuracy: 0.5979 - val_loss: 1.1970 - val_accuracy: 0.5711\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1129 - accuracy: 0.6031 - val_loss: 1.1806 - val_accuracy: 0.5813\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0885 - accuracy: 0.6143 - val_loss: 1.1604 - val_accuracy: 0.5873\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0745 - accuracy: 0.6201 - val_loss: 1.1508 - val_accuracy: 0.5853\n",
      "Epoch 14/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0548 - accuracy: 0.6272 - val_loss: 1.1319 - val_accuracy: 0.5913\n",
      "Epoch 15/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0362 - accuracy: 0.6333 - val_loss: 1.1332 - val_accuracy: 0.5944\n",
      "Epoch 16/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0220 - accuracy: 0.6363 - val_loss: 1.1288 - val_accuracy: 0.5953\n",
      "Epoch 17/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0067 - accuracy: 0.6437 - val_loss: 1.1237 - val_accuracy: 0.6035\n",
      "Epoch 18/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9938 - accuracy: 0.6469 - val_loss: 1.1146 - val_accuracy: 0.6022\n",
      "Epoch 19/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9843 - accuracy: 0.6520 - val_loss: 1.1139 - val_accuracy: 0.6104\n",
      "Epoch 20/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9729 - accuracy: 0.6551 - val_loss: 1.1092 - val_accuracy: 0.6077\n",
      "Epoch 21/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9582 - accuracy: 0.6612 - val_loss: 1.1085 - val_accuracy: 0.6079\n",
      "Epoch 22/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9488 - accuracy: 0.6650 - val_loss: 1.1064 - val_accuracy: 0.6087\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1139 - accuracy: 0.6104\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1139 - accuracy: 0.6104\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1139 - accuracy: 0.6104\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1139 - accuracy: 0.6104\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1139 - accuracy: 0.6104\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1139 - accuracy: 0.6104\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1139 - accuracy: 0.6104\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1139 - accuracy: 0.6104\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1139 - accuracy: 0.6104\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1139 - accuracy: 0.6104\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1139 - accuracy: 0.6104\n",
      "Model: \"functional_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 32, 32, 5)         140       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 16, 16, 5)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 16, 16, 10)        460       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 8, 8, 10)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 8, 8, 10)          910       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 4, 4, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 200)               32200     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 35,720\n",
      "Trainable params: 35,720\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf458b4d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf458b4d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 986/1000 [============================>.] - ETA: 0s - loss: 1.6887 - accuracy: 0.3839WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf42530e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf42530e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.6856 - accuracy: 0.3849 - val_loss: 1.5302 - val_accuracy: 0.4444\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.4049 - accuracy: 0.4934 - val_loss: 1.3750 - val_accuracy: 0.5073\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.2934 - accuracy: 0.5397 - val_loss: 1.2380 - val_accuracy: 0.5560\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.2253 - accuracy: 0.5645 - val_loss: 1.1937 - val_accuracy: 0.5741\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1694 - accuracy: 0.5842 - val_loss: 1.2001 - val_accuracy: 0.5724\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1234 - accuracy: 0.6019 - val_loss: 1.1598 - val_accuracy: 0.5873\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0815 - accuracy: 0.6132 - val_loss: 1.1463 - val_accuracy: 0.5952\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0500 - accuracy: 0.6287 - val_loss: 1.1415 - val_accuracy: 0.5939\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0193 - accuracy: 0.6385 - val_loss: 1.0890 - val_accuracy: 0.6182\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9871 - accuracy: 0.6495 - val_loss: 1.0701 - val_accuracy: 0.6234\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9655 - accuracy: 0.6590 - val_loss: 1.0696 - val_accuracy: 0.6230\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9421 - accuracy: 0.6648 - val_loss: 1.0509 - val_accuracy: 0.6301\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9214 - accuracy: 0.6743 - val_loss: 1.0331 - val_accuracy: 0.6363\n",
      "Epoch 14/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8999 - accuracy: 0.6808 - val_loss: 1.0347 - val_accuracy: 0.6406\n",
      "Epoch 15/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8817 - accuracy: 0.6897 - val_loss: 1.0395 - val_accuracy: 0.6360\n",
      "Epoch 16/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8650 - accuracy: 0.6969 - val_loss: 1.0657 - val_accuracy: 0.6355\n",
      "Epoch 17/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8493 - accuracy: 0.6991 - val_loss: 1.0381 - val_accuracy: 0.6398\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0347 - accuracy: 0.6406\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0347 - accuracy: 0.6406\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0347 - accuracy: 0.6406\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0347 - accuracy: 0.6406\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0347 - accuracy: 0.6406\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0347 - accuracy: 0.6406\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0347 - accuracy: 0.6406\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0347 - accuracy: 0.6406\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0347 - accuracy: 0.6406\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0347 - accuracy: 0.6406\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0347 - accuracy: 0.6406\n",
      "Model: \"functional_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 32, 32, 6)         168       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 16, 16, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 16, 16, 12)        660       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 8, 8, 12)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 8, 8, 12)          1308      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 4, 4, 12)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 240)               46320     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                2410      \n",
      "=================================================================\n",
      "Total params: 50,866\n",
      "Trainable params: 50,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf43484d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf43484d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 989/1000 [============================>.] - ETA: 0s - loss: 1.6591 - accuracy: 0.3966WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd45a2050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd45a2050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.6567 - accuracy: 0.3973 - val_loss: 1.4315 - val_accuracy: 0.4876\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.3696 - accuracy: 0.5092 - val_loss: 1.2968 - val_accuracy: 0.5296\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.2628 - accuracy: 0.5488 - val_loss: 1.2634 - val_accuracy: 0.5523\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1772 - accuracy: 0.5811 - val_loss: 1.1711 - val_accuracy: 0.5829\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1156 - accuracy: 0.6049 - val_loss: 1.1517 - val_accuracy: 0.5896\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0596 - accuracy: 0.6247 - val_loss: 1.1272 - val_accuracy: 0.6027\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0189 - accuracy: 0.6405 - val_loss: 1.0960 - val_accuracy: 0.6103\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9799 - accuracy: 0.6542 - val_loss: 1.0760 - val_accuracy: 0.6213\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9438 - accuracy: 0.6679 - val_loss: 1.0953 - val_accuracy: 0.6158\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9133 - accuracy: 0.6777 - val_loss: 1.0674 - val_accuracy: 0.6265\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8867 - accuracy: 0.6888 - val_loss: 1.0157 - val_accuracy: 0.6426\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8594 - accuracy: 0.6971 - val_loss: 1.0181 - val_accuracy: 0.6454\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8350 - accuracy: 0.7075 - val_loss: 1.0100 - val_accuracy: 0.6475\n",
      "Epoch 14/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8123 - accuracy: 0.7134 - val_loss: 1.0088 - val_accuracy: 0.6561\n",
      "Epoch 15/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7914 - accuracy: 0.7218 - val_loss: 1.0581 - val_accuracy: 0.6430\n",
      "Epoch 16/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7704 - accuracy: 0.7283 - val_loss: 1.0497 - val_accuracy: 0.6516\n",
      "Epoch 17/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7477 - accuracy: 0.7363 - val_loss: 1.0445 - val_accuracy: 0.6438\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.6561\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.6561\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.6561\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.6561\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.6561\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.6561\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.6561\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.6561\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.6561\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.6561\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.6561\n",
      "Model: \"functional_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 32, 32, 7)         196       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 16, 16, 7)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 16, 16, 14)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 8, 8, 14)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 8, 8, 14)          1778      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 4, 4, 14)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 224)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 280)               63000     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                2810      \n",
      "=================================================================\n",
      "Total params: 68,680\n",
      "Trainable params: 68,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf46ac050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf46ac050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 989/1000 [============================>.] - ETA: 0s - loss: 1.6334 - accuracy: 0.4061WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf44eff80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf44eff80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.6307 - accuracy: 0.4072 - val_loss: 1.3694 - val_accuracy: 0.5038\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.3052 - accuracy: 0.5301 - val_loss: 1.2468 - val_accuracy: 0.5562\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1867 - accuracy: 0.5763 - val_loss: 1.1739 - val_accuracy: 0.5844\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1093 - accuracy: 0.6074 - val_loss: 1.1518 - val_accuracy: 0.5969\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0441 - accuracy: 0.6318 - val_loss: 1.0936 - val_accuracy: 0.6132\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9926 - accuracy: 0.6502 - val_loss: 1.0533 - val_accuracy: 0.6304\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9493 - accuracy: 0.6667 - val_loss: 1.0320 - val_accuracy: 0.6354\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9068 - accuracy: 0.6805 - val_loss: 1.0301 - val_accuracy: 0.6389\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8659 - accuracy: 0.6952 - val_loss: 1.0042 - val_accuracy: 0.6452\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8308 - accuracy: 0.7058 - val_loss: 1.0416 - val_accuracy: 0.6396\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7973 - accuracy: 0.7188 - val_loss: 0.9609 - val_accuracy: 0.6661\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7676 - accuracy: 0.7309 - val_loss: 0.9844 - val_accuracy: 0.6624\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7362 - accuracy: 0.7411 - val_loss: 0.9879 - val_accuracy: 0.6585\n",
      "Epoch 14/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7152 - accuracy: 0.7486 - val_loss: 1.0036 - val_accuracy: 0.6605\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9609 - accuracy: 0.6661\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9609 - accuracy: 0.6661\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9609 - accuracy: 0.6661\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9609 - accuracy: 0.6661\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9609 - accuracy: 0.6661\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9609 - accuracy: 0.6661\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9609 - accuracy: 0.6661\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9609 - accuracy: 0.6661\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9609 - accuracy: 0.6661\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9609 - accuracy: 0.6661\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9609 - accuracy: 0.6661\n",
      "Model: \"functional_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 32, 32, 8)         224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 16, 16, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 16, 16, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 8, 8, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 8, 8, 16)          2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 320)               82240     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                3210      \n",
      "=================================================================\n",
      "Total params: 89,162\n",
      "Trainable params: 89,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf458b5f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf458b5f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 984/1000 [============================>.] - ETA: 0s - loss: 1.6010 - accuracy: 0.4174WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b240bdb00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b240bdb00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.5982 - accuracy: 0.4188 - val_loss: 1.3498 - val_accuracy: 0.5181\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.3011 - accuracy: 0.5334 - val_loss: 1.2325 - val_accuracy: 0.5596\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1680 - accuracy: 0.5853 - val_loss: 1.1937 - val_accuracy: 0.5720\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0703 - accuracy: 0.6216 - val_loss: 1.0743 - val_accuracy: 0.6167\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9999 - accuracy: 0.6471 - val_loss: 1.0584 - val_accuracy: 0.6270\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9371 - accuracy: 0.6697 - val_loss: 1.0009 - val_accuracy: 0.6495\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8897 - accuracy: 0.6876 - val_loss: 0.9826 - val_accuracy: 0.6563\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8372 - accuracy: 0.7058 - val_loss: 0.9773 - val_accuracy: 0.6599\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8003 - accuracy: 0.7185 - val_loss: 0.9549 - val_accuracy: 0.6684\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7654 - accuracy: 0.7317 - val_loss: 0.9594 - val_accuracy: 0.6635\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7270 - accuracy: 0.7447 - val_loss: 0.9841 - val_accuracy: 0.6613\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6947 - accuracy: 0.7566 - val_loss: 0.9500 - val_accuracy: 0.6745\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6630 - accuracy: 0.7665 - val_loss: 0.9724 - val_accuracy: 0.6791\n",
      "Epoch 14/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6310 - accuracy: 0.7785 - val_loss: 0.9654 - val_accuracy: 0.6800\n",
      "Epoch 15/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6007 - accuracy: 0.7901 - val_loss: 0.9821 - val_accuracy: 0.6769\n",
      "Epoch 16/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5702 - accuracy: 0.7985 - val_loss: 0.9933 - val_accuracy: 0.6826\n",
      "Epoch 17/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5427 - accuracy: 0.8089 - val_loss: 1.0215 - val_accuracy: 0.6784\n",
      "Epoch 18/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5169 - accuracy: 0.8178 - val_loss: 1.0517 - val_accuracy: 0.6711\n",
      "Epoch 19/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4884 - accuracy: 0.8285 - val_loss: 1.0376 - val_accuracy: 0.6790\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9933 - accuracy: 0.6826\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9933 - accuracy: 0.6826\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9933 - accuracy: 0.6826\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9933 - accuracy: 0.6826\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9933 - accuracy: 0.6826\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9933 - accuracy: 0.6826\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9933 - accuracy: 0.6826\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9933 - accuracy: 0.6826\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9933 - accuracy: 0.6826\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9933 - accuracy: 0.6826\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9933 - accuracy: 0.6826\n",
      "Model: \"functional_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 32, 32, 9)         252       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 16, 16, 9)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 16, 16, 18)        1476      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 8, 8, 18)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 8, 8, 18)          2934      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 4, 4, 18)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 360)               104040    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                3610      \n",
      "=================================================================\n",
      "Total params: 112,312\n",
      "Trainable params: 112,312\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf58be560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf58be560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 968/1000 [============================>.] - ETA: 0s - loss: 1.6112 - accuracy: 0.4125WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf45bc170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf45bc170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.6025 - accuracy: 0.4164 - val_loss: 1.3358 - val_accuracy: 0.5311\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.2437 - accuracy: 0.5561 - val_loss: 1.2886 - val_accuracy: 0.5494\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1001 - accuracy: 0.6120 - val_loss: 1.1519 - val_accuracy: 0.5916\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0097 - accuracy: 0.6432 - val_loss: 1.0103 - val_accuracy: 0.6449\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9457 - accuracy: 0.6656 - val_loss: 0.9598 - val_accuracy: 0.6613\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8865 - accuracy: 0.6887 - val_loss: 0.9404 - val_accuracy: 0.6755\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8334 - accuracy: 0.7073 - val_loss: 0.9304 - val_accuracy: 0.6698\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7968 - accuracy: 0.7203 - val_loss: 0.9018 - val_accuracy: 0.6837\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7559 - accuracy: 0.7343 - val_loss: 0.8859 - val_accuracy: 0.6914\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7157 - accuracy: 0.7469 - val_loss: 0.8978 - val_accuracy: 0.6922\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6862 - accuracy: 0.7578 - val_loss: 0.8689 - val_accuracy: 0.6990\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6488 - accuracy: 0.7723 - val_loss: 0.9414 - val_accuracy: 0.6792\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6167 - accuracy: 0.7823 - val_loss: 0.9315 - val_accuracy: 0.6889\n",
      "Epoch 14/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5881 - accuracy: 0.7908 - val_loss: 0.9068 - val_accuracy: 0.6953\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8689 - accuracy: 0.6990\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8689 - accuracy: 0.6990\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8689 - accuracy: 0.6990\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8689 - accuracy: 0.6990\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8689 - accuracy: 0.6990\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8689 - accuracy: 0.6990\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8689 - accuracy: 0.6990\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8689 - accuracy: 0.6990\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8689 - accuracy: 0.6990\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8689 - accuracy: 0.6990\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8689 - accuracy: 0.6990\n",
      "Model: \"functional_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 32, 32, 10)        280       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 16, 16, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 16, 16, 20)        1820      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 8, 8, 20)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 8, 8, 20)          3620      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 4, 4, 20)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 400)               128400    \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                4010      \n",
      "=================================================================\n",
      "Total params: 138,130\n",
      "Trainable params: 138,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf473c680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf473c680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 993/1000 [============================>.] - ETA: 0s - loss: 1.5750 - accuracy: 0.4295WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf456d050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf456d050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.5738 - accuracy: 0.4300 - val_loss: 1.4154 - val_accuracy: 0.4876\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.2571 - accuracy: 0.5507 - val_loss: 1.1586 - val_accuracy: 0.5849\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1091 - accuracy: 0.6068 - val_loss: 1.0863 - val_accuracy: 0.6152\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0095 - accuracy: 0.6414 - val_loss: 1.0265 - val_accuracy: 0.6405\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9277 - accuracy: 0.6737 - val_loss: 1.0454 - val_accuracy: 0.6386\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8610 - accuracy: 0.6974 - val_loss: 0.9609 - val_accuracy: 0.6675\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8089 - accuracy: 0.7154 - val_loss: 0.9654 - val_accuracy: 0.6708\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7517 - accuracy: 0.7357 - val_loss: 0.9001 - val_accuracy: 0.6875\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7028 - accuracy: 0.7533 - val_loss: 0.9047 - val_accuracy: 0.6929\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6595 - accuracy: 0.7688 - val_loss: 0.9270 - val_accuracy: 0.6893\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6147 - accuracy: 0.7841 - val_loss: 0.9213 - val_accuracy: 0.6896\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5794 - accuracy: 0.7974 - val_loss: 0.9201 - val_accuracy: 0.6948\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5393 - accuracy: 0.8100 - val_loss: 0.9576 - val_accuracy: 0.6998\n",
      "Epoch 14/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5012 - accuracy: 0.8254 - val_loss: 1.0006 - val_accuracy: 0.6857\n",
      "Epoch 15/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4662 - accuracy: 0.8357 - val_loss: 1.0235 - val_accuracy: 0.6938\n",
      "Epoch 16/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4268 - accuracy: 0.8503 - val_loss: 1.0338 - val_accuracy: 0.6911\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9576 - accuracy: 0.6998\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9576 - accuracy: 0.6998\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9576 - accuracy: 0.6998\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9576 - accuracy: 0.6998\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9576 - accuracy: 0.6998\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9576 - accuracy: 0.6998\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9576 - accuracy: 0.6998\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9576 - accuracy: 0.6998\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9576 - accuracy: 0.6998\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9576 - accuracy: 0.6998\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9576 - accuracy: 0.6998\n",
      "Model: \"functional_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 32, 32, 11)        308       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 16, 16, 11)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 16, 16, 22)        2200      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 8, 8, 22)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 8, 8, 22)          4378      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 4, 4, 22)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 352)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 440)               155320    \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                4410      \n",
      "=================================================================\n",
      "Total params: 166,616\n",
      "Trainable params: 166,616\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf599cef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf599cef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1.5336 - accuracy: 0.4395WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd3b13830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd3b13830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.5336 - accuracy: 0.4395 - val_loss: 1.2616 - val_accuracy: 0.5500\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1988 - accuracy: 0.5719 - val_loss: 1.1568 - val_accuracy: 0.5891\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0499 - accuracy: 0.6288 - val_loss: 1.0521 - val_accuracy: 0.6265\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9614 - accuracy: 0.6603 - val_loss: 0.9684 - val_accuracy: 0.6600\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8805 - accuracy: 0.6888 - val_loss: 0.9305 - val_accuracy: 0.6780\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8208 - accuracy: 0.7104 - val_loss: 0.9089 - val_accuracy: 0.6834\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7664 - accuracy: 0.7314 - val_loss: 0.9265 - val_accuracy: 0.6794\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7139 - accuracy: 0.7486 - val_loss: 0.8860 - val_accuracy: 0.7025\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6656 - accuracy: 0.7654 - val_loss: 0.8780 - val_accuracy: 0.6998\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6179 - accuracy: 0.7811 - val_loss: 0.9094 - val_accuracy: 0.6944\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5723 - accuracy: 0.7985 - val_loss: 0.8906 - val_accuracy: 0.7084\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5298 - accuracy: 0.8150 - val_loss: 0.9960 - val_accuracy: 0.6937\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4863 - accuracy: 0.8285 - val_loss: 0.9341 - val_accuracy: 0.7060\n",
      "Epoch 14/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4461 - accuracy: 0.8418 - val_loss: 0.9721 - val_accuracy: 0.7101\n",
      "Epoch 15/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4036 - accuracy: 0.8562 - val_loss: 1.0172 - val_accuracy: 0.7057\n",
      "Epoch 16/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3621 - accuracy: 0.8703 - val_loss: 1.0804 - val_accuracy: 0.6936\n",
      "Epoch 17/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3268 - accuracy: 0.8861 - val_loss: 1.1799 - val_accuracy: 0.6932\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9721 - accuracy: 0.7101\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9721 - accuracy: 0.7101\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9721 - accuracy: 0.7101\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9721 - accuracy: 0.7101\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9721 - accuracy: 0.7101\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9721 - accuracy: 0.7101\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9721 - accuracy: 0.7101\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9721 - accuracy: 0.7101\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9721 - accuracy: 0.7101\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9721 - accuracy: 0.7101\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9721 - accuracy: 0.7101\n",
      "Model: \"functional_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 32, 32, 12)        336       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 16, 16, 12)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 16, 16, 24)        2616      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 8, 8, 24)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 8, 8, 24)          5208      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 4, 4, 24)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 480)               184800    \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                4810      \n",
      "=================================================================\n",
      "Total params: 197,770\n",
      "Trainable params: 197,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd3996d40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd3996d40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 986/1000 [============================>.] - ETA: 0s - loss: 1.5377 - accuracy: 0.4451WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd3952560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd3952560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.5348 - accuracy: 0.4464 - val_loss: 1.2794 - val_accuracy: 0.5456\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1757 - accuracy: 0.5835 - val_loss: 1.0803 - val_accuracy: 0.6176\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0271 - accuracy: 0.6383 - val_loss: 1.0461 - val_accuracy: 0.6286\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9253 - accuracy: 0.6740 - val_loss: 0.9794 - val_accuracy: 0.6578\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8459 - accuracy: 0.7015 - val_loss: 0.9494 - val_accuracy: 0.6684\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7767 - accuracy: 0.7270 - val_loss: 0.9535 - val_accuracy: 0.6709\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7139 - accuracy: 0.7496 - val_loss: 0.8725 - val_accuracy: 0.6978\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6560 - accuracy: 0.7707 - val_loss: 0.8583 - val_accuracy: 0.7035\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5995 - accuracy: 0.7896 - val_loss: 0.8582 - val_accuracy: 0.7074\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5417 - accuracy: 0.8098 - val_loss: 0.8573 - val_accuracy: 0.7148\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4981 - accuracy: 0.8249 - val_loss: 0.8943 - val_accuracy: 0.7139\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4487 - accuracy: 0.8403 - val_loss: 0.9528 - val_accuracy: 0.7122\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4008 - accuracy: 0.8570 - val_loss: 1.0425 - val_accuracy: 0.6922\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8573 - accuracy: 0.7148\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8573 - accuracy: 0.7148\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8573 - accuracy: 0.7148\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8573 - accuracy: 0.7148\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8573 - accuracy: 0.7148\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8573 - accuracy: 0.7148\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8573 - accuracy: 0.7148\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8573 - accuracy: 0.7148\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8573 - accuracy: 0.7148\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8573 - accuracy: 0.7148\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8573 - accuracy: 0.7148\n",
      "Model: \"functional_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 32, 32, 13)        364       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 16, 16, 13)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 16, 16, 26)        3068      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 8, 8, 26)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 8, 8, 26)          6110      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 4, 4, 26)          0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 520)               216840    \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 10)                5210      \n",
      "=================================================================\n",
      "Total params: 231,592\n",
      "Trainable params: 231,592\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf599c8c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf599c8c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 989/1000 [============================>.] - ETA: 0s - loss: 1.5132 - accuracy: 0.4540WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd3c73560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd3c73560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.5112 - accuracy: 0.4549 - val_loss: 1.2629 - val_accuracy: 0.5510\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1607 - accuracy: 0.5864 - val_loss: 1.0730 - val_accuracy: 0.6241\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0103 - accuracy: 0.6416 - val_loss: 1.0127 - val_accuracy: 0.6465\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9028 - accuracy: 0.6816 - val_loss: 0.9757 - val_accuracy: 0.6611\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8186 - accuracy: 0.7107 - val_loss: 0.9196 - val_accuracy: 0.6798\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7405 - accuracy: 0.7389 - val_loss: 0.8602 - val_accuracy: 0.7060\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6771 - accuracy: 0.7609 - val_loss: 0.8623 - val_accuracy: 0.7096\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6071 - accuracy: 0.7860 - val_loss: 0.8540 - val_accuracy: 0.7181\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5460 - accuracy: 0.8077 - val_loss: 0.8598 - val_accuracy: 0.7138\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4881 - accuracy: 0.8270 - val_loss: 0.9076 - val_accuracy: 0.7149\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4296 - accuracy: 0.8494 - val_loss: 0.9514 - val_accuracy: 0.7084\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8540 - accuracy: 0.7181\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8540 - accuracy: 0.7181\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8540 - accuracy: 0.7181\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8540 - accuracy: 0.7181\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8540 - accuracy: 0.7181\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8540 - accuracy: 0.7181\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8540 - accuracy: 0.7181\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8540 - accuracy: 0.7181\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8540 - accuracy: 0.7181\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8540 - accuracy: 0.7181\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8540 - accuracy: 0.7181\n",
      "Model: \"functional_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 32, 32, 14)        392       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 16, 16, 14)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 16, 16, 28)        3556      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 8, 8, 28)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 8, 8, 28)          7084      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 4, 4, 28)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 560)               251440    \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                5610      \n",
      "=================================================================\n",
      "Total params: 268,082\n",
      "Trainable params: 268,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd3c73710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd3c73710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 985/1000 [============================>.] - ETA: 0s - loss: 1.5127 - accuracy: 0.4505WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd4590320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd4590320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.5094 - accuracy: 0.4518 - val_loss: 1.2200 - val_accuracy: 0.5617\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1516 - accuracy: 0.5905 - val_loss: 1.0600 - val_accuracy: 0.6254\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9871 - accuracy: 0.6476 - val_loss: 0.9577 - val_accuracy: 0.6616\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8791 - accuracy: 0.6913 - val_loss: 0.9423 - val_accuracy: 0.6731\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7896 - accuracy: 0.7202 - val_loss: 0.9106 - val_accuracy: 0.6832\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7076 - accuracy: 0.7507 - val_loss: 0.8394 - val_accuracy: 0.7075\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6358 - accuracy: 0.7772 - val_loss: 0.8548 - val_accuracy: 0.7075\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5688 - accuracy: 0.8007 - val_loss: 0.8618 - val_accuracy: 0.7151\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5020 - accuracy: 0.8242 - val_loss: 0.8494 - val_accuracy: 0.7197\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4385 - accuracy: 0.8467 - val_loss: 0.9232 - val_accuracy: 0.7119\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3883 - accuracy: 0.8629 - val_loss: 0.9484 - val_accuracy: 0.7190\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3255 - accuracy: 0.8852 - val_loss: 1.0116 - val_accuracy: 0.7164\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8494 - accuracy: 0.7197\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8494 - accuracy: 0.7197\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8494 - accuracy: 0.7197\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8494 - accuracy: 0.7197\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8494 - accuracy: 0.7197\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8494 - accuracy: 0.7197\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8494 - accuracy: 0.7197\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8494 - accuracy: 0.7197\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8494 - accuracy: 0.7197\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8494 - accuracy: 0.7197\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8494 - accuracy: 0.7197\n",
      "Model: \"functional_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 32, 32, 15)        420       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 16, 16, 15)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 16, 16, 30)        4080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 8, 8, 30)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 8, 8, 30)          8130      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling (None, 4, 4, 30)          0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 480)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 600)               288600    \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 10)                6010      \n",
      "=================================================================\n",
      "Total params: 307,240\n",
      "Trainable params: 307,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf44cc050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf44cc050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 992/1000 [============================>.] - ETA: 0s - loss: 1.4806 - accuracy: 0.4662WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf5827950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf5827950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.4773 - accuracy: 0.4675 - val_loss: 1.1793 - val_accuracy: 0.5827\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1055 - accuracy: 0.6087 - val_loss: 1.0376 - val_accuracy: 0.6288\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9515 - accuracy: 0.6646 - val_loss: 0.9805 - val_accuracy: 0.6533\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8429 - accuracy: 0.7034 - val_loss: 0.9132 - val_accuracy: 0.6786\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7573 - accuracy: 0.7329 - val_loss: 0.8582 - val_accuracy: 0.7007\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6761 - accuracy: 0.7618 - val_loss: 0.8543 - val_accuracy: 0.7096\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6055 - accuracy: 0.7859 - val_loss: 0.8596 - val_accuracy: 0.7101\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5346 - accuracy: 0.8100 - val_loss: 0.8649 - val_accuracy: 0.7168\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4744 - accuracy: 0.8339 - val_loss: 0.8696 - val_accuracy: 0.7190\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4082 - accuracy: 0.8567 - val_loss: 0.9437 - val_accuracy: 0.7128\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3517 - accuracy: 0.8770 - val_loss: 0.9750 - val_accuracy: 0.7176\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2939 - accuracy: 0.8967 - val_loss: 1.0693 - val_accuracy: 0.7065\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8696 - accuracy: 0.7190\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8696 - accuracy: 0.7190\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8696 - accuracy: 0.7190\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8696 - accuracy: 0.7190\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8696 - accuracy: 0.7190\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8696 - accuracy: 0.7190\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8696 - accuracy: 0.7190\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8696 - accuracy: 0.7190\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8696 - accuracy: 0.7190\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8696 - accuracy: 0.7190\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8696 - accuracy: 0.7190\n",
      "Model: \"functional_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 32, 32, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 16, 16, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 640)               328320    \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 10)                6410      \n",
      "=================================================================\n",
      "Total params: 349,066\n",
      "Trainable params: 349,066\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf59af050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf59af050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1.4915 - accuracy: 0.4577WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd386ec20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd386ec20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.4915 - accuracy: 0.4577 - val_loss: 1.1937 - val_accuracy: 0.5744\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1168 - accuracy: 0.6018 - val_loss: 1.0364 - val_accuracy: 0.6320\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9528 - accuracy: 0.6638 - val_loss: 0.9318 - val_accuracy: 0.6747\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8381 - accuracy: 0.7045 - val_loss: 0.8965 - val_accuracy: 0.6862\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7419 - accuracy: 0.7382 - val_loss: 0.8511 - val_accuracy: 0.7042\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6618 - accuracy: 0.7664 - val_loss: 0.8431 - val_accuracy: 0.7106\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5804 - accuracy: 0.7972 - val_loss: 0.8510 - val_accuracy: 0.7110\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5088 - accuracy: 0.8222 - val_loss: 0.8691 - val_accuracy: 0.7170\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4355 - accuracy: 0.8464 - val_loss: 0.9369 - val_accuracy: 0.7077\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3672 - accuracy: 0.8698 - val_loss: 0.9759 - val_accuracy: 0.7182\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3058 - accuracy: 0.8915 - val_loss: 1.0469 - val_accuracy: 0.7153\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2605 - accuracy: 0.9077 - val_loss: 1.1694 - val_accuracy: 0.7052\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2080 - accuracy: 0.9265 - val_loss: 1.2630 - val_accuracy: 0.7038\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9759 - accuracy: 0.7182\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9759 - accuracy: 0.7182\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9759 - accuracy: 0.7182\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9759 - accuracy: 0.7182\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9759 - accuracy: 0.7182\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9759 - accuracy: 0.7182\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9759 - accuracy: 0.7182\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9759 - accuracy: 0.7182\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9759 - accuracy: 0.7182\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9759 - accuracy: 0.7182\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9759 - accuracy: 0.7182\n",
      "Model: \"functional_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 32, 32, 17)        476       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_48 (MaxPooling (None, 16, 16, 17)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 16, 16, 34)        5236      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 8, 8, 34)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 8, 8, 34)          10438     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 4, 4, 34)          0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 544)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 680)               370600    \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 10)                6810      \n",
      "=================================================================\n",
      "Total params: 393,560\n",
      "Trainable params: 393,560\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf42f6c20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf42f6c20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 992/1000 [============================>.] - ETA: 0s - loss: 1.4504 - accuracy: 0.4739WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf57dcc20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf57dcc20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.4486 - accuracy: 0.4747 - val_loss: 1.1751 - val_accuracy: 0.5814\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0867 - accuracy: 0.6142 - val_loss: 1.0037 - val_accuracy: 0.6483\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9281 - accuracy: 0.6722 - val_loss: 0.8985 - val_accuracy: 0.6816\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8072 - accuracy: 0.7163 - val_loss: 0.8404 - val_accuracy: 0.7058\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7200 - accuracy: 0.7481 - val_loss: 0.8534 - val_accuracy: 0.7057\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6334 - accuracy: 0.7761 - val_loss: 0.8202 - val_accuracy: 0.7225\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5528 - accuracy: 0.8057 - val_loss: 0.8175 - val_accuracy: 0.7266\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4791 - accuracy: 0.8300 - val_loss: 0.8542 - val_accuracy: 0.7269\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4110 - accuracy: 0.8554 - val_loss: 0.8972 - val_accuracy: 0.7206\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3450 - accuracy: 0.8801 - val_loss: 0.9336 - val_accuracy: 0.7226\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2815 - accuracy: 0.9016 - val_loss: 1.0105 - val_accuracy: 0.7175\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8542 - accuracy: 0.7269\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8542 - accuracy: 0.7269\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8542 - accuracy: 0.7269\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8542 - accuracy: 0.7269\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8542 - accuracy: 0.7269\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8542 - accuracy: 0.7269\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8542 - accuracy: 0.7269\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8542 - accuracy: 0.7269\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8542 - accuracy: 0.7269\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8542 - accuracy: 0.7269\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8542 - accuracy: 0.7269\n",
      "Model: \"functional_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 32, 32, 18)        504       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 16, 16, 18)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 16, 16, 36)        5868      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_52 (MaxPooling (None, 8, 8, 36)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 8, 8, 36)          11700     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_53 (MaxPooling (None, 4, 4, 36)          0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 720)               415440    \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                7210      \n",
      "=================================================================\n",
      "Total params: 440,722\n",
      "Trainable params: 440,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd477a320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd477a320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 1.4610 - accuracy: 0.4718WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b1879f560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b1879f560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.4601 - accuracy: 0.4722 - val_loss: 1.1455 - val_accuracy: 0.5873\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0617 - accuracy: 0.6249 - val_loss: 0.9767 - val_accuracy: 0.6564\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8919 - accuracy: 0.6847 - val_loss: 0.8949 - val_accuracy: 0.6916\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7673 - accuracy: 0.7303 - val_loss: 0.8709 - val_accuracy: 0.7094\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6650 - accuracy: 0.7662 - val_loss: 0.8156 - val_accuracy: 0.7205\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5796 - accuracy: 0.7969 - val_loss: 0.8432 - val_accuracy: 0.7143\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4906 - accuracy: 0.8275 - val_loss: 0.8540 - val_accuracy: 0.7239\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4134 - accuracy: 0.8533 - val_loss: 0.8693 - val_accuracy: 0.7297\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3339 - accuracy: 0.8828 - val_loss: 0.9868 - val_accuracy: 0.7193\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2666 - accuracy: 0.9058 - val_loss: 1.0429 - val_accuracy: 0.7221\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2135 - accuracy: 0.9250 - val_loss: 1.1329 - val_accuracy: 0.7200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8693 - accuracy: 0.7297\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8693 - accuracy: 0.7297\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8693 - accuracy: 0.7297\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8693 - accuracy: 0.7297\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8693 - accuracy: 0.7297\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8693 - accuracy: 0.7297\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8693 - accuracy: 0.7297\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8693 - accuracy: 0.7297\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8693 - accuracy: 0.7297\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8693 - accuracy: 0.7297\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8693 - accuracy: 0.7297\n",
      "Model: \"functional_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 32, 32, 19)        532       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_54 (MaxPooling (None, 16, 16, 19)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 16, 16, 38)        6536      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_55 (MaxPooling (None, 8, 8, 38)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 8, 8, 38)          13034     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_56 (MaxPooling (None, 4, 4, 38)          0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 608)               0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 760)               462840    \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 10)                7610      \n",
      "=================================================================\n",
      "Total params: 490,552\n",
      "Trainable params: 490,552\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf5909320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf5909320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 983/1000 [============================>.] - ETA: 0s - loss: 1.4539 - accuracy: 0.4738WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd4590560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd4590560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.4494 - accuracy: 0.4757 - val_loss: 1.1956 - val_accuracy: 0.5754\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0633 - accuracy: 0.6241 - val_loss: 0.9887 - val_accuracy: 0.6509\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8969 - accuracy: 0.6844 - val_loss: 0.9094 - val_accuracy: 0.6848\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7861 - accuracy: 0.7236 - val_loss: 0.8328 - val_accuracy: 0.7123\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6938 - accuracy: 0.7556 - val_loss: 0.8148 - val_accuracy: 0.7205\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6116 - accuracy: 0.7844 - val_loss: 0.8037 - val_accuracy: 0.7332\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5360 - accuracy: 0.8116 - val_loss: 0.8190 - val_accuracy: 0.7345\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4608 - accuracy: 0.8382 - val_loss: 0.8414 - val_accuracy: 0.7334\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3933 - accuracy: 0.8608 - val_loss: 0.8803 - val_accuracy: 0.7322\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3162 - accuracy: 0.8895 - val_loss: 0.9348 - val_accuracy: 0.7295\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8190 - accuracy: 0.7345\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8190 - accuracy: 0.7345\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8190 - accuracy: 0.7345\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8190 - accuracy: 0.7345\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8190 - accuracy: 0.7345\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8190 - accuracy: 0.7345\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8190 - accuracy: 0.7345\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8190 - accuracy: 0.7345\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8190 - accuracy: 0.7345\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8190 - accuracy: 0.7345\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8190 - accuracy: 0.7345\n",
      "Model: \"functional_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 32, 32, 20)        560       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_57 (MaxPooling (None, 16, 16, 20)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 16, 16, 40)        7240      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_58 (MaxPooling (None, 8, 8, 40)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 8, 8, 40)          14440     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_59 (MaxPooling (None, 4, 4, 40)          0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 800)               512800    \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 10)                8010      \n",
      "=================================================================\n",
      "Total params: 543,050\n",
      "Trainable params: 543,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd3c63440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd3c63440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1.4231 - accuracy: 0.4829WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8c0ff23ef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8c0ff23ef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.4228 - accuracy: 0.4830 - val_loss: 1.1780 - val_accuracy: 0.5809\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0401 - accuracy: 0.6312 - val_loss: 0.9695 - val_accuracy: 0.6633\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8729 - accuracy: 0.6925 - val_loss: 0.8903 - val_accuracy: 0.6868\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7523 - accuracy: 0.7347 - val_loss: 0.8163 - val_accuracy: 0.7176\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6652 - accuracy: 0.7664 - val_loss: 0.8176 - val_accuracy: 0.7179\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5756 - accuracy: 0.7982 - val_loss: 0.7885 - val_accuracy: 0.7365\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4942 - accuracy: 0.8257 - val_loss: 0.8339 - val_accuracy: 0.7311\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4102 - accuracy: 0.8563 - val_loss: 0.9549 - val_accuracy: 0.7117\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3386 - accuracy: 0.8805 - val_loss: 0.9784 - val_accuracy: 0.7256\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7885 - accuracy: 0.7365\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7885 - accuracy: 0.7365\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7885 - accuracy: 0.7365\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7885 - accuracy: 0.7365\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7885 - accuracy: 0.7365\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7885 - accuracy: 0.7365\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7885 - accuracy: 0.7365\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7885 - accuracy: 0.7365\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7885 - accuracy: 0.7365\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7885 - accuracy: 0.7365\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7885 - accuracy: 0.7365\n",
      "Model: \"functional_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 32, 32, 21)        588       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_60 (MaxPooling (None, 16, 16, 21)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 16, 16, 42)        7980      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_61 (MaxPooling (None, 8, 8, 42)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 8, 8, 42)          15918     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_62 (MaxPooling (None, 4, 4, 42)          0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 672)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 840)               565320    \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 10)                8410      \n",
      "=================================================================\n",
      "Total params: 598,216\n",
      "Trainable params: 598,216\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd459aef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd459aef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 1.4100 - accuracy: 0.4893WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd4579680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd4579680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.4094 - accuracy: 0.4895 - val_loss: 1.1075 - val_accuracy: 0.6100\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0048 - accuracy: 0.6449 - val_loss: 0.9260 - val_accuracy: 0.6783\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8405 - accuracy: 0.7052 - val_loss: 0.8527 - val_accuracy: 0.7073\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7181 - accuracy: 0.7482 - val_loss: 0.8148 - val_accuracy: 0.7169\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6219 - accuracy: 0.7810 - val_loss: 0.7620 - val_accuracy: 0.7414\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5290 - accuracy: 0.8146 - val_loss: 0.7937 - val_accuracy: 0.7311\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4463 - accuracy: 0.8413 - val_loss: 0.7990 - val_accuracy: 0.7497\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3607 - accuracy: 0.8743 - val_loss: 0.8228 - val_accuracy: 0.7481\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2895 - accuracy: 0.8970 - val_loss: 0.8874 - val_accuracy: 0.7488\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2233 - accuracy: 0.9211 - val_loss: 1.0020 - val_accuracy: 0.7294\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7990 - accuracy: 0.7497\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7990 - accuracy: 0.7497\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7990 - accuracy: 0.7497\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7990 - accuracy: 0.7497\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7990 - accuracy: 0.7497\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7990 - accuracy: 0.7497\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7339 - accuracy: 0.7610WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0036s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7990 - accuracy: 0.7497\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7990 - accuracy: 0.7497\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7990 - accuracy: 0.7497\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7990 - accuracy: 0.7497\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7990 - accuracy: 0.7497\n",
      "Model: \"functional_43\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_22 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 32, 32, 22)        616       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_63 (MaxPooling (None, 16, 16, 22)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_64 (Conv2D)           (None, 16, 16, 44)        8756      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_64 (MaxPooling (None, 8, 8, 44)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_65 (Conv2D)           (None, 8, 8, 44)          17468     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_65 (MaxPooling (None, 4, 4, 44)          0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 704)               0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 880)               620400    \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 10)                8810      \n",
      "=================================================================\n",
      "Total params: 656,050\n",
      "Trainable params: 656,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd38d7b00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd38d7b00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 979/1000 [============================>.] - ETA: 0s - loss: 1.4449 - accuracy: 0.4767WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd3c87440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd3c87440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.4394 - accuracy: 0.4785 - val_loss: 1.1348 - val_accuracy: 0.5954\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0432 - accuracy: 0.6325 - val_loss: 1.0284 - val_accuracy: 0.6365\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8644 - accuracy: 0.6957 - val_loss: 0.8840 - val_accuracy: 0.6916\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7505 - accuracy: 0.7372 - val_loss: 0.8125 - val_accuracy: 0.7170\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6485 - accuracy: 0.7729 - val_loss: 0.8169 - val_accuracy: 0.7189\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5531 - accuracy: 0.8055 - val_loss: 0.7909 - val_accuracy: 0.7383\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4625 - accuracy: 0.8389 - val_loss: 0.8129 - val_accuracy: 0.7382\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3867 - accuracy: 0.8627 - val_loss: 0.8504 - val_accuracy: 0.7414\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3030 - accuracy: 0.8928 - val_loss: 0.9519 - val_accuracy: 0.7265\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2426 - accuracy: 0.9147 - val_loss: 0.9826 - val_accuracy: 0.7320\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1877 - accuracy: 0.9348 - val_loss: 1.1476 - val_accuracy: 0.7258\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8504 - accuracy: 0.7414\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8504 - accuracy: 0.7414\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8504 - accuracy: 0.7414\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8504 - accuracy: 0.7414\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8504 - accuracy: 0.7414\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8504 - accuracy: 0.7414\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8504 - accuracy: 0.7414\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8504 - accuracy: 0.7414\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8504 - accuracy: 0.7414\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8504 - accuracy: 0.7414\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8504 - accuracy: 0.7414\n",
      "Model: \"functional_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_23 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_66 (Conv2D)           (None, 32, 32, 23)        644       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_66 (MaxPooling (None, 16, 16, 23)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_67 (Conv2D)           (None, 16, 16, 46)        9568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_67 (MaxPooling (None, 8, 8, 46)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_68 (Conv2D)           (None, 8, 8, 46)          19090     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_68 (MaxPooling (None, 4, 4, 46)          0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 736)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 920)               678040    \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 10)                9210      \n",
      "=================================================================\n",
      "Total params: 716,552\n",
      "Trainable params: 716,552\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf446a050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf446a050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 993/1000 [============================>.] - ETA: 0s - loss: 1.4441 - accuracy: 0.4740WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd3917ef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd3917ef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.4424 - accuracy: 0.4746 - val_loss: 1.1735 - val_accuracy: 0.5782\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0597 - accuracy: 0.6222 - val_loss: 0.9635 - val_accuracy: 0.6624\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8850 - accuracy: 0.6865 - val_loss: 0.9418 - val_accuracy: 0.6635\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7637 - accuracy: 0.7309 - val_loss: 0.8512 - val_accuracy: 0.7007\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6647 - accuracy: 0.7670 - val_loss: 0.8206 - val_accuracy: 0.7172\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5664 - accuracy: 0.7992 - val_loss: 0.8184 - val_accuracy: 0.7163\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4793 - accuracy: 0.8324 - val_loss: 0.8312 - val_accuracy: 0.7221\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3903 - accuracy: 0.8649 - val_loss: 0.8971 - val_accuracy: 0.7233\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3109 - accuracy: 0.8908 - val_loss: 0.9257 - val_accuracy: 0.7215\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2425 - accuracy: 0.9146 - val_loss: 1.0432 - val_accuracy: 0.7308\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1915 - accuracy: 0.9329 - val_loss: 1.1453 - val_accuracy: 0.7271\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1600 - accuracy: 0.9432 - val_loss: 1.2647 - val_accuracy: 0.7247\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1336 - accuracy: 0.9531 - val_loss: 1.3916 - val_accuracy: 0.7167\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0080 - accuracy: 0.7380WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_test_batch_end` time: 0.0034s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0432 - accuracy: 0.7308\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0080 - accuracy: 0.7380WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0034s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.0432 - accuracy: 0.7308\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0432 - accuracy: 0.7308\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.0432 - accuracy: 0.7308\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0432 - accuracy: 0.7308\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0432 - accuracy: 0.7308\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0432 - accuracy: 0.7308\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0080 - accuracy: 0.7380WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0038s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.0432 - accuracy: 0.7308\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.0432 - accuracy: 0.7308\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.0432 - accuracy: 0.7308\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0432 - accuracy: 0.7308\n",
      "Model: \"functional_47\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_24 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_69 (Conv2D)           (None, 32, 32, 24)        672       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_69 (MaxPooling (None, 16, 16, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_70 (Conv2D)           (None, 16, 16, 48)        10416     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_70 (MaxPooling (None, 8, 8, 48)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_71 (Conv2D)           (None, 8, 8, 48)          20784     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_71 (MaxPooling (None, 4, 4, 48)          0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 960)               738240    \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 10)                9610      \n",
      "=================================================================\n",
      "Total params: 779,722\n",
      "Trainable params: 779,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8b186fad40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8b186fad40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 978/1000 [============================>.] - ETA: 0s - loss: 1.4301 - accuracy: 0.4835WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd3bd0b00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd3bd0b00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.4227 - accuracy: 0.4861 - val_loss: 1.1130 - val_accuracy: 0.6030\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0174 - accuracy: 0.6408 - val_loss: 0.9733 - val_accuracy: 0.6543\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8452 - accuracy: 0.7036 - val_loss: 0.8669 - val_accuracy: 0.7030\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7273 - accuracy: 0.7459 - val_loss: 0.8784 - val_accuracy: 0.6993\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6257 - accuracy: 0.7796 - val_loss: 0.7743 - val_accuracy: 0.7338\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5284 - accuracy: 0.8150 - val_loss: 0.7958 - val_accuracy: 0.7399\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4480 - accuracy: 0.8403 - val_loss: 0.8571 - val_accuracy: 0.7232\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3583 - accuracy: 0.8747 - val_loss: 0.8540 - val_accuracy: 0.7375\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2823 - accuracy: 0.9010 - val_loss: 0.9403 - val_accuracy: 0.7346\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7958 - accuracy: 0.7399\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7958 - accuracy: 0.7399\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7958 - accuracy: 0.7399\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7958 - accuracy: 0.7399\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7958 - accuracy: 0.7399\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7958 - accuracy: 0.7399\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7958 - accuracy: 0.7399\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7958 - accuracy: 0.7399\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7958 - accuracy: 0.7399\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7958 - accuracy: 0.7399\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7480 - accuracy: 0.7420WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_test_batch_end` time: 0.0034s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7958 - accuracy: 0.7399\n",
      "Model: \"functional_49\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_25 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_72 (Conv2D)           (None, 32, 32, 25)        700       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_72 (MaxPooling (None, 16, 16, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_73 (Conv2D)           (None, 16, 16, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_73 (MaxPooling (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_74 (Conv2D)           (None, 8, 8, 50)          22550     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_74 (MaxPooling (None, 4, 4, 50)          0         \n",
      "_________________________________________________________________\n",
      "flatten_24 (Flatten)         (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1000)              801000    \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 845,560\n",
      "Trainable params: 845,560\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8b1877d440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8b1877d440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 990/1000 [============================>.] - ETA: 0s - loss: 1.3921 - accuracy: 0.4973WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd3917950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd3917950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.3893 - accuracy: 0.4983 - val_loss: 1.1303 - val_accuracy: 0.6027\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9857 - accuracy: 0.6494 - val_loss: 0.9540 - val_accuracy: 0.6619\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8104 - accuracy: 0.7125 - val_loss: 0.8990 - val_accuracy: 0.6901\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6838 - accuracy: 0.7602 - val_loss: 0.8184 - val_accuracy: 0.7193\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5827 - accuracy: 0.7953 - val_loss: 0.7927 - val_accuracy: 0.7305\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4741 - accuracy: 0.8344 - val_loss: 0.8043 - val_accuracy: 0.7351\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3722 - accuracy: 0.8681 - val_loss: 0.8120 - val_accuracy: 0.7473\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2873 - accuracy: 0.8976 - val_loss: 0.8971 - val_accuracy: 0.7413\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2109 - accuracy: 0.9259 - val_loss: 0.9791 - val_accuracy: 0.7398\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1617 - accuracy: 0.9430 - val_loss: 1.1127 - val_accuracy: 0.7421\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7740 - accuracy: 0.7670WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0036s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8120 - accuracy: 0.7473\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7740 - accuracy: 0.7670WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0036s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8120 - accuracy: 0.7473\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7740 - accuracy: 0.7670WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0035s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8120 - accuracy: 0.7473\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7740 - accuracy: 0.7670WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0036s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8120 - accuracy: 0.7473\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8120 - accuracy: 0.7473\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8120 - accuracy: 0.7473\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7740 - accuracy: 0.7670WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0037s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8120 - accuracy: 0.7473\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7740 - accuracy: 0.7670WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0040s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8120 - accuracy: 0.7473\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8120 - accuracy: 0.7473\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7740 - accuracy: 0.7670WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0036s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8120 - accuracy: 0.7473\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7740 - accuracy: 0.7670WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0040s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8120 - accuracy: 0.7473\n",
      "Model: \"functional_51\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_26 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_75 (Conv2D)           (None, 32, 32, 26)        728       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_75 (MaxPooling (None, 16, 16, 26)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_76 (Conv2D)           (None, 16, 16, 52)        12220     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_76 (MaxPooling (None, 8, 8, 52)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_77 (Conv2D)           (None, 8, 8, 52)          24388     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_77 (MaxPooling (None, 4, 4, 52)          0         \n",
      "_________________________________________________________________\n",
      "flatten_25 (Flatten)         (None, 832)               0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 1040)              866320    \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 10)                10410     \n",
      "=================================================================\n",
      "Total params: 914,066\n",
      "Trainable params: 914,066\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8b242300e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8b242300e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 986/1000 [============================>.] - ETA: 0s - loss: 1.4218 - accuracy: 0.4858WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf46f5e60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf46f5e60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.4159 - accuracy: 0.4878 - val_loss: 1.1540 - val_accuracy: 0.5900\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9946 - accuracy: 0.6482 - val_loss: 0.9625 - val_accuracy: 0.6616\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8200 - accuracy: 0.7115 - val_loss: 0.8386 - val_accuracy: 0.7029\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6912 - accuracy: 0.7576 - val_loss: 0.8276 - val_accuracy: 0.7164\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5866 - accuracy: 0.7934 - val_loss: 0.7912 - val_accuracy: 0.7275\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4878 - accuracy: 0.8283 - val_loss: 0.8304 - val_accuracy: 0.7197\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4014 - accuracy: 0.8589 - val_loss: 0.8090 - val_accuracy: 0.7387\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3109 - accuracy: 0.8911 - val_loss: 0.9067 - val_accuracy: 0.7287\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2349 - accuracy: 0.9176 - val_loss: 0.9876 - val_accuracy: 0.7302\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1767 - accuracy: 0.9380 - val_loss: 1.0915 - val_accuracy: 0.7357\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7327 - accuracy: 0.7560WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0036s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8090 - accuracy: 0.7387\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7327 - accuracy: 0.7560WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_test_batch_end` time: 0.0036s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8090 - accuracy: 0.7387\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7327 - accuracy: 0.7560WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0036s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8090 - accuracy: 0.7387\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7327 - accuracy: 0.7560WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0044s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8090 - accuracy: 0.7387\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8090 - accuracy: 0.7387\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8090 - accuracy: 0.7387\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7327 - accuracy: 0.7560WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_test_batch_end` time: 0.0037s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8090 - accuracy: 0.7387\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7327 - accuracy: 0.7560WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0041s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8090 - accuracy: 0.7387\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7327 - accuracy: 0.7560WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0037s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8090 - accuracy: 0.7387\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7327 - accuracy: 0.7560WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0038s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8090 - accuracy: 0.7387\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8090 - accuracy: 0.7387\n",
      "Model: \"functional_53\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_27 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_78 (Conv2D)           (None, 32, 32, 27)        756       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_78 (MaxPooling (None, 16, 16, 27)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_79 (Conv2D)           (None, 16, 16, 54)        13176     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_79 (MaxPooling (None, 8, 8, 54)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_80 (Conv2D)           (None, 8, 8, 54)          26298     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_80 (MaxPooling (None, 4, 4, 54)          0         \n",
      "_________________________________________________________________\n",
      "flatten_26 (Flatten)         (None, 864)               0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 1080)              934200    \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 10)                10810     \n",
      "=================================================================\n",
      "Total params: 985,240\n",
      "Trainable params: 985,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd386c830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd386c830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 994/1000 [============================>.] - ETA: 0s - loss: 1.3841 - accuracy: 0.4970WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b240793b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b240793b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.3819 - accuracy: 0.4979 - val_loss: 1.0766 - val_accuracy: 0.6137\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9767 - accuracy: 0.6539 - val_loss: 0.9262 - val_accuracy: 0.6732\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8056 - accuracy: 0.7186 - val_loss: 0.8478 - val_accuracy: 0.7018\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6807 - accuracy: 0.7601 - val_loss: 0.8095 - val_accuracy: 0.7245\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5730 - accuracy: 0.7983 - val_loss: 0.7722 - val_accuracy: 0.7377\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4673 - accuracy: 0.8342 - val_loss: 0.7806 - val_accuracy: 0.7517\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3694 - accuracy: 0.8701 - val_loss: 0.8661 - val_accuracy: 0.7353\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2798 - accuracy: 0.9011 - val_loss: 0.8880 - val_accuracy: 0.7480\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2053 - accuracy: 0.9279 - val_loss: 1.0354 - val_accuracy: 0.7339\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7243 - accuracy: 0.7620WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0037s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7806 - accuracy: 0.7517\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7243 - accuracy: 0.7620WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0037s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7806 - accuracy: 0.7517\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7243 - accuracy: 0.7620WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0037s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7806 - accuracy: 0.7517\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7806 - accuracy: 0.7517\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7806 - accuracy: 0.7517\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7243 - accuracy: 0.7620WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0038s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7806 - accuracy: 0.7517\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7243 - accuracy: 0.7620WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0038s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7806 - accuracy: 0.7517\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7243 - accuracy: 0.7620WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0038s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7806 - accuracy: 0.7517\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7243 - accuracy: 0.7620WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0042s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7806 - accuracy: 0.7517\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7243 - accuracy: 0.7620WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0037s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7806 - accuracy: 0.7517\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7243 - accuracy: 0.7620WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0037s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7806 - accuracy: 0.7517\n",
      "Model: \"functional_55\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_28 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_81 (Conv2D)           (None, 32, 32, 28)        784       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_81 (MaxPooling (None, 16, 16, 28)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_82 (Conv2D)           (None, 16, 16, 56)        14168     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_82 (MaxPooling (None, 8, 8, 56)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_83 (Conv2D)           (None, 8, 8, 56)          28280     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_83 (MaxPooling (None, 4, 4, 56)          0         \n",
      "_________________________________________________________________\n",
      "flatten_27 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 1120)              1004640   \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 10)                11210     \n",
      "=================================================================\n",
      "Total params: 1,059,082\n",
      "Trainable params: 1,059,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf440bdd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf440bdd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 984/1000 [============================>.] - ETA: 0s - loss: 1.4186 - accuracy: 0.4848WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf57aed40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf57aed40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.4145 - accuracy: 0.4857 - val_loss: 1.1011 - val_accuracy: 0.6074\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0050 - accuracy: 0.6465 - val_loss: 0.9550 - val_accuracy: 0.6653\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8334 - accuracy: 0.7069 - val_loss: 0.8643 - val_accuracy: 0.6994\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7047 - accuracy: 0.7527 - val_loss: 0.8493 - val_accuracy: 0.7179\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5903 - accuracy: 0.7927 - val_loss: 0.7738 - val_accuracy: 0.7429\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4813 - accuracy: 0.8305 - val_loss: 0.8085 - val_accuracy: 0.7409\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3879 - accuracy: 0.8639 - val_loss: 0.8246 - val_accuracy: 0.7377\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3007 - accuracy: 0.8938 - val_loss: 0.9325 - val_accuracy: 0.7343\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7491 - accuracy: 0.7430WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0038s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7738 - accuracy: 0.7429\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7491 - accuracy: 0.7430WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0038s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7738 - accuracy: 0.7429\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7491 - accuracy: 0.7430WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0038s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7738 - accuracy: 0.7429\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7491 - accuracy: 0.7430WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0044s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7738 - accuracy: 0.7429\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7491 - accuracy: 0.7430WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0037s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7738 - accuracy: 0.7429\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7491 - accuracy: 0.7430WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0037s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7738 - accuracy: 0.7429\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7491 - accuracy: 0.7430WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0038s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7738 - accuracy: 0.7429\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7491 - accuracy: 0.7430WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0037s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7738 - accuracy: 0.7429\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7491 - accuracy: 0.7430WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0041s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7738 - accuracy: 0.7429\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7491 - accuracy: 0.7430WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0037s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7738 - accuracy: 0.7429\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7491 - accuracy: 0.7430WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0037s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7738 - accuracy: 0.7429\n",
      "Model: \"functional_57\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_29 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_84 (Conv2D)           (None, 32, 32, 29)        812       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_84 (MaxPooling (None, 16, 16, 29)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_85 (Conv2D)           (None, 16, 16, 58)        15196     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_85 (MaxPooling (None, 8, 8, 58)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_86 (Conv2D)           (None, 8, 8, 58)          30334     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_86 (MaxPooling (None, 4, 4, 58)          0         \n",
      "_________________________________________________________________\n",
      "flatten_28 (Flatten)         (None, 928)               0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 1160)              1077640   \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 10)                11610     \n",
      "=================================================================\n",
      "Total params: 1,135,592\n",
      "Trainable params: 1,135,592\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf44f37a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf44f37a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 981/1000 [============================>.] - ETA: 0s - loss: 1.3997 - accuracy: 0.4927WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd46e3200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd46e3200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.3931 - accuracy: 0.4950 - val_loss: 1.0649 - val_accuracy: 0.6203\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9718 - accuracy: 0.6555 - val_loss: 0.8949 - val_accuracy: 0.6888\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7854 - accuracy: 0.7231 - val_loss: 0.8168 - val_accuracy: 0.7143\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6617 - accuracy: 0.7669 - val_loss: 0.8153 - val_accuracy: 0.7205\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5489 - accuracy: 0.8061 - val_loss: 0.7757 - val_accuracy: 0.7413\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4398 - accuracy: 0.8449 - val_loss: 0.7641 - val_accuracy: 0.7542\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3377 - accuracy: 0.8804 - val_loss: 0.8422 - val_accuracy: 0.7582\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2527 - accuracy: 0.9105 - val_loss: 0.9166 - val_accuracy: 0.7506\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1863 - accuracy: 0.9351 - val_loss: 1.0003 - val_accuracy: 0.7537\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1480 - accuracy: 0.9470 - val_loss: 1.1082 - val_accuracy: 0.7418\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7641 - accuracy: 0.7730WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_test_batch_end` time: 0.0039s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8422 - accuracy: 0.7582\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7641 - accuracy: 0.7730WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0039s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8422 - accuracy: 0.7582\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7641 - accuracy: 0.7730WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0039s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8422 - accuracy: 0.7582\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7641 - accuracy: 0.7730WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0045s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8422 - accuracy: 0.7582\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7641 - accuracy: 0.7730WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0039s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8422 - accuracy: 0.7582\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7641 - accuracy: 0.7730WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0039s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8422 - accuracy: 0.7582\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7641 - accuracy: 0.7730WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_test_batch_end` time: 0.0040s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8422 - accuracy: 0.7582\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8422 - accuracy: 0.7582\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7641 - accuracy: 0.7730WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0039s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8422 - accuracy: 0.7582\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7641 - accuracy: 0.7730WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0039s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8422 - accuracy: 0.7582\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7641 - accuracy: 0.7730WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0039s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8422 - accuracy: 0.7582\n",
      "Model: \"functional_59\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_30 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_87 (Conv2D)           (None, 32, 32, 30)        840       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_87 (MaxPooling (None, 16, 16, 30)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_88 (Conv2D)           (None, 16, 16, 60)        16260     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_88 (MaxPooling (None, 8, 8, 60)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_89 (Conv2D)           (None, 8, 8, 60)          32460     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_89 (MaxPooling (None, 4, 4, 60)          0         \n",
      "_________________________________________________________________\n",
      "flatten_29 (Flatten)         (None, 960)               0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 1200)              1153200   \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 10)                12010     \n",
      "=================================================================\n",
      "Total params: 1,214,770\n",
      "Trainable params: 1,214,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf57fe050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf57fe050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 994/1000 [============================>.] - ETA: 0s - loss: 1.3649 - accuracy: 0.5058WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf42c78c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf42c78c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.3635 - accuracy: 0.5064 - val_loss: 1.1073 - val_accuracy: 0.6039\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9548 - accuracy: 0.6626 - val_loss: 0.9177 - val_accuracy: 0.6822\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7901 - accuracy: 0.7231 - val_loss: 0.7950 - val_accuracy: 0.7217\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6647 - accuracy: 0.7678 - val_loss: 0.8181 - val_accuracy: 0.7291\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5595 - accuracy: 0.8043 - val_loss: 0.8455 - val_accuracy: 0.7182\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4527 - accuracy: 0.8418 - val_loss: 0.7963 - val_accuracy: 0.7429\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3522 - accuracy: 0.8750 - val_loss: 0.8401 - val_accuracy: 0.7482\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2600 - accuracy: 0.9102 - val_loss: 0.9305 - val_accuracy: 0.7406\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1964 - accuracy: 0.9312 - val_loss: 1.0187 - val_accuracy: 0.7500\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1493 - accuracy: 0.9484 - val_loss: 1.1709 - val_accuracy: 0.7452\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1202 - accuracy: 0.9583 - val_loss: 1.2818 - val_accuracy: 0.7468\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1086 - accuracy: 0.9622 - val_loss: 1.3581 - val_accuracy: 0.7459\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9433 - accuracy: 0.7590WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0040s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.0187 - accuracy: 0.7500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9433 - accuracy: 0.7590WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0040s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.0187 - accuracy: 0.7500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9433 - accuracy: 0.7590WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0040s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.0187 - accuracy: 0.7500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9433 - accuracy: 0.7590WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0021s vs `on_test_batch_end` time: 0.0042s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.0187 - accuracy: 0.7500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9433 - accuracy: 0.7590WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0040s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.0187 - accuracy: 0.7500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9433 - accuracy: 0.7590WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0046s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.0187 - accuracy: 0.7500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9433 - accuracy: 0.7590WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0048s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.0187 - accuracy: 0.7500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9433 - accuracy: 0.7590WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0040s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.0187 - accuracy: 0.7500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9433 - accuracy: 0.7590WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_test_batch_end` time: 0.0042s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.0187 - accuracy: 0.7500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9433 - accuracy: 0.7590WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0040s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.0187 - accuracy: 0.7500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9433 - accuracy: 0.7590WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0040s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.0187 - accuracy: 0.7500\n",
      "Model: \"functional_61\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_31 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_90 (Conv2D)           (None, 32, 32, 31)        868       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_90 (MaxPooling (None, 16, 16, 31)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_91 (Conv2D)           (None, 16, 16, 62)        17360     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_91 (MaxPooling (None, 8, 8, 62)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_92 (Conv2D)           (None, 8, 8, 62)          34658     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_92 (MaxPooling (None, 4, 4, 62)          0         \n",
      "_________________________________________________________________\n",
      "flatten_30 (Flatten)         (None, 992)               0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 1240)              1231320   \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 10)                12410     \n",
      "=================================================================\n",
      "Total params: 1,296,616\n",
      "Trainable params: 1,296,616\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd3aea170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd3aea170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 991/1000 [============================>.] - ETA: 0s - loss: 1.3560 - accuracy: 0.5110WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd46910e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd46910e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.3541 - accuracy: 0.5118 - val_loss: 1.0469 - val_accuracy: 0.6264\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9382 - accuracy: 0.6666 - val_loss: 0.9010 - val_accuracy: 0.6845\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7700 - accuracy: 0.7295 - val_loss: 0.8135 - val_accuracy: 0.7182\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6366 - accuracy: 0.7769 - val_loss: 0.7946 - val_accuracy: 0.7265\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5258 - accuracy: 0.8167 - val_loss: 0.8338 - val_accuracy: 0.7228\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4152 - accuracy: 0.8528 - val_loss: 0.7949 - val_accuracy: 0.7500\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3104 - accuracy: 0.8920 - val_loss: 0.8713 - val_accuracy: 0.7440\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2319 - accuracy: 0.9189 - val_loss: 1.0015 - val_accuracy: 0.7431\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1695 - accuracy: 0.9417 - val_loss: 1.0493 - val_accuracy: 0.7450\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7617 - accuracy: 0.7460WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0041s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7949 - accuracy: 0.7500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7617 - accuracy: 0.7460WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0040s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7949 - accuracy: 0.7500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7617 - accuracy: 0.7460WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0040s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7949 - accuracy: 0.7500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7617 - accuracy: 0.7460WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0042s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7949 - accuracy: 0.7500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7617 - accuracy: 0.7460WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0044s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7949 - accuracy: 0.7500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7617 - accuracy: 0.7460WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0040s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7949 - accuracy: 0.7500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7617 - accuracy: 0.7460WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0040s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7949 - accuracy: 0.7500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7617 - accuracy: 0.7460WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0042s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7949 - accuracy: 0.7500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7617 - accuracy: 0.7460WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0041s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7949 - accuracy: 0.7500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7617 - accuracy: 0.7460WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0041s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7949 - accuracy: 0.7500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7617 - accuracy: 0.7460WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0048s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7949 - accuracy: 0.7500\n",
      "Model: \"functional_63\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_32 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_93 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_93 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_94 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_94 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_95 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_31 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 1280)              1312000   \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 10)                12810     \n",
      "=================================================================\n",
      "Total params: 1,381,130\n",
      "Trainable params: 1,381,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf4607290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf4607290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 996/1000 [============================>.] - ETA: 0s - loss: 1.3838 - accuracy: 0.4996WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b18740f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b18740f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.3826 - accuracy: 0.5000 - val_loss: 1.0787 - val_accuracy: 0.6170\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9750 - accuracy: 0.6570 - val_loss: 0.8948 - val_accuracy: 0.6841\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7980 - accuracy: 0.7185 - val_loss: 0.8250 - val_accuracy: 0.7132\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6739 - accuracy: 0.7598 - val_loss: 0.8257 - val_accuracy: 0.7096\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5602 - accuracy: 0.8015 - val_loss: 0.7921 - val_accuracy: 0.7364\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4435 - accuracy: 0.8435 - val_loss: 0.8058 - val_accuracy: 0.7394\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3400 - accuracy: 0.8798 - val_loss: 0.8227 - val_accuracy: 0.7524\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2433 - accuracy: 0.9141 - val_loss: 0.9522 - val_accuracy: 0.7507\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1838 - accuracy: 0.9360 - val_loss: 0.9906 - val_accuracy: 0.7507\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1333 - accuracy: 0.9546 - val_loss: 1.1734 - val_accuracy: 0.7453\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7379 - accuracy: 0.7660WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0049s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8227 - accuracy: 0.7524\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7379 - accuracy: 0.7660WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0041s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8227 - accuracy: 0.7524\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7379 - accuracy: 0.7660WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0041s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8227 - accuracy: 0.7524\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7379 - accuracy: 0.7660WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0041s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8227 - accuracy: 0.7524\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7379 - accuracy: 0.7660WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0043s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8227 - accuracy: 0.7524\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7379 - accuracy: 0.7660WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0041s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8227 - accuracy: 0.7524\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7379 - accuracy: 0.7660WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0050s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8227 - accuracy: 0.7524\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7379 - accuracy: 0.7660WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0041s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8227 - accuracy: 0.7524\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7379 - accuracy: 0.7660WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0041s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8227 - accuracy: 0.7524\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7379 - accuracy: 0.7660WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0041s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8227 - accuracy: 0.7524\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7379 - accuracy: 0.7660WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0041s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8227 - accuracy: 0.7524\n",
      "Model: \"functional_65\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_33 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_96 (Conv2D)           (None, 32, 32, 33)        924       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_96 (MaxPooling (None, 16, 16, 33)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_97 (Conv2D)           (None, 16, 16, 66)        19668     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_97 (MaxPooling (None, 8, 8, 66)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_98 (Conv2D)           (None, 8, 8, 66)          39270     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_98 (MaxPooling (None, 4, 4, 66)          0         \n",
      "_________________________________________________________________\n",
      "flatten_32 (Flatten)         (None, 1056)              0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 1320)              1395240   \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 10)                13210     \n",
      "=================================================================\n",
      "Total params: 1,468,312\n",
      "Trainable params: 1,468,312\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8b18740170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8b18740170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 994/1000 [============================>.] - ETA: 0s - loss: 1.3937 - accuracy: 0.4958WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf44107a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf44107a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.3920 - accuracy: 0.4965 - val_loss: 1.1389 - val_accuracy: 0.5948\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9613 - accuracy: 0.6611 - val_loss: 0.8728 - val_accuracy: 0.6953\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7828 - accuracy: 0.7242 - val_loss: 0.8334 - val_accuracy: 0.7049\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6461 - accuracy: 0.7721 - val_loss: 0.7779 - val_accuracy: 0.7355\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5256 - accuracy: 0.8140 - val_loss: 0.7731 - val_accuracy: 0.7378\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4218 - accuracy: 0.8517 - val_loss: 0.7832 - val_accuracy: 0.7479\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3116 - accuracy: 0.8910 - val_loss: 0.8999 - val_accuracy: 0.7359\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2326 - accuracy: 0.9172 - val_loss: 0.9201 - val_accuracy: 0.7491\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1685 - accuracy: 0.9417 - val_loss: 1.0324 - val_accuracy: 0.7490\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1353 - accuracy: 0.9530 - val_loss: 1.2127 - val_accuracy: 0.7389\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1127 - accuracy: 0.9620 - val_loss: 1.3057 - val_accuracy: 0.7412\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7984 - accuracy: 0.7730WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_test_batch_end` time: 0.0075s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9201 - accuracy: 0.7491\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7984 - accuracy: 0.7730WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0065s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9201 - accuracy: 0.7491\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7984 - accuracy: 0.7730WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0056s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9201 - accuracy: 0.7491\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7984 - accuracy: 0.7730WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0055s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9201 - accuracy: 0.7491\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7984 - accuracy: 0.7730WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0056s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.9201 - accuracy: 0.7491\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7984 - accuracy: 0.7730WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0064s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9201 - accuracy: 0.7491\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7984 - accuracy: 0.7730WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_test_batch_end` time: 0.0056s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9201 - accuracy: 0.7491\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7984 - accuracy: 0.7730WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0056s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9201 - accuracy: 0.7491\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7984 - accuracy: 0.7730WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0056s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9201 - accuracy: 0.7491\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7984 - accuracy: 0.7730WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0056s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9201 - accuracy: 0.7491\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7984 - accuracy: 0.7730WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0058s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9201 - accuracy: 0.7491\n",
      "Model: \"functional_67\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_34 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_99 (Conv2D)           (None, 32, 32, 34)        952       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_99 (MaxPooling (None, 16, 16, 34)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_100 (Conv2D)          (None, 16, 16, 68)        20876     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_100 (MaxPoolin (None, 8, 8, 68)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_101 (Conv2D)          (None, 8, 8, 68)          41684     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_101 (MaxPoolin (None, 4, 4, 68)          0         \n",
      "_________________________________________________________________\n",
      "flatten_33 (Flatten)         (None, 1088)              0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 1360)              1481040   \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 10)                13610     \n",
      "=================================================================\n",
      "Total params: 1,558,162\n",
      "Trainable params: 1,558,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8b240cf290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8b240cf290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 995/1000 [============================>.] - ETA: 0s - loss: 1.3805 - accuracy: 0.5005WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf4f6dd40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf4f6dd40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.3793 - accuracy: 0.5010 - val_loss: 1.1102 - val_accuracy: 0.6045\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9493 - accuracy: 0.6648 - val_loss: 0.9048 - val_accuracy: 0.6863\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7683 - accuracy: 0.7329 - val_loss: 0.7799 - val_accuracy: 0.7324\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6375 - accuracy: 0.7761 - val_loss: 0.7702 - val_accuracy: 0.7377\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5233 - accuracy: 0.8159 - val_loss: 0.7556 - val_accuracy: 0.7434\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4162 - accuracy: 0.8551 - val_loss: 0.7761 - val_accuracy: 0.7542\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3135 - accuracy: 0.8902 - val_loss: 0.8369 - val_accuracy: 0.7438\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2276 - accuracy: 0.9199 - val_loss: 0.9808 - val_accuracy: 0.7374\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1678 - accuracy: 0.9426 - val_loss: 1.0665 - val_accuracy: 0.7391\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7592 - accuracy: 0.7480WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0057s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7761 - accuracy: 0.7542\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7592 - accuracy: 0.7480WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0057s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7761 - accuracy: 0.7542\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7592 - accuracy: 0.7480WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0057s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7761 - accuracy: 0.7542\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7592 - accuracy: 0.7480WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0057s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7761 - accuracy: 0.7542\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7592 - accuracy: 0.7480WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0056s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7761 - accuracy: 0.7542\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7592 - accuracy: 0.7480WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0057s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7761 - accuracy: 0.7542\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7592 - accuracy: 0.7480WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_test_batch_end` time: 0.0054s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7761 - accuracy: 0.7542\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7592 - accuracy: 0.7480WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0057s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7761 - accuracy: 0.7542\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7592 - accuracy: 0.7480WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0057s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7761 - accuracy: 0.7542\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7592 - accuracy: 0.7480WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0059s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7761 - accuracy: 0.7542\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7592 - accuracy: 0.7480WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0056s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7761 - accuracy: 0.7542\n",
      "Model: \"functional_69\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_35 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_102 (Conv2D)          (None, 32, 32, 35)        980       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_102 (MaxPoolin (None, 16, 16, 35)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_103 (Conv2D)          (None, 16, 16, 70)        22120     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_103 (MaxPoolin (None, 8, 8, 70)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_104 (Conv2D)          (None, 8, 8, 70)          44170     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_104 (MaxPoolin (None, 4, 4, 70)          0         \n",
      "_________________________________________________________________\n",
      "flatten_34 (Flatten)         (None, 1120)              0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 1400)              1569400   \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 10)                14010     \n",
      "=================================================================\n",
      "Total params: 1,650,680\n",
      "Trainable params: 1,650,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd3b43290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd3b43290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 995/1000 [============================>.] - ETA: 0s - loss: 1.3822 - accuracy: 0.4997WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd3b28200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd3b28200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.3805 - accuracy: 0.5004 - val_loss: 1.0837 - val_accuracy: 0.6186\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9406 - accuracy: 0.6673 - val_loss: 0.8840 - val_accuracy: 0.6934\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7586 - accuracy: 0.7334 - val_loss: 0.8059 - val_accuracy: 0.7191\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6227 - accuracy: 0.7806 - val_loss: 0.7711 - val_accuracy: 0.7325\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4951 - accuracy: 0.8266 - val_loss: 0.8061 - val_accuracy: 0.7475\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3814 - accuracy: 0.8678 - val_loss: 0.7962 - val_accuracy: 0.7529\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2773 - accuracy: 0.9032 - val_loss: 0.9031 - val_accuracy: 0.7495\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1954 - accuracy: 0.9316 - val_loss: 1.0095 - val_accuracy: 0.7501\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1413 - accuracy: 0.9522 - val_loss: 1.1216 - val_accuracy: 0.7480\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7315 - accuracy: 0.7620WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0058s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7962 - accuracy: 0.7529\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7315 - accuracy: 0.7620WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0058s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7962 - accuracy: 0.7529\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7315 - accuracy: 0.7620WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0058s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7962 - accuracy: 0.7529\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7315 - accuracy: 0.7620WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0058s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7962 - accuracy: 0.7529\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7315 - accuracy: 0.7620WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0060s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7962 - accuracy: 0.7529\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7315 - accuracy: 0.7620WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0057s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7962 - accuracy: 0.7529\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7315 - accuracy: 0.7620WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0057s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7962 - accuracy: 0.7529\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7315 - accuracy: 0.7620WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0057s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7962 - accuracy: 0.7529\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7315 - accuracy: 0.7620WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0058s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7962 - accuracy: 0.7529\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7315 - accuracy: 0.7620WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0060s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7962 - accuracy: 0.7529\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7315 - accuracy: 0.7620WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0058s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7962 - accuracy: 0.7529\n",
      "Model: \"functional_71\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_36 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_105 (Conv2D)          (None, 32, 32, 36)        1008      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_105 (MaxPoolin (None, 16, 16, 36)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_106 (Conv2D)          (None, 16, 16, 72)        23400     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_106 (MaxPoolin (None, 8, 8, 72)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_107 (Conv2D)          (None, 8, 8, 72)          46728     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_107 (MaxPoolin (None, 4, 4, 72)          0         \n",
      "_________________________________________________________________\n",
      "flatten_35 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 1440)              1660320   \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 10)                14410     \n",
      "=================================================================\n",
      "Total params: 1,745,866\n",
      "Trainable params: 1,745,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd389b950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd389b950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 993/1000 [============================>.] - ETA: 0s - loss: 1.3506 - accuracy: 0.5114WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b186a1050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b186a1050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.3490 - accuracy: 0.5120 - val_loss: 1.0550 - val_accuracy: 0.6264\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9352 - accuracy: 0.6691 - val_loss: 0.9334 - val_accuracy: 0.6782\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7613 - accuracy: 0.7320 - val_loss: 0.8359 - val_accuracy: 0.7108\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6243 - accuracy: 0.7802 - val_loss: 0.7985 - val_accuracy: 0.7299\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5057 - accuracy: 0.8229 - val_loss: 0.7623 - val_accuracy: 0.7516\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3902 - accuracy: 0.8643 - val_loss: 0.7928 - val_accuracy: 0.7564\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2853 - accuracy: 0.8998 - val_loss: 0.8720 - val_accuracy: 0.7494\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1980 - accuracy: 0.9310 - val_loss: 1.0573 - val_accuracy: 0.7459\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1568 - accuracy: 0.9453 - val_loss: 1.0827 - val_accuracy: 0.7438\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7454 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0058s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7928 - accuracy: 0.7564\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7454 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0056s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7928 - accuracy: 0.7564\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7454 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0058s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7928 - accuracy: 0.7564\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7454 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0058s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7928 - accuracy: 0.7564\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7454 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0064s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7928 - accuracy: 0.7564\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7454 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0063s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7928 - accuracy: 0.7564\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7454 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_test_batch_end` time: 0.0058s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7928 - accuracy: 0.7564\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7454 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0058s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7928 - accuracy: 0.7564\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7454 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0059s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7928 - accuracy: 0.7564\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7454 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0060s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7928 - accuracy: 0.7564\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7454 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0058s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7928 - accuracy: 0.7564\n",
      "Model: \"functional_73\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_37 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_108 (Conv2D)          (None, 32, 32, 37)        1036      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_108 (MaxPoolin (None, 16, 16, 37)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_109 (Conv2D)          (None, 16, 16, 74)        24716     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_109 (MaxPoolin (None, 8, 8, 74)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_110 (Conv2D)          (None, 8, 8, 74)          49358     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_110 (MaxPoolin (None, 4, 4, 74)          0         \n",
      "_________________________________________________________________\n",
      "flatten_36 (Flatten)         (None, 1184)              0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 1480)              1753800   \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 10)                14810     \n",
      "=================================================================\n",
      "Total params: 1,843,720\n",
      "Trainable params: 1,843,720\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd3c9a680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd3c9a680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 995/1000 [============================>.] - ETA: 0s - loss: 1.3752 - accuracy: 0.5055WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b2411d830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b2411d830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.3742 - accuracy: 0.5059 - val_loss: 1.0584 - val_accuracy: 0.6263\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9442 - accuracy: 0.6667 - val_loss: 0.8768 - val_accuracy: 0.6941\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7558 - accuracy: 0.7358 - val_loss: 0.8213 - val_accuracy: 0.7145\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6181 - accuracy: 0.7825 - val_loss: 0.7762 - val_accuracy: 0.7380\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4936 - accuracy: 0.8261 - val_loss: 0.7803 - val_accuracy: 0.7414\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3761 - accuracy: 0.8669 - val_loss: 0.8138 - val_accuracy: 0.7476\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2719 - accuracy: 0.9041 - val_loss: 0.9104 - val_accuracy: 0.7451\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1899 - accuracy: 0.9336 - val_loss: 0.9899 - val_accuracy: 0.7483\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1399 - accuracy: 0.9508 - val_loss: 1.1879 - val_accuracy: 0.7341\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1166 - accuracy: 0.9587 - val_loss: 1.2416 - val_accuracy: 0.7448\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1044 - accuracy: 0.9645 - val_loss: 1.2950 - val_accuracy: 0.7489\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0901 - accuracy: 0.9693 - val_loss: 1.5047 - val_accuracy: 0.7425\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0917 - accuracy: 0.9691 - val_loss: 1.5087 - val_accuracy: 0.7459\n",
      "Epoch 14/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0812 - accuracy: 0.9730 - val_loss: 1.5821 - val_accuracy: 0.7432\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1888 - accuracy: 0.7540WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0060s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.2950 - accuracy: 0.7489\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1888 - accuracy: 0.7540WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0060s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.2950 - accuracy: 0.7489\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1888 - accuracy: 0.7540WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0059s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.2950 - accuracy: 0.7489\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1888 - accuracy: 0.7540WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0060s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.2950 - accuracy: 0.7489\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1888 - accuracy: 0.7540WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0060s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.2950 - accuracy: 0.7489\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1888 - accuracy: 0.7540WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0059s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.2950 - accuracy: 0.7489\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1888 - accuracy: 0.7540WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0059s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.2950 - accuracy: 0.7489\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1888 - accuracy: 0.7540WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_test_batch_end` time: 0.0060s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.2950 - accuracy: 0.7489\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1888 - accuracy: 0.7540WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0060s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.2950 - accuracy: 0.7489\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1888 - accuracy: 0.7540WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_test_batch_end` time: 0.0065s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.2950 - accuracy: 0.7489\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1888 - accuracy: 0.7540WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0059s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.2950 - accuracy: 0.7489\n",
      "Model: \"functional_75\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_38 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_111 (Conv2D)          (None, 32, 32, 38)        1064      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_111 (MaxPoolin (None, 16, 16, 38)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_112 (Conv2D)          (None, 16, 16, 76)        26068     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_112 (MaxPoolin (None, 8, 8, 76)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_113 (Conv2D)          (None, 8, 8, 76)          52060     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_113 (MaxPoolin (None, 4, 4, 76)          0         \n",
      "_________________________________________________________________\n",
      "flatten_37 (Flatten)         (None, 1216)              0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 1520)              1849840   \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 10)                15210     \n",
      "=================================================================\n",
      "Total params: 1,944,242\n",
      "Trainable params: 1,944,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8b187b9a70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8b187b9a70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 993/1000 [============================>.] - ETA: 0s - loss: 1.3777 - accuracy: 0.5005WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf59af830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf59af830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.3756 - accuracy: 0.5012 - val_loss: 1.0316 - val_accuracy: 0.6348\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9425 - accuracy: 0.6669 - val_loss: 0.8616 - val_accuracy: 0.6938\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7629 - accuracy: 0.7315 - val_loss: 0.8600 - val_accuracy: 0.7057\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6325 - accuracy: 0.7770 - val_loss: 0.7619 - val_accuracy: 0.7354\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5145 - accuracy: 0.8196 - val_loss: 0.7556 - val_accuracy: 0.7512\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3982 - accuracy: 0.8598 - val_loss: 0.8056 - val_accuracy: 0.7464\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2918 - accuracy: 0.8978 - val_loss: 0.8821 - val_accuracy: 0.7506\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2065 - accuracy: 0.9281 - val_loss: 1.0594 - val_accuracy: 0.7441\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7577 - accuracy: 0.7550WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0060s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7556 - accuracy: 0.7512\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7577 - accuracy: 0.7550WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0063s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7556 - accuracy: 0.7512\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7577 - accuracy: 0.7550WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0061s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7556 - accuracy: 0.7512\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7577 - accuracy: 0.7550WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_test_batch_end` time: 0.0060s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7556 - accuracy: 0.7512\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7577 - accuracy: 0.7550WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0060s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7556 - accuracy: 0.7512\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7577 - accuracy: 0.7550WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_test_batch_end` time: 0.0062s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7556 - accuracy: 0.7512\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7577 - accuracy: 0.7550WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0060s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7556 - accuracy: 0.7512\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7577 - accuracy: 0.7550WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0060s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7556 - accuracy: 0.7512\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7577 - accuracy: 0.7550WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0064s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7556 - accuracy: 0.7512\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7577 - accuracy: 0.7550WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0060s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7556 - accuracy: 0.7512\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7577 - accuracy: 0.7550WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0030s vs `on_test_batch_end` time: 0.0061s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7556 - accuracy: 0.7512\n",
      "Model: \"functional_77\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_39 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_114 (Conv2D)          (None, 32, 32, 39)        1092      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_114 (MaxPoolin (None, 16, 16, 39)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_115 (Conv2D)          (None, 16, 16, 78)        27456     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_115 (MaxPoolin (None, 8, 8, 78)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_116 (Conv2D)          (None, 8, 8, 78)          54834     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_116 (MaxPoolin (None, 4, 4, 78)          0         \n",
      "_________________________________________________________________\n",
      "flatten_38 (Flatten)         (None, 1248)              0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 1560)              1948440   \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 10)                15610     \n",
      "=================================================================\n",
      "Total params: 2,047,432\n",
      "Trainable params: 2,047,432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd3b28560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd3b28560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1.3648 - accuracy: 0.5059WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b24156b00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b24156b00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.3645 - accuracy: 0.5060 - val_loss: 1.0771 - val_accuracy: 0.6178\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9352 - accuracy: 0.6694 - val_loss: 0.8622 - val_accuracy: 0.7012\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7659 - accuracy: 0.7313 - val_loss: 0.8320 - val_accuracy: 0.7117\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6261 - accuracy: 0.7801 - val_loss: 0.7680 - val_accuracy: 0.7380\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5090 - accuracy: 0.8218 - val_loss: 0.7860 - val_accuracy: 0.7388\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3909 - accuracy: 0.8614 - val_loss: 0.8054 - val_accuracy: 0.7536\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2894 - accuracy: 0.8987 - val_loss: 0.8724 - val_accuracy: 0.7478\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2025 - accuracy: 0.9286 - val_loss: 0.9739 - val_accuracy: 0.7540\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1470 - accuracy: 0.9489 - val_loss: 1.0842 - val_accuracy: 0.7504\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1221 - accuracy: 0.9571 - val_loss: 1.2536 - val_accuracy: 0.7409\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1081 - accuracy: 0.9633 - val_loss: 1.2995 - val_accuracy: 0.7414\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9252 - accuracy: 0.7510WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0062s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9739 - accuracy: 0.7540\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9252 - accuracy: 0.7510WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0062s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.9739 - accuracy: 0.7540\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9252 - accuracy: 0.7510WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0064s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.9739 - accuracy: 0.7540\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9252 - accuracy: 0.7510WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0062s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.9739 - accuracy: 0.7540\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9252 - accuracy: 0.7510WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0062s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.9739 - accuracy: 0.7540\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9252 - accuracy: 0.7510WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0062s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.9739 - accuracy: 0.7540\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9252 - accuracy: 0.7510WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0062s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.9739 - accuracy: 0.7540\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9252 - accuracy: 0.7510WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0062s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.9739 - accuracy: 0.7540\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9252 - accuracy: 0.7510WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0061s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.9739 - accuracy: 0.7540\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9252 - accuracy: 0.7510WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0061s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.9739 - accuracy: 0.7540\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9252 - accuracy: 0.7510WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0062s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.9739 - accuracy: 0.7540\n",
      "Model: \"functional_79\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_40 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_117 (Conv2D)          (None, 32, 32, 40)        1120      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_117 (MaxPoolin (None, 16, 16, 40)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_118 (Conv2D)          (None, 16, 16, 80)        28880     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_118 (MaxPoolin (None, 8, 8, 80)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_119 (Conv2D)          (None, 8, 8, 80)          57680     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_119 (MaxPoolin (None, 4, 4, 80)          0         \n",
      "_________________________________________________________________\n",
      "flatten_39 (Flatten)         (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 1600)              2049600   \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 2,153,290\n",
      "Trainable params: 2,153,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd3bd4320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd3bd4320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 996/1000 [============================>.] - ETA: 0s - loss: 1.3262 - accuracy: 0.5230WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b240d3e60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b240d3e60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.3247 - accuracy: 0.5237 - val_loss: 1.0675 - val_accuracy: 0.6255\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.8988 - accuracy: 0.6843 - val_loss: 0.8598 - val_accuracy: 0.6995\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7222 - accuracy: 0.7469 - val_loss: 0.7800 - val_accuracy: 0.7296\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5816 - accuracy: 0.7967 - val_loss: 0.7288 - val_accuracy: 0.7538\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4531 - accuracy: 0.8413 - val_loss: 0.7445 - val_accuracy: 0.7618\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3400 - accuracy: 0.8805 - val_loss: 0.8031 - val_accuracy: 0.7558\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2365 - accuracy: 0.9174 - val_loss: 0.9464 - val_accuracy: 0.7474\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1674 - accuracy: 0.9420 - val_loss: 1.0104 - val_accuracy: 0.7559\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6991 - accuracy: 0.7600WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0063s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7445 - accuracy: 0.7618\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6991 - accuracy: 0.7600WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0062s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7445 - accuracy: 0.7618\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6991 - accuracy: 0.7600WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0070s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7445 - accuracy: 0.7618\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6991 - accuracy: 0.7600WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0062s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7445 - accuracy: 0.7618\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6991 - accuracy: 0.7600WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0062s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7445 - accuracy: 0.7618\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6991 - accuracy: 0.7600WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0061s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7445 - accuracy: 0.7618\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6991 - accuracy: 0.7600WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0070s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7445 - accuracy: 0.7618\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6991 - accuracy: 0.7600WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0062s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7445 - accuracy: 0.7618\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6991 - accuracy: 0.7600WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0062s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7445 - accuracy: 0.7618\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6991 - accuracy: 0.7600WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0064s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7445 - accuracy: 0.7618\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6991 - accuracy: 0.7600WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0062s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7445 - accuracy: 0.7618\n",
      "Model: \"functional_81\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_41 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_120 (Conv2D)          (None, 32, 32, 41)        1148      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_120 (MaxPoolin (None, 16, 16, 41)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_121 (Conv2D)          (None, 16, 16, 82)        30340     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_121 (MaxPoolin (None, 8, 8, 82)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_122 (Conv2D)          (None, 8, 8, 82)          60598     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_122 (MaxPoolin (None, 4, 4, 82)          0         \n",
      "_________________________________________________________________\n",
      "flatten_40 (Flatten)         (None, 1312)              0         \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 1640)              2153320   \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 10)                16410     \n",
      "=================================================================\n",
      "Total params: 2,261,816\n",
      "Trainable params: 2,261,816\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf436b320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf436b320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 983/1000 [============================>.] - ETA: 0s - loss: 1.3411 - accuracy: 0.5164WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf423bd40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf423bd40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.3357 - accuracy: 0.5182 - val_loss: 1.0295 - val_accuracy: 0.6356\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9279 - accuracy: 0.6738 - val_loss: 0.8399 - val_accuracy: 0.7095\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7463 - accuracy: 0.7365 - val_loss: 0.8092 - val_accuracy: 0.7201\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6100 - accuracy: 0.7856 - val_loss: 0.7653 - val_accuracy: 0.7347\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4941 - accuracy: 0.8276 - val_loss: 0.7651 - val_accuracy: 0.7512\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3757 - accuracy: 0.8695 - val_loss: 0.7918 - val_accuracy: 0.7519\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2687 - accuracy: 0.9058 - val_loss: 0.8720 - val_accuracy: 0.7492\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1907 - accuracy: 0.9329 - val_loss: 1.0243 - val_accuracy: 0.7423\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1364 - accuracy: 0.9535 - val_loss: 1.0918 - val_accuracy: 0.7527\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1177 - accuracy: 0.9596 - val_loss: 1.1887 - val_accuracy: 0.7467\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0998 - accuracy: 0.9661 - val_loss: 1.2977 - val_accuracy: 0.7435\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0939 - accuracy: 0.9676 - val_loss: 1.3827 - val_accuracy: 0.7459\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9820 - accuracy: 0.7740WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0067s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.0918 - accuracy: 0.7527\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9820 - accuracy: 0.7740WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0065s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.0918 - accuracy: 0.7527\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9820 - accuracy: 0.7740WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_test_batch_end` time: 0.0064s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.0918 - accuracy: 0.7527\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9820 - accuracy: 0.7740WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0076s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.0918 - accuracy: 0.7527\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9820 - accuracy: 0.7740WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0076s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.0918 - accuracy: 0.7527\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9820 - accuracy: 0.7740WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0067s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.0918 - accuracy: 0.7527\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9820 - accuracy: 0.7740WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0067s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.0918 - accuracy: 0.7527\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9820 - accuracy: 0.7740WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0066s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.0918 - accuracy: 0.7527\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9820 - accuracy: 0.7740WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0065s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.0918 - accuracy: 0.7527\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9820 - accuracy: 0.7740WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0066s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.0918 - accuracy: 0.7527\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9820 - accuracy: 0.7740WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0065s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.0918 - accuracy: 0.7527\n",
      "Model: \"functional_83\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_42 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_123 (Conv2D)          (None, 32, 32, 42)        1176      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_123 (MaxPoolin (None, 16, 16, 42)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_124 (Conv2D)          (None, 16, 16, 84)        31836     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_124 (MaxPoolin (None, 8, 8, 84)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_125 (Conv2D)          (None, 8, 8, 84)          63588     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_125 (MaxPoolin (None, 4, 4, 84)          0         \n",
      "_________________________________________________________________\n",
      "flatten_41 (Flatten)         (None, 1344)              0         \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 1680)              2259600   \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 10)                16810     \n",
      "=================================================================\n",
      "Total params: 2,373,010\n",
      "Trainable params: 2,373,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd39d63b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd39d63b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 987/1000 [============================>.] - ETA: 0s - loss: 1.3563 - accuracy: 0.5114WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd451ae60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd451ae60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.3513 - accuracy: 0.5131 - val_loss: 1.0196 - val_accuracy: 0.6407\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9191 - accuracy: 0.6766 - val_loss: 0.9210 - val_accuracy: 0.6845\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7466 - accuracy: 0.7367 - val_loss: 0.7885 - val_accuracy: 0.7222\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6165 - accuracy: 0.7849 - val_loss: 0.7820 - val_accuracy: 0.7270\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4935 - accuracy: 0.8261 - val_loss: 0.7788 - val_accuracy: 0.7480\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3736 - accuracy: 0.8687 - val_loss: 0.8213 - val_accuracy: 0.7453\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2713 - accuracy: 0.9039 - val_loss: 0.9646 - val_accuracy: 0.7411\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1909 - accuracy: 0.9332 - val_loss: 0.9882 - val_accuracy: 0.7466\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7139 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_test_batch_end` time: 0.0067s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7788 - accuracy: 0.7480\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7139 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_test_batch_end` time: 0.0066s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7788 - accuracy: 0.7480\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7139 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0066s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7788 - accuracy: 0.7480\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7139 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0076s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7788 - accuracy: 0.7480\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7139 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0075s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.7788 - accuracy: 0.7480\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7139 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0069s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7788 - accuracy: 0.7480\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7139 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0068s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7788 - accuracy: 0.7480\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7139 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0076s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7788 - accuracy: 0.7480\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7139 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_test_batch_end` time: 0.0077s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7788 - accuracy: 0.7480\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7139 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0072s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7788 - accuracy: 0.7480\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7139 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0073s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7788 - accuracy: 0.7480\n",
      "Model: \"functional_85\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_43 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_126 (Conv2D)          (None, 32, 32, 43)        1204      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_126 (MaxPoolin (None, 16, 16, 43)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_127 (Conv2D)          (None, 16, 16, 86)        33368     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_127 (MaxPoolin (None, 8, 8, 86)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_128 (Conv2D)          (None, 8, 8, 86)          66650     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_128 (MaxPoolin (None, 4, 4, 86)          0         \n",
      "_________________________________________________________________\n",
      "flatten_42 (Flatten)         (None, 1376)              0         \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 1720)              2368440   \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 10)                17210     \n",
      "=================================================================\n",
      "Total params: 2,486,872\n",
      "Trainable params: 2,486,872\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8b182bdcb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8b182bdcb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 986/1000 [============================>.] - ETA: 0s - loss: 1.3670 - accuracy: 0.5033WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf431d9e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf431d9e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.3636 - accuracy: 0.5047 - val_loss: 1.0976 - val_accuracy: 0.6184\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9415 - accuracy: 0.6691 - val_loss: 0.8904 - val_accuracy: 0.6924\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7571 - accuracy: 0.7340 - val_loss: 0.7840 - val_accuracy: 0.7295\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6150 - accuracy: 0.7845 - val_loss: 0.7543 - val_accuracy: 0.7380\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4878 - accuracy: 0.8303 - val_loss: 0.7520 - val_accuracy: 0.7509\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3714 - accuracy: 0.8688 - val_loss: 0.7853 - val_accuracy: 0.7572\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2694 - accuracy: 0.9054 - val_loss: 0.8833 - val_accuracy: 0.7459\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1908 - accuracy: 0.9329 - val_loss: 0.9901 - val_accuracy: 0.7543\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1424 - accuracy: 0.9502 - val_loss: 1.1409 - val_accuracy: 0.7500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7121 - accuracy: 0.7740WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0074s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7853 - accuracy: 0.7572\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7121 - accuracy: 0.7740WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0067s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7853 - accuracy: 0.7572\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7121 - accuracy: 0.7740WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0067s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7853 - accuracy: 0.7572\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7121 - accuracy: 0.7740WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0067s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7853 - accuracy: 0.7572\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7121 - accuracy: 0.7740WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0075s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7853 - accuracy: 0.7572\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7121 - accuracy: 0.7740WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0066s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7853 - accuracy: 0.7572\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7121 - accuracy: 0.7740WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0069s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7853 - accuracy: 0.7572\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7121 - accuracy: 0.7740WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_test_batch_end` time: 0.0072s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7853 - accuracy: 0.7572\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7121 - accuracy: 0.7740WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0068s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7853 - accuracy: 0.7572\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7121 - accuracy: 0.7740WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0069s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7853 - accuracy: 0.7572\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7121 - accuracy: 0.7740WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_test_batch_end` time: 0.0066s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7853 - accuracy: 0.7572\n",
      "Model: \"functional_87\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_44 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_129 (Conv2D)          (None, 32, 32, 44)        1232      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_129 (MaxPoolin (None, 16, 16, 44)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_130 (Conv2D)          (None, 16, 16, 88)        34936     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_130 (MaxPoolin (None, 8, 8, 88)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_131 (Conv2D)          (None, 8, 8, 88)          69784     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_131 (MaxPoolin (None, 4, 4, 88)          0         \n",
      "_________________________________________________________________\n",
      "flatten_43 (Flatten)         (None, 1408)              0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 1760)              2479840   \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 10)                17610     \n",
      "=================================================================\n",
      "Total params: 2,603,402\n",
      "Trainable params: 2,603,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8b1861acb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8b1861acb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1.3386 - accuracy: 0.5185WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd3c9ad40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd3c9ad40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.3386 - accuracy: 0.5185 - val_loss: 1.0242 - val_accuracy: 0.6360\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.9050 - accuracy: 0.6813 - val_loss: 0.8559 - val_accuracy: 0.6992\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.7286 - accuracy: 0.7451 - val_loss: 0.8031 - val_accuracy: 0.7214\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5930 - accuracy: 0.7907 - val_loss: 0.7505 - val_accuracy: 0.7461\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.4676 - accuracy: 0.8370 - val_loss: 0.8282 - val_accuracy: 0.7441\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3479 - accuracy: 0.8771 - val_loss: 0.7906 - val_accuracy: 0.7566\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.2503 - accuracy: 0.9120 - val_loss: 0.8532 - val_accuracy: 0.7538\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1715 - accuracy: 0.9407 - val_loss: 1.0058 - val_accuracy: 0.7507\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1367 - accuracy: 0.9512 - val_loss: 1.0726 - val_accuracy: 0.7574\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1055 - accuracy: 0.9641 - val_loss: 1.3248 - val_accuracy: 0.7394\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0972 - accuracy: 0.9672 - val_loss: 1.3146 - val_accuracy: 0.7612\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0858 - accuracy: 0.9718 - val_loss: 1.3863 - val_accuracy: 0.7327\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0828 - accuracy: 0.9726 - val_loss: 1.4859 - val_accuracy: 0.7540\n",
      "Epoch 14/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0823 - accuracy: 0.9730 - val_loss: 1.5252 - val_accuracy: 0.7489\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1968 - accuracy: 0.7720WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0068s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.3146 - accuracy: 0.7612\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1968 - accuracy: 0.7720WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0067s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.3146 - accuracy: 0.7612\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1968 - accuracy: 0.7720WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0067s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.3146 - accuracy: 0.7612\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1968 - accuracy: 0.7720WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0067s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.3146 - accuracy: 0.7612\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1968 - accuracy: 0.7720WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0068s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.3146 - accuracy: 0.7612\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1968 - accuracy: 0.7720WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0021s vs `on_test_batch_end` time: 0.0069s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.3146 - accuracy: 0.7612\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1968 - accuracy: 0.7720WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0067s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.3146 - accuracy: 0.7612\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1968 - accuracy: 0.7720WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0067s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.3146 - accuracy: 0.7612\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1968 - accuracy: 0.7720WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0067s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.3146 - accuracy: 0.7612\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1968 - accuracy: 0.7720WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0067s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.3146 - accuracy: 0.7612\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1968 - accuracy: 0.7720WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0066s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.3146 - accuracy: 0.7612\n",
      "Model: \"functional_89\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_45 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_132 (Conv2D)          (None, 32, 32, 45)        1260      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_132 (MaxPoolin (None, 16, 16, 45)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_133 (Conv2D)          (None, 16, 16, 90)        36540     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_133 (MaxPoolin (None, 8, 8, 90)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_134 (Conv2D)          (None, 8, 8, 90)          72990     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_134 (MaxPoolin (None, 4, 4, 90)          0         \n",
      "_________________________________________________________________\n",
      "flatten_44 (Flatten)         (None, 1440)              0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 1800)              2593800   \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 10)                18010     \n",
      "=================================================================\n",
      "Total params: 2,722,600\n",
      "Trainable params: 2,722,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf4483c20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf4483c20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1.3725 - accuracy: 0.5042WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b18472b00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b18472b00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.3725 - accuracy: 0.5042 - val_loss: 1.0278 - val_accuracy: 0.6412\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.9346 - accuracy: 0.6694 - val_loss: 0.9460 - val_accuracy: 0.6705\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.7613 - accuracy: 0.7334 - val_loss: 0.7897 - val_accuracy: 0.7189\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.6207 - accuracy: 0.7813 - val_loss: 0.8217 - val_accuracy: 0.7140\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5045 - accuracy: 0.8235 - val_loss: 0.8417 - val_accuracy: 0.7238\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3899 - accuracy: 0.8659 - val_loss: 0.8217 - val_accuracy: 0.7440\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.2881 - accuracy: 0.8993 - val_loss: 0.8922 - val_accuracy: 0.7337\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1942 - accuracy: 0.9334 - val_loss: 1.0214 - val_accuracy: 0.7416\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1516 - accuracy: 0.9477 - val_loss: 1.0628 - val_accuracy: 0.7494\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1227 - accuracy: 0.9576 - val_loss: 1.2408 - val_accuracy: 0.7360\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1108 - accuracy: 0.9630 - val_loss: 1.2943 - val_accuracy: 0.7516\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0920 - accuracy: 0.9692 - val_loss: 1.3439 - val_accuracy: 0.7522\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0909 - accuracy: 0.9694 - val_loss: 1.5212 - val_accuracy: 0.7393\n",
      "Epoch 14/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0857 - accuracy: 0.9707 - val_loss: 1.5730 - val_accuracy: 0.7376\n",
      "Epoch 15/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0785 - accuracy: 0.9740 - val_loss: 1.6611 - val_accuracy: 0.7352\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2235 - accuracy: 0.7610WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_test_batch_end` time: 0.0069s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.3439 - accuracy: 0.7522\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2235 - accuracy: 0.7610WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0069s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.3439 - accuracy: 0.7522\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2235 - accuracy: 0.7610WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0069s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.3439 - accuracy: 0.7522\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2235 - accuracy: 0.7610WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0068s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.3439 - accuracy: 0.7522\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2235 - accuracy: 0.7610WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_test_batch_end` time: 0.0069s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.3439 - accuracy: 0.7522\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2235 - accuracy: 0.7610WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0077s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.3439 - accuracy: 0.7522\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2235 - accuracy: 0.7610WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_test_batch_end` time: 0.0074s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.3439 - accuracy: 0.7522\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2235 - accuracy: 0.7610WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0069s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.3439 - accuracy: 0.7522\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2235 - accuracy: 0.7610WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0070s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.3439 - accuracy: 0.7522\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2235 - accuracy: 0.7610WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_test_batch_end` time: 0.0070s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.3439 - accuracy: 0.7522\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2235 - accuracy: 0.7610WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_test_batch_end` time: 0.0069s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.3439 - accuracy: 0.7522\n",
      "Model: \"functional_91\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_46 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_135 (Conv2D)          (None, 32, 32, 46)        1288      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_135 (MaxPoolin (None, 16, 16, 46)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_136 (Conv2D)          (None, 16, 16, 92)        38180     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_136 (MaxPoolin (None, 8, 8, 92)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_137 (Conv2D)          (None, 8, 8, 92)          76268     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_137 (MaxPoolin (None, 4, 4, 92)          0         \n",
      "_________________________________________________________________\n",
      "flatten_45 (Flatten)         (None, 1472)              0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 1840)              2710320   \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 10)                18410     \n",
      "=================================================================\n",
      "Total params: 2,844,466\n",
      "Trainable params: 2,844,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8b24153320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8b24153320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 991/1000 [============================>.] - ETA: 0s - loss: 1.3823 - accuracy: 0.4996WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf57fd950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf57fd950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.3794 - accuracy: 0.5010 - val_loss: 1.0218 - val_accuracy: 0.6325\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.9307 - accuracy: 0.6733 - val_loss: 0.8884 - val_accuracy: 0.6908\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.7435 - accuracy: 0.7390 - val_loss: 0.7749 - val_accuracy: 0.7314\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5966 - accuracy: 0.7906 - val_loss: 0.7528 - val_accuracy: 0.7430\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.4639 - accuracy: 0.8372 - val_loss: 0.8050 - val_accuracy: 0.7331\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3378 - accuracy: 0.8829 - val_loss: 0.8446 - val_accuracy: 0.7468\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.2388 - accuracy: 0.9164 - val_loss: 0.8939 - val_accuracy: 0.7479\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1654 - accuracy: 0.9431 - val_loss: 1.0291 - val_accuracy: 0.7482\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1308 - accuracy: 0.9544 - val_loss: 1.1600 - val_accuracy: 0.7341\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1118 - accuracy: 0.9633 - val_loss: 1.2579 - val_accuracy: 0.7423\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0948 - accuracy: 0.9672 - val_loss: 1.3631 - val_accuracy: 0.7470\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8951 - accuracy: 0.7630WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_test_batch_end` time: 0.0070s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.0291 - accuracy: 0.7482\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8951 - accuracy: 0.7630WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0069s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.0291 - accuracy: 0.7482\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8951 - accuracy: 0.7630WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0072s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.0291 - accuracy: 0.7482\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8951 - accuracy: 0.7630WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0069s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.0291 - accuracy: 0.7482\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8951 - accuracy: 0.7630WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0072s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.0291 - accuracy: 0.7482\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8951 - accuracy: 0.7630WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_test_batch_end` time: 0.0072s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.0291 - accuracy: 0.7482\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8951 - accuracy: 0.7630WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0072s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.0291 - accuracy: 0.7482\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8951 - accuracy: 0.7630WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_test_batch_end` time: 0.0071s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.0291 - accuracy: 0.7482\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8951 - accuracy: 0.7630WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0070s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.0291 - accuracy: 0.7482\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8951 - accuracy: 0.7630WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_test_batch_end` time: 0.0080s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.0291 - accuracy: 0.7482\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8951 - accuracy: 0.7630WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0069s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.0291 - accuracy: 0.7482\n",
      "Model: \"functional_93\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_47 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_138 (Conv2D)          (None, 32, 32, 47)        1316      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_138 (MaxPoolin (None, 16, 16, 47)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_139 (Conv2D)          (None, 16, 16, 94)        39856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_139 (MaxPoolin (None, 8, 8, 94)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_140 (Conv2D)          (None, 8, 8, 94)          79618     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_140 (MaxPoolin (None, 4, 4, 94)          0         \n",
      "_________________________________________________________________\n",
      "flatten_46 (Flatten)         (None, 1504)              0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 1880)              2829400   \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 10)                18810     \n",
      "=================================================================\n",
      "Total params: 2,969,000\n",
      "Trainable params: 2,969,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf4483710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf4483710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 989/1000 [============================>.] - ETA: 0s - loss: 1.3582 - accuracy: 0.5088WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf5798680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf5798680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.3556 - accuracy: 0.5095 - val_loss: 1.0494 - val_accuracy: 0.6199\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.9240 - accuracy: 0.6715 - val_loss: 0.8581 - val_accuracy: 0.6932\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.7411 - accuracy: 0.7389 - val_loss: 0.8140 - val_accuracy: 0.7146\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.6118 - accuracy: 0.7858 - val_loss: 0.7608 - val_accuracy: 0.7383\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.4859 - accuracy: 0.8296 - val_loss: 0.8196 - val_accuracy: 0.7297\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3646 - accuracy: 0.8723 - val_loss: 0.8527 - val_accuracy: 0.7465\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.2661 - accuracy: 0.9071 - val_loss: 0.9046 - val_accuracy: 0.7548\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1897 - accuracy: 0.9337 - val_loss: 1.0218 - val_accuracy: 0.7491\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1458 - accuracy: 0.9490 - val_loss: 1.1399 - val_accuracy: 0.7396\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1214 - accuracy: 0.9577 - val_loss: 1.3325 - val_accuracy: 0.7358\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7926 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0072s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.9046 - accuracy: 0.7548\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7926 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0071s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.9046 - accuracy: 0.7548\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7926 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0070s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.9046 - accuracy: 0.7548\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7926 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0076s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.9046 - accuracy: 0.7548\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7926 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0070s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.9046 - accuracy: 0.7548\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7926 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0073s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.9046 - accuracy: 0.7548\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7926 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0072s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.9046 - accuracy: 0.7548\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7926 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0072s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.9046 - accuracy: 0.7548\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7926 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0081s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.9046 - accuracy: 0.7548\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7926 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0070s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.9046 - accuracy: 0.7548\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7926 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0070s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.9046 - accuracy: 0.7548\n",
      "Model: \"functional_95\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_48 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_141 (Conv2D)          (None, 32, 32, 48)        1344      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_141 (MaxPoolin (None, 16, 16, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_142 (Conv2D)          (None, 16, 16, 96)        41568     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_142 (MaxPoolin (None, 8, 8, 96)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_143 (Conv2D)          (None, 8, 8, 96)          83040     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_143 (MaxPoolin (None, 4, 4, 96)          0         \n",
      "_________________________________________________________________\n",
      "flatten_47 (Flatten)         (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 1920)              2951040   \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 10)                19210     \n",
      "=================================================================\n",
      "Total params: 3,096,202\n",
      "Trainable params: 3,096,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8b186023b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8b186023b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1.3633 - accuracy: 0.5070WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b184f3170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b184f3170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.3633 - accuracy: 0.5070 - val_loss: 1.0462 - val_accuracy: 0.6247\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.9288 - accuracy: 0.6734 - val_loss: 0.9344 - val_accuracy: 0.6744\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.7426 - accuracy: 0.7393 - val_loss: 0.8232 - val_accuracy: 0.7145\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5981 - accuracy: 0.7905 - val_loss: 0.7643 - val_accuracy: 0.7414\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.4740 - accuracy: 0.8342 - val_loss: 0.7997 - val_accuracy: 0.7313\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3499 - accuracy: 0.8779 - val_loss: 0.8714 - val_accuracy: 0.7436\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.2437 - accuracy: 0.9164 - val_loss: 0.9429 - val_accuracy: 0.7506\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1762 - accuracy: 0.9384 - val_loss: 1.0680 - val_accuracy: 0.7453\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1310 - accuracy: 0.9546 - val_loss: 1.1869 - val_accuracy: 0.7443\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1134 - accuracy: 0.9607 - val_loss: 1.2883 - val_accuracy: 0.7469\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8469 - accuracy: 0.7750WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0073s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.9429 - accuracy: 0.7506\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8469 - accuracy: 0.7750WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0072s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.9429 - accuracy: 0.7506\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8469 - accuracy: 0.7750WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0072s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.9429 - accuracy: 0.7506\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8469 - accuracy: 0.7750WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0082s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.9429 - accuracy: 0.7506\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8469 - accuracy: 0.7750WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0072s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.9429 - accuracy: 0.7506\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8469 - accuracy: 0.7750WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_test_batch_end` time: 0.0074s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.9429 - accuracy: 0.7506\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8469 - accuracy: 0.7750WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0071s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.9429 - accuracy: 0.7506\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8469 - accuracy: 0.7750WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0074s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.9429 - accuracy: 0.7506\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8469 - accuracy: 0.7750WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0082s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.9429 - accuracy: 0.7506\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8469 - accuracy: 0.7750WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0080s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.9429 - accuracy: 0.7506\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8469 - accuracy: 0.7750WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0077s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.9429 - accuracy: 0.7506\n",
      "Model: \"functional_97\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_49 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_144 (Conv2D)          (None, 32, 32, 49)        1372      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_144 (MaxPoolin (None, 16, 16, 49)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_145 (Conv2D)          (None, 16, 16, 98)        43316     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_145 (MaxPoolin (None, 8, 8, 98)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_146 (Conv2D)          (None, 8, 8, 98)          86534     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_146 (MaxPoolin (None, 4, 4, 98)          0         \n",
      "_________________________________________________________________\n",
      "flatten_48 (Flatten)         (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 1960)              3075240   \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 10)                19610     \n",
      "=================================================================\n",
      "Total params: 3,226,072\n",
      "Trainable params: 3,226,072\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8b18233290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8b18233290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 991/1000 [============================>.] - ETA: 0s - loss: 1.4010 - accuracy: 0.4919WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b1853c290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b1853c290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.3973 - accuracy: 0.4933 - val_loss: 1.0324 - val_accuracy: 0.6345\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.9438 - accuracy: 0.6674 - val_loss: 0.9042 - val_accuracy: 0.6810\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.7532 - accuracy: 0.7346 - val_loss: 0.8070 - val_accuracy: 0.7180\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.6025 - accuracy: 0.7873 - val_loss: 0.7368 - val_accuracy: 0.7455\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.4738 - accuracy: 0.8331 - val_loss: 0.7713 - val_accuracy: 0.7539\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3534 - accuracy: 0.8757 - val_loss: 0.8419 - val_accuracy: 0.7448\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.2509 - accuracy: 0.9117 - val_loss: 0.8853 - val_accuracy: 0.7548\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1763 - accuracy: 0.9384 - val_loss: 1.0415 - val_accuracy: 0.7506\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1274 - accuracy: 0.9558 - val_loss: 1.1486 - val_accuracy: 0.7434\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1087 - accuracy: 0.9635 - val_loss: 1.2268 - val_accuracy: 0.7478\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8429 - accuracy: 0.7660WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0085s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.8853 - accuracy: 0.7548\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8429 - accuracy: 0.7660WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0084s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.8853 - accuracy: 0.7548\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8429 - accuracy: 0.7660WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0084s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.8853 - accuracy: 0.7548\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8429 - accuracy: 0.7660WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0089s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.8853 - accuracy: 0.7548\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8429 - accuracy: 0.7660WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0083s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.8853 - accuracy: 0.7548\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8429 - accuracy: 0.7660WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_test_batch_end` time: 0.0084s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.8853 - accuracy: 0.7548\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8429 - accuracy: 0.7660WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_test_batch_end` time: 0.0087s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.8853 - accuracy: 0.7548\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8429 - accuracy: 0.7660WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0086s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.8853 - accuracy: 0.7548\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8429 - accuracy: 0.7660WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0086s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.8853 - accuracy: 0.7548\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8429 - accuracy: 0.7660WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_test_batch_end` time: 0.0083s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.8853 - accuracy: 0.7548\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8429 - accuracy: 0.7660WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0084s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.8853 - accuracy: 0.7548\n",
      "Model: \"functional_99\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_50 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_147 (Conv2D)          (None, 32, 32, 50)        1400      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_147 (MaxPoolin (None, 16, 16, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_148 (Conv2D)          (None, 16, 16, 100)       45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_148 (MaxPoolin (None, 8, 8, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_149 (Conv2D)          (None, 8, 8, 100)         90100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_149 (MaxPoolin (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_49 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 2000)              3202000   \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 10)                20010     \n",
      "=================================================================\n",
      "Total params: 3,358,610\n",
      "Trainable params: 3,358,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd39fc9e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd39fc9e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 987/1000 [============================>.] - ETA: 0s - loss: 1.3586 - accuracy: 0.5094WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd3c9a4d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd3c9a4d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.3535 - accuracy: 0.5112 - val_loss: 1.0766 - val_accuracy: 0.6215\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.9044 - accuracy: 0.6812 - val_loss: 0.8815 - val_accuracy: 0.6931\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.7184 - accuracy: 0.7470 - val_loss: 0.7550 - val_accuracy: 0.7401\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5721 - accuracy: 0.7998 - val_loss: 0.7348 - val_accuracy: 0.7532\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.4470 - accuracy: 0.8436 - val_loss: 0.7692 - val_accuracy: 0.7531\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3235 - accuracy: 0.8865 - val_loss: 0.8257 - val_accuracy: 0.7441\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.2193 - accuracy: 0.9229 - val_loss: 0.8957 - val_accuracy: 0.7639\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1553 - accuracy: 0.9458 - val_loss: 1.0043 - val_accuracy: 0.7583\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1207 - accuracy: 0.9588 - val_loss: 1.1172 - val_accuracy: 0.7691\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1031 - accuracy: 0.9640 - val_loss: 1.2109 - val_accuracy: 0.7496\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0884 - accuracy: 0.9690 - val_loss: 1.3329 - val_accuracy: 0.7562\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0845 - accuracy: 0.9713 - val_loss: 1.3942 - val_accuracy: 0.7508\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9257 - accuracy: 0.7810WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0087s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.1172 - accuracy: 0.7691\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9257 - accuracy: 0.7810WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0090s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.1172 - accuracy: 0.7691\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9257 - accuracy: 0.7810WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0087s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.1172 - accuracy: 0.7691\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9257 - accuracy: 0.7810WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0087s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.1172 - accuracy: 0.7691\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9257 - accuracy: 0.7810WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_test_batch_end` time: 0.0089s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 1.1172 - accuracy: 0.7691\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9257 - accuracy: 0.7810WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0092s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.1172 - accuracy: 0.7691\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9257 - accuracy: 0.7810WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0085s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.1172 - accuracy: 0.7691\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1.1172 - accuracy: 0.7691\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9257 - accuracy: 0.7810WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0085s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.1172 - accuracy: 0.7691\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9257 - accuracy: 0.7810WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0085s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.1172 - accuracy: 0.7691\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9257 - accuracy: 0.7810WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0095s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.1172 - accuracy: 0.7691\n",
      "Model: \"functional_101\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_51 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_150 (Conv2D)          (None, 32, 32, 51)        1428      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_150 (MaxPoolin (None, 16, 16, 51)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_151 (Conv2D)          (None, 16, 16, 102)       46920     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_151 (MaxPoolin (None, 8, 8, 102)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_152 (Conv2D)          (None, 8, 8, 102)         93738     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_152 (MaxPoolin (None, 4, 4, 102)         0         \n",
      "_________________________________________________________________\n",
      "flatten_50 (Flatten)         (None, 1632)              0         \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 2040)              3331320   \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 10)                20410     \n",
      "=================================================================\n",
      "Total params: 3,493,816\n",
      "Trainable params: 3,493,816\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8c0ff23950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8c0ff23950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 987/1000 [============================>.] - ETA: 0s - loss: 1.3531 - accuracy: 0.5092WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b7e873560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b7e873560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.3491 - accuracy: 0.5110 - val_loss: 1.0209 - val_accuracy: 0.6428\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.9216 - accuracy: 0.6748 - val_loss: 0.8918 - val_accuracy: 0.6867\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.7421 - accuracy: 0.7409 - val_loss: 0.8409 - val_accuracy: 0.7102\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.6056 - accuracy: 0.7889 - val_loss: 0.7730 - val_accuracy: 0.7306\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.4794 - accuracy: 0.8311 - val_loss: 0.7615 - val_accuracy: 0.7485\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3580 - accuracy: 0.8749 - val_loss: 0.8010 - val_accuracy: 0.7544\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.2529 - accuracy: 0.9114 - val_loss: 0.9085 - val_accuracy: 0.7558\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1819 - accuracy: 0.9364 - val_loss: 1.0383 - val_accuracy: 0.7514\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1349 - accuracy: 0.9521 - val_loss: 1.1633 - val_accuracy: 0.7443\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1115 - accuracy: 0.9622 - val_loss: 1.2823 - val_accuracy: 0.7506\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8702 - accuracy: 0.7660WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0088s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.9085 - accuracy: 0.7558\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8702 - accuracy: 0.7660WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_test_batch_end` time: 0.0091s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.9085 - accuracy: 0.7558\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8702 - accuracy: 0.7660WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0087s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.9085 - accuracy: 0.7558\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8702 - accuracy: 0.7660WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0085s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.9085 - accuracy: 0.7558\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8702 - accuracy: 0.7660WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0086s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.9085 - accuracy: 0.7558\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8702 - accuracy: 0.7660WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0086s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.9085 - accuracy: 0.7558\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8702 - accuracy: 0.7660WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0030s vs `on_test_batch_end` time: 0.0100s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.9085 - accuracy: 0.7558\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8702 - accuracy: 0.7660WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_test_batch_end` time: 0.0093s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.9085 - accuracy: 0.7558\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8702 - accuracy: 0.7660WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0088s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.9085 - accuracy: 0.7558\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8702 - accuracy: 0.7660WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0091s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.9085 - accuracy: 0.7558\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8702 - accuracy: 0.7660WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0092s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.9085 - accuracy: 0.7558\n",
      "Model: \"functional_103\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_52 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_153 (Conv2D)          (None, 32, 32, 52)        1456      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_153 (MaxPoolin (None, 16, 16, 52)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_154 (Conv2D)          (None, 16, 16, 104)       48776     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_154 (MaxPoolin (None, 8, 8, 104)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_155 (Conv2D)          (None, 8, 8, 104)         97448     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_155 (MaxPoolin (None, 4, 4, 104)         0         \n",
      "_________________________________________________________________\n",
      "flatten_51 (Flatten)         (None, 1664)              0         \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 2080)              3463200   \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 10)                20810     \n",
      "=================================================================\n",
      "Total params: 3,631,690\n",
      "Trainable params: 3,631,690\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8b24153710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8b24153710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 993/1000 [============================>.] - ETA: 0s - loss: 1.3725 - accuracy: 0.5037WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf4600440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf4600440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.3706 - accuracy: 0.5043 - val_loss: 1.0418 - val_accuracy: 0.6286\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.9396 - accuracy: 0.6651 - val_loss: 0.9098 - val_accuracy: 0.6832\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.7605 - accuracy: 0.7352 - val_loss: 0.8042 - val_accuracy: 0.7203\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.6277 - accuracy: 0.7790 - val_loss: 0.7731 - val_accuracy: 0.7346\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5050 - accuracy: 0.8242 - val_loss: 0.7657 - val_accuracy: 0.7459\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3902 - accuracy: 0.8633 - val_loss: 0.8252 - val_accuracy: 0.7448\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.2803 - accuracy: 0.9008 - val_loss: 0.8469 - val_accuracy: 0.7602\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1971 - accuracy: 0.9311 - val_loss: 0.9704 - val_accuracy: 0.7432\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1502 - accuracy: 0.9489 - val_loss: 1.1118 - val_accuracy: 0.7467\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1174 - accuracy: 0.9602 - val_loss: 1.2610 - val_accuracy: 0.7333\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8048 - accuracy: 0.7490WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0092s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.8469 - accuracy: 0.7602\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8048 - accuracy: 0.7490WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0089s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.8469 - accuracy: 0.7602\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8048 - accuracy: 0.7490WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0087s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.8469 - accuracy: 0.7602\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8048 - accuracy: 0.7490WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0085s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.8469 - accuracy: 0.7602\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8048 - accuracy: 0.7490WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0097s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.8469 - accuracy: 0.7602\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8048 - accuracy: 0.7490WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0087s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.8469 - accuracy: 0.7602\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8048 - accuracy: 0.7490WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_test_batch_end` time: 0.0091s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.8469 - accuracy: 0.7602\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8048 - accuracy: 0.7490WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_test_batch_end` time: 0.0086s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.8469 - accuracy: 0.7602\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8048 - accuracy: 0.7490WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0089s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.8469 - accuracy: 0.7602\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8048 - accuracy: 0.7490WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0086s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.8469 - accuracy: 0.7602\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8048 - accuracy: 0.7490WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_test_batch_end` time: 0.0088s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.8469 - accuracy: 0.7602\n",
      "Model: \"functional_105\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_53 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_156 (Conv2D)          (None, 32, 32, 53)        1484      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_156 (MaxPoolin (None, 16, 16, 53)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_157 (Conv2D)          (None, 16, 16, 106)       50668     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_157 (MaxPoolin (None, 8, 8, 106)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_158 (Conv2D)          (None, 8, 8, 106)         101230    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_158 (MaxPoolin (None, 4, 4, 106)         0         \n",
      "_________________________________________________________________\n",
      "flatten_52 (Flatten)         (None, 1696)              0         \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 2120)              3597640   \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 10)                21210     \n",
      "=================================================================\n",
      "Total params: 3,772,232\n",
      "Trainable params: 3,772,232\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd462ddd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd462ddd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 1.3509 - accuracy: 0.5109WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf586fb90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf586fb90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.3504 - accuracy: 0.5111 - val_loss: 1.0103 - val_accuracy: 0.6408\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.9113 - accuracy: 0.6783 - val_loss: 0.8440 - val_accuracy: 0.7057\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.7174 - accuracy: 0.7487 - val_loss: 0.7950 - val_accuracy: 0.7298\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5736 - accuracy: 0.7979 - val_loss: 0.7431 - val_accuracy: 0.7476\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.4540 - accuracy: 0.8398 - val_loss: 0.7487 - val_accuracy: 0.7550\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3354 - accuracy: 0.8810 - val_loss: 0.7914 - val_accuracy: 0.7661\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.2416 - accuracy: 0.9164 - val_loss: 0.8709 - val_accuracy: 0.7606\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1675 - accuracy: 0.9411 - val_loss: 0.9950 - val_accuracy: 0.7633\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1247 - accuracy: 0.9574 - val_loss: 1.1080 - val_accuracy: 0.7607\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7248 - accuracy: 0.7790WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0092s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.7914 - accuracy: 0.7661\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7248 - accuracy: 0.7790WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0097s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.7914 - accuracy: 0.7661\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7248 - accuracy: 0.7790WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0090s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.7914 - accuracy: 0.7661\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7248 - accuracy: 0.7790WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0094s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.7914 - accuracy: 0.7661\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7248 - accuracy: 0.7790WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0032s vs `on_test_batch_end` time: 0.0106s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.7914 - accuracy: 0.7661\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7248 - accuracy: 0.7790WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0094s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.7914 - accuracy: 0.7661\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7248 - accuracy: 0.7790WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_test_batch_end` time: 0.0090s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.7914 - accuracy: 0.7661\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7248 - accuracy: 0.7790WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0091s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.7914 - accuracy: 0.7661\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7248 - accuracy: 0.7790WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0088s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.7914 - accuracy: 0.7661\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7248 - accuracy: 0.7790WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0095s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.7914 - accuracy: 0.7661\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7248 - accuracy: 0.7790WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0030s vs `on_test_batch_end` time: 0.0128s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.7914 - accuracy: 0.7661\n",
      "Model: \"functional_107\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_54 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_159 (Conv2D)          (None, 32, 32, 54)        1512      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_159 (MaxPoolin (None, 16, 16, 54)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_160 (Conv2D)          (None, 16, 16, 108)       52596     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_160 (MaxPoolin (None, 8, 8, 108)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_161 (Conv2D)          (None, 8, 8, 108)         105084    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_161 (MaxPoolin (None, 4, 4, 108)         0         \n",
      "_________________________________________________________________\n",
      "flatten_53 (Flatten)         (None, 1728)              0         \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 2160)              3734640   \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 10)                21610     \n",
      "=================================================================\n",
      "Total params: 3,915,442\n",
      "Trainable params: 3,915,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd3b14050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd3b14050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 996/1000 [============================>.] - ETA: 0s - loss: 1.3544 - accuracy: 0.5092WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b2409bb00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b2409bb00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.3526 - accuracy: 0.5099 - val_loss: 1.0625 - val_accuracy: 0.6201\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.9025 - accuracy: 0.6815 - val_loss: 0.9063 - val_accuracy: 0.6792\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.7212 - accuracy: 0.7483 - val_loss: 0.7704 - val_accuracy: 0.7321\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5780 - accuracy: 0.7978 - val_loss: 0.7355 - val_accuracy: 0.7508\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.4549 - accuracy: 0.8402 - val_loss: 0.7539 - val_accuracy: 0.7509\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3322 - accuracy: 0.8829 - val_loss: 0.7919 - val_accuracy: 0.7618\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.2296 - accuracy: 0.9202 - val_loss: 0.9025 - val_accuracy: 0.7429\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1671 - accuracy: 0.9420 - val_loss: 1.0411 - val_accuracy: 0.7486\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.1252 - accuracy: 0.9568 - val_loss: 1.2631 - val_accuracy: 0.7382\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7462 - accuracy: 0.7590WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0035s vs `on_test_batch_end` time: 0.0108s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7919 - accuracy: 0.7618\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7462 - accuracy: 0.7590WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0108s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7919 - accuracy: 0.7618\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7462 - accuracy: 0.7590WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0090s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7919 - accuracy: 0.7618\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7462 - accuracy: 0.7590WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0030s vs `on_test_batch_end` time: 0.0089s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7919 - accuracy: 0.7618\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7462 - accuracy: 0.7590WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0108s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7919 - accuracy: 0.7618\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7462 - accuracy: 0.7590WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0106s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7919 - accuracy: 0.7618\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7462 - accuracy: 0.7590WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0108s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7919 - accuracy: 0.7618\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7462 - accuracy: 0.7590WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_test_batch_end` time: 0.0091s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7919 - accuracy: 0.7618\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7462 - accuracy: 0.7590WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0109s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7919 - accuracy: 0.7618\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7462 - accuracy: 0.7590WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_test_batch_end` time: 0.0109s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7919 - accuracy: 0.7618\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7462 - accuracy: 0.7590WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0109s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7919 - accuracy: 0.7618\n",
      "Model: \"functional_109\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_55 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_162 (Conv2D)          (None, 32, 32, 55)        1540      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_162 (MaxPoolin (None, 16, 16, 55)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_163 (Conv2D)          (None, 16, 16, 110)       54560     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_163 (MaxPoolin (None, 8, 8, 110)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_164 (Conv2D)          (None, 8, 8, 110)         109010    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_164 (MaxPoolin (None, 4, 4, 110)         0         \n",
      "_________________________________________________________________\n",
      "flatten_54 (Flatten)         (None, 1760)              0         \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 2200)              3874200   \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 10)                22010     \n",
      "=================================================================\n",
      "Total params: 4,061,320\n",
      "Trainable params: 4,061,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd395c050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd395c050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1.3659 - accuracy: 0.5073WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd3bd63b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd3bd63b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 1.3659 - accuracy: 0.5073 - val_loss: 1.0854 - val_accuracy: 0.6212\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.9241 - accuracy: 0.6740 - val_loss: 0.8695 - val_accuracy: 0.6971\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.7371 - accuracy: 0.7409 - val_loss: 0.8159 - val_accuracy: 0.7192\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5917 - accuracy: 0.7918 - val_loss: 0.7874 - val_accuracy: 0.7408\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.4654 - accuracy: 0.8371 - val_loss: 0.8280 - val_accuracy: 0.7300\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3416 - accuracy: 0.8789 - val_loss: 0.8109 - val_accuracy: 0.7509\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.2390 - accuracy: 0.9152 - val_loss: 0.9145 - val_accuracy: 0.7468\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1686 - accuracy: 0.9409 - val_loss: 1.0740 - val_accuracy: 0.7398\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1381 - accuracy: 0.9541 - val_loss: 1.1418 - val_accuracy: 0.7444\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7421 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0099s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.8109 - accuracy: 0.7509\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7421 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0104s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.8109 - accuracy: 0.7509\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7421 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0090s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.8109 - accuracy: 0.7509\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7421 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0090s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.8109 - accuracy: 0.7509\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7421 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_test_batch_end` time: 0.0094s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.8109 - accuracy: 0.7509\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7421 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_test_batch_end` time: 0.0091s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.8109 - accuracy: 0.7509\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7421 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0097s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.8109 - accuracy: 0.7509\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7421 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0090s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.8109 - accuracy: 0.7509\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7421 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0091s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.8109 - accuracy: 0.7509\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7421 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0090s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.8109 - accuracy: 0.7509\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7421 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0092s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.8109 - accuracy: 0.7509\n",
      "Model: \"functional_111\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_56 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_165 (Conv2D)          (None, 32, 32, 56)        1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_165 (MaxPoolin (None, 16, 16, 56)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_166 (Conv2D)          (None, 16, 16, 112)       56560     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_166 (MaxPoolin (None, 8, 8, 112)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_167 (Conv2D)          (None, 8, 8, 112)         113008    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_167 (MaxPoolin (None, 4, 4, 112)         0         \n",
      "_________________________________________________________________\n",
      "flatten_55 (Flatten)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 2240)              4016320   \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 10)                22410     \n",
      "=================================================================\n",
      "Total params: 4,209,866\n",
      "Trainable params: 4,209,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd3abe050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd3abe050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "   1/1000 [..............................] - ETA: 0s - loss: 2.3107 - accuracy: 0.1200WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_train_batch_end` time: 0.0024s). Check your callbacks.\n",
      " 997/1000 [============================>.] - ETA: 0s - loss: 1.3510 - accuracy: 0.5114WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b1806c440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b1806c440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_test_batch_end` time: 0.0015s). Check your callbacks.\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 1.3501 - accuracy: 0.5117 - val_loss: 1.0866 - val_accuracy: 0.6166\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.9121 - accuracy: 0.6782 - val_loss: 0.8262 - val_accuracy: 0.7079\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.7218 - accuracy: 0.7462 - val_loss: 0.7764 - val_accuracy: 0.7320\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5749 - accuracy: 0.7977 - val_loss: 0.7374 - val_accuracy: 0.7554\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.4484 - accuracy: 0.8420 - val_loss: 0.7716 - val_accuracy: 0.7505\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3240 - accuracy: 0.8867 - val_loss: 0.8440 - val_accuracy: 0.7507\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.2284 - accuracy: 0.9192 - val_loss: 0.9309 - val_accuracy: 0.7558\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1555 - accuracy: 0.9476 - val_loss: 1.0479 - val_accuracy: 0.7488\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1245 - accuracy: 0.9579 - val_loss: 1.1575 - val_accuracy: 0.7496\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1046 - accuracy: 0.9638 - val_loss: 1.2469 - val_accuracy: 0.7540\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8189 - accuracy: 0.7840WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_test_batch_end` time: 0.0094s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.9309 - accuracy: 0.7558\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8189 - accuracy: 0.7840WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0092s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.9309 - accuracy: 0.7558\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8189 - accuracy: 0.7840WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0032s vs `on_test_batch_end` time: 0.0091s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.9309 - accuracy: 0.7558\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8189 - accuracy: 0.7840WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0092s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.9309 - accuracy: 0.7558\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8189 - accuracy: 0.7840WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0031s vs `on_test_batch_end` time: 0.0096s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.9309 - accuracy: 0.7558\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8189 - accuracy: 0.7840WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0092s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.9309 - accuracy: 0.7558\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8189 - accuracy: 0.7840WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0090s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.9309 - accuracy: 0.7558\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8189 - accuracy: 0.7840WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0091s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.9309 - accuracy: 0.7558\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8189 - accuracy: 0.7840WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0089s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.9309 - accuracy: 0.7558\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8189 - accuracy: 0.7840WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_test_batch_end` time: 0.0092s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.9309 - accuracy: 0.7558\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8189 - accuracy: 0.7840WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0092s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.9309 - accuracy: 0.7558\n",
      "Model: \"functional_113\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_57 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_168 (Conv2D)          (None, 32, 32, 57)        1596      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_168 (MaxPoolin (None, 16, 16, 57)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_169 (Conv2D)          (None, 16, 16, 114)       58596     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_169 (MaxPoolin (None, 8, 8, 114)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_170 (Conv2D)          (None, 8, 8, 114)         117078    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_170 (MaxPoolin (None, 4, 4, 114)         0         \n",
      "_________________________________________________________________\n",
      "flatten_56 (Flatten)         (None, 1824)              0         \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 2280)              4161000   \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 10)                22810     \n",
      "=================================================================\n",
      "Total params: 4,361,080\n",
      "Trainable params: 4,361,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd3c528c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd3c528c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "   1/1000 [..............................] - ETA: 0s - loss: 2.3208 - accuracy: 0.0600WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0015s vs `on_train_batch_end` time: 0.0025s). Check your callbacks.\n",
      " 996/1000 [============================>.] - ETA: 0s - loss: 1.3701 - accuracy: 0.5032WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf586f9e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf586f9e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 1.3693 - accuracy: 0.5035 - val_loss: 1.0928 - val_accuracy: 0.6208\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.9275 - accuracy: 0.6727 - val_loss: 0.8775 - val_accuracy: 0.6932\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7447 - accuracy: 0.7386 - val_loss: 0.7912 - val_accuracy: 0.7272\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.6005 - accuracy: 0.7887 - val_loss: 0.7578 - val_accuracy: 0.7430\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.4777 - accuracy: 0.8325 - val_loss: 0.8074 - val_accuracy: 0.7431\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.3540 - accuracy: 0.8752 - val_loss: 0.8357 - val_accuracy: 0.7463\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.2522 - accuracy: 0.9114 - val_loss: 0.9019 - val_accuracy: 0.7441\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.1818 - accuracy: 0.9353 - val_loss: 1.0082 - val_accuracy: 0.7531\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1344 - accuracy: 0.9538 - val_loss: 1.1424 - val_accuracy: 0.7403\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.1133 - accuracy: 0.9608 - val_loss: 1.2606 - val_accuracy: 0.7480\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.1022 - accuracy: 0.9644 - val_loss: 1.3430 - val_accuracy: 0.7430\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8757 - accuracy: 0.7620WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0099s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 1.0082 - accuracy: 0.7531\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8757 - accuracy: 0.7620WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0095s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1.0082 - accuracy: 0.7531\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8757 - accuracy: 0.7620WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0114s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1.0082 - accuracy: 0.7531\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8757 - accuracy: 0.7620WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0095s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 1.0082 - accuracy: 0.7531\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8757 - accuracy: 0.7620WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0115s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1.0082 - accuracy: 0.7531\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8757 - accuracy: 0.7620WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0095s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 1.0082 - accuracy: 0.7531\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8757 - accuracy: 0.7620WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0098s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 1.0082 - accuracy: 0.7531\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8757 - accuracy: 0.7620WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0095s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1.0082 - accuracy: 0.7531\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8757 - accuracy: 0.7620WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0095s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1.0082 - accuracy: 0.7531\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8757 - accuracy: 0.7620WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0109s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1.0082 - accuracy: 0.7531\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8757 - accuracy: 0.7620WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0095s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 1.0082 - accuracy: 0.7531\n",
      "Model: \"functional_115\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_58 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_171 (Conv2D)          (None, 32, 32, 58)        1624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_171 (MaxPoolin (None, 16, 16, 58)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_172 (Conv2D)          (None, 16, 16, 116)       60668     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_172 (MaxPoolin (None, 8, 8, 116)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_173 (Conv2D)          (None, 8, 8, 116)         121220    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_173 (MaxPoolin (None, 4, 4, 116)         0         \n",
      "_________________________________________________________________\n",
      "flatten_57 (Flatten)         (None, 1856)              0         \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 2320)              4308240   \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 10)                23210     \n",
      "=================================================================\n",
      "Total params: 4,514,962\n",
      "Trainable params: 4,514,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8c0ff22050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8c0ff22050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 995/1000 [============================>.] - ETA: 0s - loss: 1.3567 - accuracy: 0.5087WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf4600cb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf4600cb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 1.3544 - accuracy: 0.5096 - val_loss: 1.0642 - val_accuracy: 0.6176\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.9034 - accuracy: 0.6823 - val_loss: 0.8961 - val_accuracy: 0.6852\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7183 - accuracy: 0.7480 - val_loss: 0.8616 - val_accuracy: 0.6963\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.5635 - accuracy: 0.8013 - val_loss: 0.7492 - val_accuracy: 0.7400\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.4217 - accuracy: 0.8518 - val_loss: 0.7950 - val_accuracy: 0.7401\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.3019 - accuracy: 0.8947 - val_loss: 0.7927 - val_accuracy: 0.7633\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.2025 - accuracy: 0.9300 - val_loss: 0.9928 - val_accuracy: 0.7547\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.1415 - accuracy: 0.9508 - val_loss: 1.0627 - val_accuracy: 0.7586\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.1138 - accuracy: 0.9601 - val_loss: 1.1582 - val_accuracy: 0.7545\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6918 - accuracy: 0.7790WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0101s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.7927 - accuracy: 0.7633\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6918 - accuracy: 0.7790WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0097s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7927 - accuracy: 0.7633\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6918 - accuracy: 0.7790WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0096s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.7927 - accuracy: 0.7633\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6918 - accuracy: 0.7790WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0096s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7927 - accuracy: 0.7633\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6918 - accuracy: 0.7790WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0095s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.7927 - accuracy: 0.7633\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6918 - accuracy: 0.7790WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0095s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7927 - accuracy: 0.7633\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6918 - accuracy: 0.7790WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0096s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7927 - accuracy: 0.7633\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6918 - accuracy: 0.7790WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0104s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7927 - accuracy: 0.7633\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6918 - accuracy: 0.7790WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0097s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7927 - accuracy: 0.7633\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6918 - accuracy: 0.7790WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0114s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7927 - accuracy: 0.7633\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6918 - accuracy: 0.7790WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0095s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7927 - accuracy: 0.7633\n",
      "Model: \"functional_117\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_59 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_174 (Conv2D)          (None, 32, 32, 59)        1652      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_174 (MaxPoolin (None, 16, 16, 59)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_175 (Conv2D)          (None, 16, 16, 118)       62776     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_175 (MaxPoolin (None, 8, 8, 118)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_176 (Conv2D)          (None, 8, 8, 118)         125434    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_176 (MaxPoolin (None, 4, 4, 118)         0         \n",
      "_________________________________________________________________\n",
      "flatten_58 (Flatten)         (None, 1888)              0         \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 2360)              4458040   \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 10)                23610     \n",
      "=================================================================\n",
      "Total params: 4,671,512\n",
      "Trainable params: 4,671,512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf461aa70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf461aa70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "   1/1000 [..............................] - ETA: 0s - loss: 2.2945 - accuracy: 0.1400WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0016s vs `on_train_batch_end` time: 0.0025s). Check your callbacks.\n",
      " 992/1000 [============================>.] - ETA: 0s - loss: 1.3798 - accuracy: 0.4990WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b24230ef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b24230ef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 1.3768 - accuracy: 0.5000 - val_loss: 1.0828 - val_accuracy: 0.6091\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.9564 - accuracy: 0.6617 - val_loss: 0.8824 - val_accuracy: 0.6921\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7680 - accuracy: 0.7297 - val_loss: 0.8068 - val_accuracy: 0.7199\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.6251 - accuracy: 0.7805 - val_loss: 0.7716 - val_accuracy: 0.7362\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.5081 - accuracy: 0.8207 - val_loss: 0.7652 - val_accuracy: 0.7451\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.3822 - accuracy: 0.8646 - val_loss: 0.8559 - val_accuracy: 0.7425\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.2808 - accuracy: 0.9013 - val_loss: 0.9180 - val_accuracy: 0.7443\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.2087 - accuracy: 0.9263 - val_loss: 1.0467 - val_accuracy: 0.7392\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7494 - accuracy: 0.7540WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0105s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.7652 - accuracy: 0.7451\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7494 - accuracy: 0.7540WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0096s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7652 - accuracy: 0.7451\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7494 - accuracy: 0.7540WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0031s vs `on_test_batch_end` time: 0.0098s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7652 - accuracy: 0.7451\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7494 - accuracy: 0.7540WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0096s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7652 - accuracy: 0.7451\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7494 - accuracy: 0.7540WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0098s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7652 - accuracy: 0.7451\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7494 - accuracy: 0.7540WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0147s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7652 - accuracy: 0.7451\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7494 - accuracy: 0.7540WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0146s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7652 - accuracy: 0.7451\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7494 - accuracy: 0.7540WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0114s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7652 - accuracy: 0.7451\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7494 - accuracy: 0.7540WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0098s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7652 - accuracy: 0.7451\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7494 - accuracy: 0.7540WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0033s vs `on_test_batch_end` time: 0.0129s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7652 - accuracy: 0.7451\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7494 - accuracy: 0.7540WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0098s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7652 - accuracy: 0.7451\n",
      "Model: \"functional_119\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_60 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_177 (Conv2D)          (None, 32, 32, 60)        1680      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_177 (MaxPoolin (None, 16, 16, 60)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_178 (Conv2D)          (None, 16, 16, 120)       64920     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_178 (MaxPoolin (None, 8, 8, 120)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_179 (Conv2D)          (None, 8, 8, 120)         129720    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_179 (MaxPoolin (None, 4, 4, 120)         0         \n",
      "_________________________________________________________________\n",
      "flatten_59 (Flatten)         (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 2400)              4610400   \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 10)                24010     \n",
      "=================================================================\n",
      "Total params: 4,830,730\n",
      "Trainable params: 4,830,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf43d69e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf43d69e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "   1/1000 [..............................] - ETA: 0s - loss: 2.2939 - accuracy: 0.0600WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0018s vs `on_train_batch_end` time: 0.0037s). Check your callbacks.\n",
      " 993/1000 [============================>.] - ETA: 0s - loss: 1.3921 - accuracy: 0.4977WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b1844f050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b1844f050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 1.3902 - accuracy: 0.4985 - val_loss: 1.0656 - val_accuracy: 0.6234\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.9332 - accuracy: 0.6707 - val_loss: 0.8994 - val_accuracy: 0.6901\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7502 - accuracy: 0.7377 - val_loss: 0.7862 - val_accuracy: 0.7224\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.6045 - accuracy: 0.7881 - val_loss: 0.7862 - val_accuracy: 0.7310\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.4766 - accuracy: 0.8337 - val_loss: 0.7873 - val_accuracy: 0.7464\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.3521 - accuracy: 0.8749 - val_loss: 0.7978 - val_accuracy: 0.7545\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.2523 - accuracy: 0.9108 - val_loss: 0.9560 - val_accuracy: 0.7350\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.1752 - accuracy: 0.9383 - val_loss: 1.0560 - val_accuracy: 0.7462\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.1371 - accuracy: 0.9525 - val_loss: 1.1423 - val_accuracy: 0.7472\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7260 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0102s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.7978 - accuracy: 0.7545\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7260 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0098s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7978 - accuracy: 0.7545\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7260 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0099s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7978 - accuracy: 0.7545\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7260 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0097s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7978 - accuracy: 0.7545\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7260 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0098s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7978 - accuracy: 0.7545\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7260 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0100s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7978 - accuracy: 0.7545\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7260 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0098s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7978 - accuracy: 0.7545\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7260 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0114s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7978 - accuracy: 0.7545\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7260 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0098s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7978 - accuracy: 0.7545\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7260 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0096s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7978 - accuracy: 0.7545\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7260 - accuracy: 0.7690WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0099s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7978 - accuracy: 0.7545\n",
      "Model: \"functional_121\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_61 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_180 (Conv2D)          (None, 32, 32, 61)        1708      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_180 (MaxPoolin (None, 16, 16, 61)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_181 (Conv2D)          (None, 16, 16, 122)       67100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_181 (MaxPoolin (None, 8, 8, 122)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_182 (Conv2D)          (None, 8, 8, 122)         134078    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_182 (MaxPoolin (None, 4, 4, 122)         0         \n",
      "_________________________________________________________________\n",
      "flatten_60 (Flatten)         (None, 1952)              0         \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 2440)              4765320   \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 10)                24410     \n",
      "=================================================================\n",
      "Total params: 4,992,616\n",
      "Trainable params: 4,992,616\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd3c72e60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd3c72e60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "   1/1000 [..............................] - ETA: 0s - loss: 2.2976 - accuracy: 0.1000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0015s vs `on_train_batch_end` time: 0.0027s). Check your callbacks.\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 1.3603 - accuracy: 0.5069WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf59fc710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf59fc710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 1.3597 - accuracy: 0.5071 - val_loss: 1.0465 - val_accuracy: 0.6258\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.9078 - accuracy: 0.6820 - val_loss: 0.8557 - val_accuracy: 0.6997\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7220 - accuracy: 0.7482 - val_loss: 0.7428 - val_accuracy: 0.7398\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.5640 - accuracy: 0.8014 - val_loss: 0.7521 - val_accuracy: 0.7420\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.4248 - accuracy: 0.8510 - val_loss: 0.7634 - val_accuracy: 0.7549\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.2990 - accuracy: 0.8958 - val_loss: 0.9363 - val_accuracy: 0.7299\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.1988 - accuracy: 0.9299 - val_loss: 0.9775 - val_accuracy: 0.7478\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.1461 - accuracy: 0.9503 - val_loss: 1.0465 - val_accuracy: 0.7574\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.1068 - accuracy: 0.9639 - val_loss: 1.1688 - val_accuracy: 0.7473\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.1056 - accuracy: 0.9643 - val_loss: 1.2581 - val_accuracy: 0.7496\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0855 - accuracy: 0.9712 - val_loss: 1.5159 - val_accuracy: 0.7405\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9561 - accuracy: 0.7720WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0103s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1.0465 - accuracy: 0.7574\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9561 - accuracy: 0.7720WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0100s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1.0465 - accuracy: 0.7574\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9561 - accuracy: 0.7720WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0100s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1.0465 - accuracy: 0.7574\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9561 - accuracy: 0.7720WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0124s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1.0465 - accuracy: 0.7574\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9561 - accuracy: 0.7720WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0112s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1.0465 - accuracy: 0.7574\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9561 - accuracy: 0.7720WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0099s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1.0465 - accuracy: 0.7574\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9561 - accuracy: 0.7720WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0099s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1.0465 - accuracy: 0.7574\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9561 - accuracy: 0.7720WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0101s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1.0465 - accuracy: 0.7574\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9561 - accuracy: 0.7720WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_test_batch_end` time: 0.0113s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1.0465 - accuracy: 0.7574\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9561 - accuracy: 0.7720WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0110s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.0465 - accuracy: 0.7574\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9561 - accuracy: 0.7720WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0139s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.0465 - accuracy: 0.7574\n",
      "Model: \"functional_123\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_62 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_183 (Conv2D)          (None, 32, 32, 62)        1736      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_183 (MaxPoolin (None, 16, 16, 62)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_184 (Conv2D)          (None, 16, 16, 124)       69316     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_184 (MaxPoolin (None, 8, 8, 124)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_185 (Conv2D)          (None, 8, 8, 124)         138508    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_185 (MaxPoolin (None, 4, 4, 124)         0         \n",
      "_________________________________________________________________\n",
      "flatten_61 (Flatten)         (None, 1984)              0         \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 2480)              4922800   \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 10)                24810     \n",
      "=================================================================\n",
      "Total params: 5,157,170\n",
      "Trainable params: 5,157,170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd45d3b90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd45d3b90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "   1/1000 [..............................] - ETA: 0s - loss: 2.3121 - accuracy: 0.0400WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0016s vs `on_train_batch_end` time: 0.0027s). Check your callbacks.\n",
      " 993/1000 [============================>.] - ETA: 0s - loss: 1.3450 - accuracy: 0.5135WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b10777560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b10777560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 1.3430 - accuracy: 0.5143 - val_loss: 1.1082 - val_accuracy: 0.6101\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.8982 - accuracy: 0.6854 - val_loss: 0.8562 - val_accuracy: 0.7032\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7005 - accuracy: 0.7550 - val_loss: 0.7708 - val_accuracy: 0.7299\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.5567 - accuracy: 0.8056 - val_loss: 0.8345 - val_accuracy: 0.7168\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.4156 - accuracy: 0.8555 - val_loss: 0.8104 - val_accuracy: 0.7406\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.2884 - accuracy: 0.8982 - val_loss: 0.8373 - val_accuracy: 0.7612\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.1994 - accuracy: 0.9308 - val_loss: 0.9507 - val_accuracy: 0.7532\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.1428 - accuracy: 0.9496 - val_loss: 1.1172 - val_accuracy: 0.7397\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.1155 - accuracy: 0.9609 - val_loss: 1.1581 - val_accuracy: 0.7512\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7765 - accuracy: 0.7630WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0103s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.8373 - accuracy: 0.7612\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7765 - accuracy: 0.7630WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0116s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.8373 - accuracy: 0.7612\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7765 - accuracy: 0.7630WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0031s vs `on_test_batch_end` time: 0.0126s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.8373 - accuracy: 0.7612\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7765 - accuracy: 0.7630WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0152s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.8373 - accuracy: 0.7612\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7765 - accuracy: 0.7630WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0113s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.8373 - accuracy: 0.7612\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7765 - accuracy: 0.7630WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0158s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.8373 - accuracy: 0.7612\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7765 - accuracy: 0.7630WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0112s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.8373 - accuracy: 0.7612\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7765 - accuracy: 0.7630WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0110s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.8373 - accuracy: 0.7612\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7765 - accuracy: 0.7630WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0116s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.8373 - accuracy: 0.7612\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7765 - accuracy: 0.7630WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0099s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.8373 - accuracy: 0.7612\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7765 - accuracy: 0.7630WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0028s vs `on_test_batch_end` time: 0.0109s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.8373 - accuracy: 0.7612\n",
      "Model: \"functional_125\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_63 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_186 (Conv2D)          (None, 32, 32, 63)        1764      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_186 (MaxPoolin (None, 16, 16, 63)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_187 (Conv2D)          (None, 16, 16, 126)       71568     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_187 (MaxPoolin (None, 8, 8, 126)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_188 (Conv2D)          (None, 8, 8, 126)         143010    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_188 (MaxPoolin (None, 4, 4, 126)         0         \n",
      "_________________________________________________________________\n",
      "flatten_62 (Flatten)         (None, 2016)              0         \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 2520)              5082840   \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 10)                25210     \n",
      "=================================================================\n",
      "Total params: 5,324,392\n",
      "Trainable params: 5,324,392\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8b104fdb90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8b104fdb90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "   1/1000 [..............................] - ETA: 0s - loss: 2.3023 - accuracy: 0.1200WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0015s vs `on_train_batch_end` time: 0.0029s). Check your callbacks.\n",
      " 990/1000 [============================>.] - ETA: 0s - loss: 1.3460 - accuracy: 0.5113WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b10659950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b10659950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 1.3433 - accuracy: 0.5123 - val_loss: 1.0522 - val_accuracy: 0.6289\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.8941 - accuracy: 0.6838 - val_loss: 0.8316 - val_accuracy: 0.7119\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.6942 - accuracy: 0.7552 - val_loss: 0.7939 - val_accuracy: 0.7242\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.5478 - accuracy: 0.8056 - val_loss: 0.7386 - val_accuracy: 0.7519\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.4073 - accuracy: 0.8572 - val_loss: 0.7691 - val_accuracy: 0.7580\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.2824 - accuracy: 0.9009 - val_loss: 0.8660 - val_accuracy: 0.7513\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.1936 - accuracy: 0.9334 - val_loss: 0.9717 - val_accuracy: 0.7486\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.1365 - accuracy: 0.9523 - val_loss: 1.0619 - val_accuracy: 0.7538\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7562 - accuracy: 0.7630WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0031s vs `on_test_batch_end` time: 0.0105s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7691 - accuracy: 0.7580\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7562 - accuracy: 0.7630WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0028s vs `on_test_batch_end` time: 0.0100s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7691 - accuracy: 0.7580\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7562 - accuracy: 0.7630WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0139s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7691 - accuracy: 0.7580\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7562 - accuracy: 0.7630WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0103s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7691 - accuracy: 0.7580\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7562 - accuracy: 0.7630WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0101s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7691 - accuracy: 0.7580\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7562 - accuracy: 0.7630WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0101s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7691 - accuracy: 0.7580\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7562 - accuracy: 0.7630WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0101s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7691 - accuracy: 0.7580\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7562 - accuracy: 0.7630WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0151s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.7691 - accuracy: 0.7580\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7562 - accuracy: 0.7630WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0152s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.7691 - accuracy: 0.7580\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7562 - accuracy: 0.7630WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0102s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7691 - accuracy: 0.7580\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7562 - accuracy: 0.7630WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0100s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.7691 - accuracy: 0.7580\n",
      "Model: \"functional_127\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_64 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_189 (Conv2D)          (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_189 (MaxPoolin (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_190 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_190 (MaxPoolin (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_191 (Conv2D)          (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_191 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_63 (Flatten)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 2560)              5245440   \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 10)                25610     \n",
      "=================================================================\n",
      "Total params: 5,494,282\n",
      "Trainable params: 5,494,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8b104fd680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8b104fd680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "   1/1000 [..............................] - ETA: 0s - loss: 2.3131 - accuracy: 0.1400WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0015s vs `on_train_batch_end` time: 0.0029s). Check your callbacks.\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 1.3609 - accuracy: 0.5070WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd3c72f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd3c72f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 1.3602 - accuracy: 0.5073 - val_loss: 1.0295 - val_accuracy: 0.6270\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.9106 - accuracy: 0.6809 - val_loss: 0.8910 - val_accuracy: 0.6940\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7175 - accuracy: 0.7472 - val_loss: 0.7896 - val_accuracy: 0.7283\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.5687 - accuracy: 0.7986 - val_loss: 0.7941 - val_accuracy: 0.7397\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.4311 - accuracy: 0.8484 - val_loss: 0.7950 - val_accuracy: 0.7494\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.3023 - accuracy: 0.8931 - val_loss: 0.8524 - val_accuracy: 0.7523\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.2063 - accuracy: 0.9301 - val_loss: 0.9555 - val_accuracy: 0.7499\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.1553 - accuracy: 0.9464 - val_loss: 1.1041 - val_accuracy: 0.7350\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.1202 - accuracy: 0.9583 - val_loss: 1.2815 - val_accuracy: 0.7315\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8363 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0106s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.8524 - accuracy: 0.7523\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8363 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0029s vs `on_test_batch_end` time: 0.0110s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.8524 - accuracy: 0.7523\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8363 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_test_batch_end` time: 0.0151s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.8524 - accuracy: 0.7523\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8363 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0141s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.8524 - accuracy: 0.7523\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8363 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0101s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.8524 - accuracy: 0.7523\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8363 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0102s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.8524 - accuracy: 0.7523\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8363 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0102s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.8524 - accuracy: 0.7523\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8363 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0103s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.8524 - accuracy: 0.7523\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8363 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0105s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.8524 - accuracy: 0.7523\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8363 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0101s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.8524 - accuracy: 0.7523\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8363 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0103s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.8524 - accuracy: 0.7523\n",
      "Model: \"functional_129\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_65 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_192 (Conv2D)          (None, 32, 32, 65)        1820      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_192 (MaxPoolin (None, 16, 16, 65)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_193 (Conv2D)          (None, 16, 16, 130)       76180     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_193 (MaxPoolin (None, 8, 8, 130)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_194 (Conv2D)          (None, 8, 8, 130)         152230    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_194 (MaxPoolin (None, 4, 4, 130)         0         \n",
      "_________________________________________________________________\n",
      "flatten_64 (Flatten)         (None, 2080)              0         \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 2600)              5410600   \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 10)                26010     \n",
      "=================================================================\n",
      "Total params: 5,666,840\n",
      "Trainable params: 5,666,840\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd3916200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd3916200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "   1/1000 [..............................] - ETA: 0s - loss: 2.2999 - accuracy: 0.1000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0017s vs `on_train_batch_end` time: 0.0033s). Check your callbacks.\n",
      " 994/1000 [============================>.] - ETA: 0s - loss: 1.3552 - accuracy: 0.5110WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd3b28cb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd3b28cb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 1.3530 - accuracy: 0.5120 - val_loss: 1.0972 - val_accuracy: 0.6076\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.8964 - accuracy: 0.6842 - val_loss: 0.8500 - val_accuracy: 0.7027\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7089 - accuracy: 0.7511 - val_loss: 0.7512 - val_accuracy: 0.7415\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.5582 - accuracy: 0.8061 - val_loss: 0.7686 - val_accuracy: 0.7379\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.4195 - accuracy: 0.8526 - val_loss: 0.7734 - val_accuracy: 0.7483\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.2951 - accuracy: 0.8965 - val_loss: 0.8609 - val_accuracy: 0.7444\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.2011 - accuracy: 0.9301 - val_loss: 1.0401 - val_accuracy: 0.7291\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1398 - accuracy: 0.9515 - val_loss: 1.2308 - val_accuracy: 0.7262\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7585 - accuracy: 0.7470WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0136s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7734 - accuracy: 0.7483\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7585 - accuracy: 0.7470WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_test_batch_end` time: 0.0150s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7734 - accuracy: 0.7483\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7585 - accuracy: 0.7470WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0130s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7734 - accuracy: 0.7483\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7585 - accuracy: 0.7470WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0130s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7734 - accuracy: 0.7483\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7585 - accuracy: 0.7470WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0130s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7734 - accuracy: 0.7483\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7585 - accuracy: 0.7470WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0131s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7734 - accuracy: 0.7483\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7585 - accuracy: 0.7470WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0130s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7734 - accuracy: 0.7483\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7585 - accuracy: 0.7470WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0147s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7734 - accuracy: 0.7483\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7585 - accuracy: 0.7470WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0134s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7734 - accuracy: 0.7483\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7585 - accuracy: 0.7470WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0149s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7734 - accuracy: 0.7483\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7585 - accuracy: 0.7470WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0149s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7734 - accuracy: 0.7483\n",
      "Model: \"functional_131\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_66 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_195 (Conv2D)          (None, 32, 32, 66)        1848      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_195 (MaxPoolin (None, 16, 16, 66)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_196 (Conv2D)          (None, 16, 16, 132)       78540     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_196 (MaxPoolin (None, 8, 8, 132)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_197 (Conv2D)          (None, 8, 8, 132)         156948    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_197 (MaxPoolin (None, 4, 4, 132)         0         \n",
      "_________________________________________________________________\n",
      "flatten_65 (Flatten)         (None, 2112)              0         \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 2640)              5578320   \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 10)                26410     \n",
      "=================================================================\n",
      "Total params: 5,842,066\n",
      "Trainable params: 5,842,066\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf4387830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf4387830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "   1/1000 [..............................] - ETA: 0s - loss: 2.3004 - accuracy: 0.1200WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0015s vs `on_train_batch_end` time: 0.0037s). Check your callbacks.\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1.3527 - accuracy: 0.5080WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b240d8050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b240d8050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 1.3523 - accuracy: 0.5083 - val_loss: 0.9967 - val_accuracy: 0.6552\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.8960 - accuracy: 0.6843 - val_loss: 0.8224 - val_accuracy: 0.7109\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7124 - accuracy: 0.7500 - val_loss: 0.7569 - val_accuracy: 0.7308\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.5700 - accuracy: 0.7987 - val_loss: 0.7305 - val_accuracy: 0.7493\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.4500 - accuracy: 0.8421 - val_loss: 0.7372 - val_accuracy: 0.7615\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3249 - accuracy: 0.8867 - val_loss: 0.7718 - val_accuracy: 0.7624\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.2293 - accuracy: 0.9188 - val_loss: 0.9304 - val_accuracy: 0.7526\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1628 - accuracy: 0.9430 - val_loss: 1.0672 - val_accuracy: 0.7470\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1261 - accuracy: 0.9561 - val_loss: 1.1163 - val_accuracy: 0.7536\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7700 - accuracy: 0.7520WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_test_batch_end` time: 0.0132s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7718 - accuracy: 0.7625\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7700 - accuracy: 0.7520WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0134s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7718 - accuracy: 0.7625\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7700 - accuracy: 0.7520WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0145s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7718 - accuracy: 0.7625\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7700 - accuracy: 0.7520WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0151s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7718 - accuracy: 0.7625\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7700 - accuracy: 0.7520WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0133s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7718 - accuracy: 0.7625\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7700 - accuracy: 0.7520WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0133s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7718 - accuracy: 0.7625\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7700 - accuracy: 0.7520WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_test_batch_end` time: 0.0131s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7718 - accuracy: 0.7625\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7700 - accuracy: 0.7520WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_test_batch_end` time: 0.0133s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7718 - accuracy: 0.7625\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7700 - accuracy: 0.7520WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0132s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7718 - accuracy: 0.7625\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7700 - accuracy: 0.7520WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0146s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7718 - accuracy: 0.7625\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7700 - accuracy: 0.7520WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0149s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7718 - accuracy: 0.7625\n",
      "Model: \"functional_133\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_67 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_198 (Conv2D)          (None, 32, 32, 67)        1876      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_198 (MaxPoolin (None, 16, 16, 67)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_199 (Conv2D)          (None, 16, 16, 134)       80936     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_199 (MaxPoolin (None, 8, 8, 134)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_200 (Conv2D)          (None, 8, 8, 134)         161738    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_200 (MaxPoolin (None, 4, 4, 134)         0         \n",
      "_________________________________________________________________\n",
      "flatten_66 (Flatten)         (None, 2144)              0         \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 2680)              5748600   \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 10)                26810     \n",
      "=================================================================\n",
      "Total params: 6,019,960\n",
      "Trainable params: 6,019,960\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf5915c20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bf5915c20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "   1/1000 [..............................] - ETA: 0s - loss: 2.2981 - accuracy: 0.1400WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_train_batch_end` time: 0.0037s). Check your callbacks.\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1.3649 - accuracy: 0.5070WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf59c3d40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf59c3d40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 1.3645 - accuracy: 0.5071 - val_loss: 1.0810 - val_accuracy: 0.6202\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.9146 - accuracy: 0.6776 - val_loss: 0.8424 - val_accuracy: 0.7061\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7241 - accuracy: 0.7453 - val_loss: 0.7778 - val_accuracy: 0.7298\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.5741 - accuracy: 0.7994 - val_loss: 0.7575 - val_accuracy: 0.7461\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.4351 - accuracy: 0.8480 - val_loss: 0.8705 - val_accuracy: 0.7288\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3117 - accuracy: 0.8902 - val_loss: 0.8759 - val_accuracy: 0.7445\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.2060 - accuracy: 0.9283 - val_loss: 0.9675 - val_accuracy: 0.7505\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1449 - accuracy: 0.9494 - val_loss: 1.1640 - val_accuracy: 0.7489\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1240 - accuracy: 0.9565 - val_loss: 1.1994 - val_accuracy: 0.7485\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1039 - accuracy: 0.9643 - val_loss: 1.2123 - val_accuracy: 0.7503\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8810 - accuracy: 0.7610WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0139s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.9675 - accuracy: 0.7505\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8810 - accuracy: 0.7610WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0135s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9675 - accuracy: 0.7505\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8810 - accuracy: 0.7610WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0148s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9675 - accuracy: 0.7505\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8810 - accuracy: 0.7610WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0030s vs `on_test_batch_end` time: 0.0141s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9675 - accuracy: 0.7505\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8810 - accuracy: 0.7610WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0133s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.9675 - accuracy: 0.7505\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8810 - accuracy: 0.7610WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0148s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9675 - accuracy: 0.7505\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8810 - accuracy: 0.7610WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0145s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9675 - accuracy: 0.7505\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8810 - accuracy: 0.7610WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0030s vs `on_test_batch_end` time: 0.0173s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9675 - accuracy: 0.7505\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8810 - accuracy: 0.7610WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0149s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9675 - accuracy: 0.7505\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8810 - accuracy: 0.7610WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0154s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9675 - accuracy: 0.7505\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8810 - accuracy: 0.7610WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0134s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.9675 - accuracy: 0.7505\n",
      "Model: \"functional_135\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_68 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_201 (Conv2D)          (None, 32, 32, 68)        1904      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_201 (MaxPoolin (None, 16, 16, 68)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_202 (Conv2D)          (None, 16, 16, 136)       83368     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_202 (MaxPoolin (None, 8, 8, 136)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_203 (Conv2D)          (None, 8, 8, 136)         166600    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_203 (MaxPoolin (None, 4, 4, 136)         0         \n",
      "_________________________________________________________________\n",
      "flatten_67 (Flatten)         (None, 2176)              0         \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 2720)              5921440   \n",
      "_________________________________________________________________\n",
      "dense_135 (Dense)            (None, 10)                27210     \n",
      "=================================================================\n",
      "Total params: 6,200,522\n",
      "Trainable params: 6,200,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd3a6c7a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd3a6c7a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "   1/1000 [..............................] - ETA: 0s - loss: 2.3173 - accuracy: 0.0800WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0019s vs `on_train_batch_end` time: 0.0032s). Check your callbacks.\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1.3714 - accuracy: 0.5015WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf42e5200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf42e5200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 1.3709 - accuracy: 0.5016 - val_loss: 1.0322 - val_accuracy: 0.6350\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.9133 - accuracy: 0.6773 - val_loss: 0.8820 - val_accuracy: 0.6873\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7221 - accuracy: 0.7460 - val_loss: 0.7941 - val_accuracy: 0.7256\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.5705 - accuracy: 0.8000 - val_loss: 0.7719 - val_accuracy: 0.7453\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.4317 - accuracy: 0.8492 - val_loss: 0.7986 - val_accuracy: 0.7415\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.2958 - accuracy: 0.8972 - val_loss: 0.8400 - val_accuracy: 0.7492\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.2083 - accuracy: 0.9271 - val_loss: 1.0238 - val_accuracy: 0.7471\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1469 - accuracy: 0.9500 - val_loss: 1.1475 - val_accuracy: 0.7520\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1246 - accuracy: 0.9577 - val_loss: 1.2719 - val_accuracy: 0.7468\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1009 - accuracy: 0.9664 - val_loss: 1.3125 - val_accuracy: 0.7479\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0988 - accuracy: 0.9670 - val_loss: 1.3903 - val_accuracy: 0.7289\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0172 - accuracy: 0.7680WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_test_batch_end` time: 0.0139s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.1475 - accuracy: 0.7520\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0172 - accuracy: 0.7680WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0136s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.1475 - accuracy: 0.7520\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0172 - accuracy: 0.7680WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0135s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.1475 - accuracy: 0.7520\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0172 - accuracy: 0.7680WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0136s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.1475 - accuracy: 0.7520\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0172 - accuracy: 0.7680WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0136s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.1475 - accuracy: 0.7520\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0172 - accuracy: 0.7680WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0134s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.1475 - accuracy: 0.7520\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0172 - accuracy: 0.7680WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0029s vs `on_test_batch_end` time: 0.0137s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.1475 - accuracy: 0.7520\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0172 - accuracy: 0.7680WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0135s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.1475 - accuracy: 0.7520\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0172 - accuracy: 0.7680WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0134s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.1475 - accuracy: 0.7520\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0172 - accuracy: 0.7680WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0191s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.1475 - accuracy: 0.7520\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0172 - accuracy: 0.7680WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0031s vs `on_test_batch_end` time: 0.0164s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.1475 - accuracy: 0.7520\n",
      "Model: \"functional_137\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_69 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_204 (Conv2D)          (None, 32, 32, 69)        1932      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_204 (MaxPoolin (None, 16, 16, 69)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_205 (Conv2D)          (None, 16, 16, 138)       85836     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_205 (MaxPoolin (None, 8, 8, 138)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_206 (Conv2D)          (None, 8, 8, 138)         171534    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_206 (MaxPoolin (None, 4, 4, 138)         0         \n",
      "_________________________________________________________________\n",
      "flatten_68 (Flatten)         (None, 2208)              0         \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 2760)              6096840   \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 10)                27610     \n",
      "=================================================================\n",
      "Total params: 6,383,752\n",
      "Trainable params: 6,383,752\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd396a050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd396a050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "   1/1000 [..............................] - ETA: 0s - loss: 2.3045 - accuracy: 0.1400WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_train_batch_end` time: 0.0038s). Check your callbacks.\n",
      " 994/1000 [============================>.] - ETA: 0s - loss: 1.3680 - accuracy: 0.5041WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf46668c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf46668c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 1.3671 - accuracy: 0.5042 - val_loss: 1.0751 - val_accuracy: 0.6177\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.9180 - accuracy: 0.6763 - val_loss: 0.8968 - val_accuracy: 0.6845\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7351 - accuracy: 0.7413 - val_loss: 0.8487 - val_accuracy: 0.6973\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.5870 - accuracy: 0.7943 - val_loss: 0.7842 - val_accuracy: 0.7386\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.4539 - accuracy: 0.8402 - val_loss: 0.7796 - val_accuracy: 0.7441\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3199 - accuracy: 0.8879 - val_loss: 0.8403 - val_accuracy: 0.7531\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.2218 - accuracy: 0.9228 - val_loss: 0.9896 - val_accuracy: 0.7423\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1576 - accuracy: 0.9443 - val_loss: 1.0912 - val_accuracy: 0.7422\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1263 - accuracy: 0.9570 - val_loss: 1.2561 - val_accuracy: 0.7427\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8421 - accuracy: 0.7590WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0143s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.8403 - accuracy: 0.7531\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8421 - accuracy: 0.7590WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0136s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8403 - accuracy: 0.7531\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8421 - accuracy: 0.7590WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_test_batch_end` time: 0.0152s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8403 - accuracy: 0.7531\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8421 - accuracy: 0.7590WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0149s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8403 - accuracy: 0.7531\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8421 - accuracy: 0.7590WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0031s vs `on_test_batch_end` time: 0.0144s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8403 - accuracy: 0.7531\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8421 - accuracy: 0.7590WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0029s vs `on_test_batch_end` time: 0.0162s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8403 - accuracy: 0.7531\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8421 - accuracy: 0.7590WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0178s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8403 - accuracy: 0.7531\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8421 - accuracy: 0.7590WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0029s vs `on_test_batch_end` time: 0.0170s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8403 - accuracy: 0.7531\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8421 - accuracy: 0.7590WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0030s vs `on_test_batch_end` time: 0.0154s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8403 - accuracy: 0.7531\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8421 - accuracy: 0.7590WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0149s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8403 - accuracy: 0.7531\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8421 - accuracy: 0.7590WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0138s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8403 - accuracy: 0.7531\n",
      "Model: \"functional_139\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_70 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_207 (Conv2D)          (None, 32, 32, 70)        1960      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_207 (MaxPoolin (None, 16, 16, 70)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_208 (Conv2D)          (None, 16, 16, 140)       88340     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_208 (MaxPoolin (None, 8, 8, 140)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_209 (Conv2D)          (None, 8, 8, 140)         176540    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_209 (MaxPoolin (None, 4, 4, 140)         0         \n",
      "_________________________________________________________________\n",
      "flatten_69 (Flatten)         (None, 2240)              0         \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 2800)              6274800   \n",
      "_________________________________________________________________\n",
      "dense_139 (Dense)            (None, 10)                28010     \n",
      "=================================================================\n",
      "Total params: 6,569,650\n",
      "Trainable params: 6,569,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8b1059d290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8b1059d290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "   1/1000 [..............................] - ETA: 0s - loss: 2.2982 - accuracy: 0.1200WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0015s vs `on_train_batch_end` time: 0.0037s). Check your callbacks.\n",
      " 992/1000 [============================>.] - ETA: 0s - loss: 1.3556 - accuracy: 0.5087WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b18052f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b18052f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 1.3523 - accuracy: 0.5098 - val_loss: 1.0547 - val_accuracy: 0.6253\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.9078 - accuracy: 0.6802 - val_loss: 0.8501 - val_accuracy: 0.7044\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7188 - accuracy: 0.7479 - val_loss: 0.8209 - val_accuracy: 0.7155\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.5712 - accuracy: 0.7972 - val_loss: 0.8268 - val_accuracy: 0.7237\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.4337 - accuracy: 0.8459 - val_loss: 0.8254 - val_accuracy: 0.7381\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3084 - accuracy: 0.8914 - val_loss: 0.9020 - val_accuracy: 0.7374\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.2104 - accuracy: 0.9254 - val_loss: 0.9927 - val_accuracy: 0.7312\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1475 - accuracy: 0.9491 - val_loss: 1.0489 - val_accuracy: 0.7594\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1244 - accuracy: 0.9577 - val_loss: 1.1781 - val_accuracy: 0.7461\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0978 - accuracy: 0.9665 - val_loss: 1.2952 - val_accuracy: 0.7497\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0895 - accuracy: 0.9702 - val_loss: 1.3821 - val_accuracy: 0.7467\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9910 - accuracy: 0.7600WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0142s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.0489 - accuracy: 0.7594\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9910 - accuracy: 0.7600WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0139s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.0489 - accuracy: 0.7594\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9910 - accuracy: 0.7600WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0139s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.0489 - accuracy: 0.7594\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9910 - accuracy: 0.7600WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0031s vs `on_test_batch_end` time: 0.0154s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.0489 - accuracy: 0.7594\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9910 - accuracy: 0.7600WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0151s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.0489 - accuracy: 0.7594\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9910 - accuracy: 0.7600WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0032s vs `on_test_batch_end` time: 0.0152s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.0489 - accuracy: 0.7594\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9910 - accuracy: 0.7600WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0029s vs `on_test_batch_end` time: 0.0164s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.0489 - accuracy: 0.7594\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9910 - accuracy: 0.7600WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_test_batch_end` time: 0.0138s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.0489 - accuracy: 0.7594\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9910 - accuracy: 0.7600WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0139s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.0489 - accuracy: 0.7594\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9910 - accuracy: 0.7600WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0148s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.0489 - accuracy: 0.7594\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9910 - accuracy: 0.7600WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0155s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.0489 - accuracy: 0.7594\n",
      "Model: \"functional_141\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_71 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_210 (Conv2D)          (None, 32, 32, 71)        1988      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_210 (MaxPoolin (None, 16, 16, 71)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_211 (Conv2D)          (None, 16, 16, 142)       90880     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_211 (MaxPoolin (None, 8, 8, 142)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_212 (Conv2D)          (None, 8, 8, 142)         181618    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_212 (MaxPoolin (None, 4, 4, 142)         0         \n",
      "_________________________________________________________________\n",
      "flatten_70 (Flatten)         (None, 2272)              0         \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (None, 2840)              6455320   \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (None, 10)                28410     \n",
      "=================================================================\n",
      "Total params: 6,758,216\n",
      "Trainable params: 6,758,216\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd3bd6170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd3bd6170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "   1/1000 [..............................] - ETA: 0s - loss: 2.3140 - accuracy: 0.1000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0017s vs `on_train_batch_end` time: 0.0037s). Check your callbacks.\n",
      " 992/1000 [============================>.] - ETA: 0s - loss: 1.3673 - accuracy: 0.5052WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b240877a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b240877a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 1.3650 - accuracy: 0.5061 - val_loss: 1.0135 - val_accuracy: 0.6408\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.9094 - accuracy: 0.6788 - val_loss: 0.8534 - val_accuracy: 0.7022\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7297 - accuracy: 0.7412 - val_loss: 0.7880 - val_accuracy: 0.7284\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.5802 - accuracy: 0.7953 - val_loss: 0.7545 - val_accuracy: 0.7420\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.4505 - accuracy: 0.8414 - val_loss: 0.7799 - val_accuracy: 0.7439\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3286 - accuracy: 0.8855 - val_loss: 0.7979 - val_accuracy: 0.7581\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.2201 - accuracy: 0.9243 - val_loss: 0.8978 - val_accuracy: 0.7492\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1572 - accuracy: 0.9452 - val_loss: 1.0275 - val_accuracy: 0.7613\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1245 - accuracy: 0.9565 - val_loss: 1.1574 - val_accuracy: 0.7501\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1062 - accuracy: 0.9637 - val_loss: 1.2653 - val_accuracy: 0.7479\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0968 - accuracy: 0.9673 - val_loss: 1.2935 - val_accuracy: 0.7460\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0149 - accuracy: 0.7550WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0154s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.0275 - accuracy: 0.7613\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0149 - accuracy: 0.7550WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0147s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.0275 - accuracy: 0.7613\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0149 - accuracy: 0.7550WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0145s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.0275 - accuracy: 0.7613\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0149 - accuracy: 0.7550WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0152s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.0275 - accuracy: 0.7613\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0149 - accuracy: 0.7550WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0146s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.0275 - accuracy: 0.7613\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0149 - accuracy: 0.7550WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0149s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.0275 - accuracy: 0.7613\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0149 - accuracy: 0.7550WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0147s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.0275 - accuracy: 0.7613\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0149 - accuracy: 0.7550WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0198s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.0275 - accuracy: 0.7613\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0149 - accuracy: 0.7550WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_test_batch_end` time: 0.0145s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.0275 - accuracy: 0.7613\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0149 - accuracy: 0.7550WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0150s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.0275 - accuracy: 0.7613\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0149 - accuracy: 0.7550WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0170s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.0275 - accuracy: 0.7613\n",
      "Model: \"functional_143\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_72 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_213 (Conv2D)          (None, 32, 32, 72)        2016      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_213 (MaxPoolin (None, 16, 16, 72)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_214 (Conv2D)          (None, 16, 16, 144)       93456     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_214 (MaxPoolin (None, 8, 8, 144)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_215 (Conv2D)          (None, 8, 8, 144)         186768    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_215 (MaxPoolin (None, 4, 4, 144)         0         \n",
      "_________________________________________________________________\n",
      "flatten_71 (Flatten)         (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 2880)              6638400   \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 10)                28810     \n",
      "=================================================================\n",
      "Total params: 6,949,450\n",
      "Trainable params: 6,949,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8c0ff23f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8c0ff23f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "   1/1000 [..............................] - ETA: 0s - loss: 2.3002 - accuracy: 0.0800WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0015s vs `on_train_batch_end` time: 0.0037s). Check your callbacks.\n",
      " 994/1000 [============================>.] - ETA: 0s - loss: 1.3710 - accuracy: 0.5049WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b184838c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b184838c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 1.3691 - accuracy: 0.5057 - val_loss: 1.0658 - val_accuracy: 0.6266\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.9315 - accuracy: 0.6733 - val_loss: 0.8772 - val_accuracy: 0.6967\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7529 - accuracy: 0.7368 - val_loss: 0.7866 - val_accuracy: 0.7248\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6227 - accuracy: 0.7822 - val_loss: 0.7566 - val_accuracy: 0.7425\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.4984 - accuracy: 0.8246 - val_loss: 0.7610 - val_accuracy: 0.7497\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3821 - accuracy: 0.8657 - val_loss: 0.7812 - val_accuracy: 0.7485\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.2777 - accuracy: 0.9016 - val_loss: 0.8888 - val_accuracy: 0.7466\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1951 - accuracy: 0.9313 - val_loss: 0.9705 - val_accuracy: 0.7437\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7430 - accuracy: 0.7460WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0155s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7610 - accuracy: 0.7497\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7430 - accuracy: 0.7460WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0029s vs `on_test_batch_end` time: 0.0162s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7610 - accuracy: 0.7497\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7430 - accuracy: 0.7460WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0028s vs `on_test_batch_end` time: 0.0167s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7610 - accuracy: 0.7497\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7430 - accuracy: 0.7460WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0203s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7610 - accuracy: 0.7497\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7430 - accuracy: 0.7460WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0028s vs `on_test_batch_end` time: 0.0140s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7610 - accuracy: 0.7497\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7430 - accuracy: 0.7460WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0033s vs `on_test_batch_end` time: 0.0182s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7610 - accuracy: 0.7497\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7430 - accuracy: 0.7460WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0200s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7610 - accuracy: 0.7497\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7430 - accuracy: 0.7460WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0193s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7610 - accuracy: 0.7497\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7430 - accuracy: 0.7460WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0194s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7610 - accuracy: 0.7497\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7430 - accuracy: 0.7460WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0192s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7610 - accuracy: 0.7497\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7430 - accuracy: 0.7460WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0194s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7610 - accuracy: 0.7497\n",
      "Model: \"functional_145\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_73 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_216 (Conv2D)          (None, 32, 32, 73)        2044      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_216 (MaxPoolin (None, 16, 16, 73)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_217 (Conv2D)          (None, 16, 16, 146)       96068     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_217 (MaxPoolin (None, 8, 8, 146)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_218 (Conv2D)          (None, 8, 8, 146)         191990    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_218 (MaxPoolin (None, 4, 4, 146)         0         \n",
      "_________________________________________________________________\n",
      "flatten_72 (Flatten)         (None, 2336)              0         \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 2920)              6824040   \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (None, 10)                29210     \n",
      "=================================================================\n",
      "Total params: 7,143,352\n",
      "Trainable params: 7,143,352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8b106e6b00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8b106e6b00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "   1/1000 [..............................] - ETA: 0s - loss: 2.3067 - accuracy: 0.1200WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_train_batch_end` time: 0.0041s). Check your callbacks.\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 1.3682 - accuracy: 0.5044WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf422e170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bf422e170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 1.3675 - accuracy: 0.5048 - val_loss: 1.0609 - val_accuracy: 0.6173\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.9302 - accuracy: 0.6721 - val_loss: 0.8651 - val_accuracy: 0.6996\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7431 - accuracy: 0.7389 - val_loss: 0.7904 - val_accuracy: 0.7330\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.5960 - accuracy: 0.7903 - val_loss: 0.7971 - val_accuracy: 0.7263\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.4636 - accuracy: 0.8370 - val_loss: 0.8053 - val_accuracy: 0.7417\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3395 - accuracy: 0.8821 - val_loss: 0.8247 - val_accuracy: 0.7487\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.2245 - accuracy: 0.9213 - val_loss: 0.9191 - val_accuracy: 0.7483\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1626 - accuracy: 0.9437 - val_loss: 1.0689 - val_accuracy: 0.7447\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1290 - accuracy: 0.9556 - val_loss: 1.1425 - val_accuracy: 0.7506\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1068 - accuracy: 0.9638 - val_loss: 1.2636 - val_accuracy: 0.7425\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0927 - accuracy: 0.9687 - val_loss: 1.4028 - val_accuracy: 0.7438\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0935 - accuracy: 0.9689 - val_loss: 1.4314 - val_accuracy: 0.7440\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0853 - accuracy: 0.7570WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0165s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.1425 - accuracy: 0.7506\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0853 - accuracy: 0.7570WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0144s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.1425 - accuracy: 0.7506\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0853 - accuracy: 0.7570WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0030s vs `on_test_batch_end` time: 0.0144s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.1425 - accuracy: 0.7506\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0853 - accuracy: 0.7570WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_test_batch_end` time: 0.0144s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.1425 - accuracy: 0.7506\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0853 - accuracy: 0.7570WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0200s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.1425 - accuracy: 0.7506\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0853 - accuracy: 0.7570WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0202s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.1425 - accuracy: 0.7506\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0853 - accuracy: 0.7570WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0145s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.1425 - accuracy: 0.7506\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0853 - accuracy: 0.7570WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0028s vs `on_test_batch_end` time: 0.0177s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.1425 - accuracy: 0.7506\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0853 - accuracy: 0.7570WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0143s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.1425 - accuracy: 0.7506\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0853 - accuracy: 0.7570WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0157s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.1425 - accuracy: 0.7506\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0853 - accuracy: 0.7570WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0146s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.1425 - accuracy: 0.7506\n",
      "Model: \"functional_147\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_74 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_219 (Conv2D)          (None, 32, 32, 74)        2072      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_219 (MaxPoolin (None, 16, 16, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_220 (Conv2D)          (None, 16, 16, 148)       98716     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_220 (MaxPoolin (None, 8, 8, 148)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_221 (Conv2D)          (None, 8, 8, 148)         197284    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_221 (MaxPoolin (None, 4, 4, 148)         0         \n",
      "_________________________________________________________________\n",
      "flatten_73 (Flatten)         (None, 2368)              0         \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 2960)              7012240   \n",
      "_________________________________________________________________\n",
      "dense_147 (Dense)            (None, 10)                29610     \n",
      "=================================================================\n",
      "Total params: 7,339,922\n",
      "Trainable params: 7,339,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd46e0680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8bd46e0680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "   1/1000 [..............................] - ETA: 0s - loss: 2.3116 - accuracy: 0.0600WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_train_batch_end` time: 0.0037s). Check your callbacks.\n",
      " 996/1000 [============================>.] - ETA: 0s - loss: 1.3660 - accuracy: 0.5047WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd3b14c20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8bd3b14c20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 1.3653 - accuracy: 0.5048 - val_loss: 1.0434 - val_accuracy: 0.6311\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.9275 - accuracy: 0.6730 - val_loss: 0.8727 - val_accuracy: 0.6927\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7285 - accuracy: 0.7437 - val_loss: 0.8191 - val_accuracy: 0.7205\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.5777 - accuracy: 0.8003 - val_loss: 0.7414 - val_accuracy: 0.7473\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.4325 - accuracy: 0.8459 - val_loss: 0.7853 - val_accuracy: 0.7447\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.2993 - accuracy: 0.8939 - val_loss: 0.8861 - val_accuracy: 0.7507\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.2012 - accuracy: 0.9299 - val_loss: 0.9373 - val_accuracy: 0.7512\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1461 - accuracy: 0.9500 - val_loss: 1.1122 - val_accuracy: 0.7440\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1104 - accuracy: 0.9625 - val_loss: 1.2699 - val_accuracy: 0.7337\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1131 - accuracy: 0.9622 - val_loss: 1.3238 - val_accuracy: 0.7445\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8668 - accuracy: 0.7600WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0153s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9373 - accuracy: 0.7512\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8668 - accuracy: 0.7600WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0143s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.9373 - accuracy: 0.7512\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8668 - accuracy: 0.7600WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0145s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.9373 - accuracy: 0.7512\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8668 - accuracy: 0.7600WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_test_batch_end` time: 0.0198s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.9373 - accuracy: 0.7512\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8668 - accuracy: 0.7600WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0167s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.9373 - accuracy: 0.7512\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8668 - accuracy: 0.7600WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_test_batch_end` time: 0.0199s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.9373 - accuracy: 0.7512\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8668 - accuracy: 0.7600WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0198s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.9373 - accuracy: 0.7512\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8668 - accuracy: 0.7600WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0200s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.9373 - accuracy: 0.7512\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8668 - accuracy: 0.7600WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0198s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.9373 - accuracy: 0.7512\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8668 - accuracy: 0.7600WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0028s vs `on_test_batch_end` time: 0.0144s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.9373 - accuracy: 0.7512\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8668 - accuracy: 0.7600WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0161s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.9373 - accuracy: 0.7512\n"
     ]
    }
   ],
   "source": [
    "time_prediction = []\n",
    "scores = []\n",
    "for neuronas in range(1,75):\n",
    "    # capas de la red\n",
    "    input = Input(shape=(32,32,3))\n",
    "    layer = input\n",
    "    layer = Conv2D(filters=neuronas, kernel_size=3, strides=1, padding='same', activation='relu')(layer)\n",
    "    layer = MaxPooling2D((2, 2))(layer)\n",
    "    layer = Conv2D(filters=neuronas*2, kernel_size=3, strides=1, padding='same', activation='relu')(layer)\n",
    "    layer = MaxPooling2D((2, 2))(layer)\n",
    "    layer = Conv2D(filters=neuronas*2, kernel_size=3, strides=1, padding='same', activation='relu')(layer)\n",
    "    layer = MaxPooling2D((2, 2))(layer)\n",
    "    layer = Flatten()(layer)\n",
    "    layer = Dense(units=neuronas*40, activation='relu')(layer)\n",
    "    output = Dense(units=10, activation='softmax')(layer)\n",
    "\n",
    "    # creamos el modelo\n",
    "    model = Model(inputs=input, outputs=output)\n",
    "    print(model.summary())\n",
    "\n",
    "    # optimizador\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "    # función loss\n",
    "    loss = SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "    # métrica\n",
    "    metrics = ['accuracy']\n",
    "\n",
    "    # compilamos el modelo\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, mode='max', restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(x=X_train_cifar10, y=y_train_cifar10, batch_size=50, epochs=30,\n",
    "                        validation_data=(X_validation_cifar10, y_validation_cifar10), callbacks=[early_stopping])\n",
    "\n",
    "    t1 = time()\n",
    "    # hacemos varias predicciones para calcular los tiempos de ejecución\n",
    "    for _ in range(10):\n",
    "        model.evaluate(X_validation_cifar10, y_validation_cifar10, batch_size=1000)\n",
    "    scores.append(model.evaluate(X_validation_cifar10, y_validation_cifar10, batch_size=1000)[1])\n",
    "    time_prediction.append(time()-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA5VklEQVR4nO3dd3hUVfrA8e+bEEiAEEKHBAhVBKRIBBF7Qazo4iquvWFv67qrv911FXVX3VXR1VVRUazYVkRlVSyIUiSJ9J7QktACqaSX9/fHvYEhTJIJZJhJ8n6eZ57MPbfMOzMw7z3n3HOuqCrGGGNMVSGBDsAYY0xwsgRhjDHGK0sQxhhjvLIEYYwxxitLEMYYY7yyBGGMMcYrSxAmYERERaRvoONo6kTkWhH5uZ6OdYWIfFMfxzKBZwnCHBYROVFEFohIjohkish8ETnuCL7+XBG58Ui9Xn2pLTm6P9rlIrLXfWwUkVvrcPw3ReSx+on2oGNX+52r6ruqOtYfr2uOvGaBDsA0XCLSBvgCuBX4EGgOnAQUBzIufxCRZqpaVqUsVFXL/fiyC1X1RPe1hgPzRGSRqi7x42vWqCl958ZqEObw9AdQ1fdVtVxVC1X1G1VdXrmBiFwvImtEJEtEvhaRnt4OJCItRORfIrJVRHaKyMsiEuGxfryILBWRXBFJEZFxIvI4zo/TC+5Z9gvVHLvyjDdbRFJF5Fq3PEpE3hKRDBHZIiJ/EZEQd9217pnxsyKyB3jYPSt/SURmi0g+cJqIdBORT9xjbBKRuzxeN1RE/s+NN09EkkSku4jMczdZ5sZ9WW0ftJsU1gBHexz/IxHZ4Z7JzxORQW75JOAK4I/u8T93y7uLyH/dWPdU/bzczz/LfR/nVBNKjd+5Z3OViFS+fuWjVETe9PjsXxeR7SKSLiKPiUhobZ+DOcJU1R72OKQH0AbYA0wHzgGiq6wfDyTj/Kg1A/4CLPBYr0Bf9/mzwCygHRAJfA78w103EsgBzsI5qYkBBrjr5gI31hBjTyAPuBwIA9oDw9x1bwGfua8XB6wHbnDXXQuUAXe6sUcAb7pxjHHjaAkkAQ/hnEn3BjYCZ7vHuB9YARwFCDAUaF/1vVcT97XAzx7LxwHZQH+Psuvd2FsAU4ClHuveBB7zWA4FlrmfcysgHDjR47VKgZvc7W4FtgFyCN/5AXF7lHd3j3mOu/wp8IobSydgMXBzoP9N26PK9xboAOzRsB/uj/+bQJr7gzoL6Oyu+1/lD667HAIUAD3dZQX6uj+e+UAfj21HA5vc568Az1bz+nOpOUE8CHzqpTwUKAEGepTdDMx1n18LbK2yz5vAWx7Lo7xs8yDwhvt8HTC+mrh8SRBlblLIc7f/t7cfbXf7tu42UR6xeiaI0UAG0Kya10r2WG7pHqvLIXznByUInOSaBPzJXe6M0yQV4bHN5cAPgf73bI8DH9bEZA6Lqq5R1WtVNRYYDHTDOZsF5+z9ObdpJxvIxEkGMVUO0xH3bNxj26/ccnDOPlMOMcTq9u2AU6PY4lG2pUpsqV728yzrCXSrjNmN+/9wfgAPN26ARaraVlUjgS7AIODvsK/56gm3+SoX2OzxvrzpDmzRKv0oHnZUPlHVAvdpa28b1vKde/M6sE5Vn3SXe+J89ts9PrdXcGoSJohYgjD1RlXX4pxZDnaLUnGaDdp6PCJUdUGVXXcDhcAgj+2iVLW1x3H6VPeytYRV3b67cZpVPPtEegDptRzbsywVp5bj+f4iVfVcH+KuE1XdCXwCXOAW/Q6nCe9MIAqniQycBOwt9lSgh4jU64UpXr7zA4jIAzj9FjdUiaUY6ODxubVR1UH1GZs5fJYgzCETkQEicp+IxLrL3XGaCha5m7wMPOjReRolIr+tehxVrQBeBZ4VkU7utjEicra7yevAdSJyhoiEuOsGuOt24rT9V+dd4EwRuVREmolIexEZps7VRx8Cj4tIpNt5/nvgnTp8BIuBPBH5k4hEuGf1g2X/Zb6vAY+KSD9xDBGR9j7GfQB3v4uBVW5RJM6P7B6c2tffq+xS9fiLge3AEyLSSkTCRWRMHd5rZRy1feee254D3AVcrKqFleWquh34BnhaRNq432kfETmlrvEY/7IEYQ5HHk47/C/uVT2LgJXAfQCq+inwJDDDbQZZidOx6c2fcDq0F7nbfovTuYuqLgauw+lgzQF+ZP+Z/3PAJe7VN89XPaiqbgXOdWPKBJbidBaD0wGdj9Ox/DPwHjDN1zfvJpnzgWHAJpxayWs4Z/QAz+AkoW+AXJxEV3ll1sPAdLeJ5dJqXmJ05RVAOFcwZbgxg9PBvgWnxrOag3+gXwcGusef6cZ6AU6fz1ac/oNar57yosbvvIrLcJoJ13hcyfSyu+5qnI791UAW8DHQ9RDiMX4kqnbDIGOMMQezGoQxxhivLEEYY4zxyhKEMcYYryxBGGOM8arRTNbXoUMHjYuLC3QYxhjToCQlJe1W1Y7e1jWaBBEXF0diYmKgwzDGmAZFRLZUt86amIwxxnhlCcIYY4xXliCMMcZ4ZQnCGGOMV5YgjDHGeGUJwhhjjFeWIIwxxnhlCcIYUydJWzJZmZ4T6DDMEWAJwhjjs6z8Eq6ZlsDV0xaTW1Qa6HCMn1mCMMb47KUfU8gvKSOroIQXv0/2aZ/v1+7kkpcW8FFiKhUVdv+ZhsQShDHGJztyipi+YDMXD49hwrGxvDF/M1v3FFS7fUWF8syc9Vz/ZiJrd+Rx/8fLGf/ifBI2Zx52LGXlFWzZk3/YxzE1swRhTJDYmVvEVyt3cDh3eSwqLaekrKIeo9rv+e83UKHKvWf25/6zj6JZqPDEV2u8bptdUML10xN4/rsNXDIiloQ/n8mUy4aRkVfMb19eyB3v/UpWfskhxaGq3PfRMk5/+keSd+095PdTUlZxWJ/V3uIyJr2VyPzk3Yd8jKrKK5T07MLaNzxCGs1kfcY0ZNtzCrn0lYWkZhYyefwgrh4dV6f9i0rLmb5gM/+Zm0Jch1bMuOl4IpqH1lt8m3fn82FCKleM6kH3di0BuOWUPjwzZz2LN2Uysle7fdsmbs7k3g+XsiOniMcuGswVo3ogIlw0PIaxgzozdd5G/vNDCoUl5bx2TTwiUqdYPkpM47Ol2wB495ct/O2CQXXaP7+4jLcWbmHqvBTKKpRL47tz9eie9Gzfqk7HmfbzJr5ZvZMV6TnM+f0ptG5R959TVWX19lwWpuxhYcoeFm/KJK+4jKd/O5QJI2LrfLz6ZjUI0+gUlpTz+bJtlJb750y6vu3KK+KKV38hK7+Ukb3a8cjnq/l5g29npWXlFby/eCun/nMu//jfWo7qHMnytGz+8PGyw6qJVPXMnPWEhYZw++l995XddFJvukaF8+gXq6moUHbmFnHvB0u55OWFlJcrH9w8miuP73lAAmjZvBn3nNmfB84ZwHdrd/FBQmqd4tiwM4+HZq3khD7tOW9IVz5OSqOgpMynfQtKypg6L4WTnvqBJ79ay5DYtpx6VCemL9jMqf+ay/VvJrAwZY9Px8rML2HqvI0M6taGHblFPP3Nujq9D3CS+r0fLOW853/msS/XsHF3PucP7caQ2Cgmf7GaXXlFdT5mfbMahGl0nvtuAy//mMKEY2P512+H1PkM9VBk5pcwZ/UOxg3qSlTLsDrtd+Vrv7Ajt4i3rh/JgK5tmPCfBdz2bhKf3XEivTpUf1abU1DKxFcXsWZ7Lsf2aMtzE4cxqnd7Xv4xhSf+t5Z+nVpzz5n9D/u9rd6Wy6xl27jt1D50igzfVx7RPJQ/jjuKez9Yxp0zlvDD2l2UVSh3nNaX207rQ8vm1f+8XHtCHN+u2cmjX6zmhD4d6NG+5QHrS8srKK9QwsP214KKSsu5470ltGrejCmXDWNLZgFfLt/OrKXbmDiyR7WvtWZ7Lh8kpDJzaTrZBaWc1K8D95zZnxE9owHYed7RvPvLVt77ZSuXv7qIm0/pzR/GHkVYaPXnz//5IZmCkjKmXDaM6Qs37+ubGRLbtraPE3BOCia9lcTS1GzuPqMfl4/sQZco57NNydjLOc/9xMOzVvGfK0b4dDx/kfo8ywik+Ph4tftBmMz8Ek588nvahIexI7eISSf35v/OPfqwj1tUWk5Kxl56tm91QFNCWlYBr/20iRkJWykqrWBQtza8e+Mo2rZsXusxcwpK+d1ri0jetZc3rjuOE/p0ACA1s4ALX/iZ6FbN+fS2MURFHJxwyiuU695MYGHKbqZcNpxzj+myLxGqKn/4aDmf/JrGvy8fzgVDu1Ubw46cIt5fvJXfHBvjtYklr6iUW95JYkVaDj/98fSDkl9FhXLxSwtYlprN2IGd+ct5Aw/6sa9OenYh456dx4CukcyYNJrQECf+r1bu4K+frSS/uIyzB3XhouExjOnTnodmreK9X7by5nXHcepRnVBVznnuJ0JDhC/uPPGAEwFV5aPENN5etIUV6Tk0Dw3hrEGdue6EOOLj2nmNp6i0nMe+XM07i7ZyXFw0/7782H0/2p62ZRdy6r/mMn5oN/7526HkFpVyxtM/0imyBZ/dPoZmNSQWcBLujdMTyCoo5dnLhjJucNeDtnnxh2T++fU6Xr7yWK/r65OIJKlqvNd1/kwQIjIOeA4IBV5T1SeqrH8WOM1dbAl0UtW27rpyYIW7bquqXljTa1mCMAD/+nodL85N5pt7TubtRVt4a+EWHjhnALec0qfG/bbsyadVi2Z0aN3ioHVJWzK578NlbHav2ImNjuCozpE0bxbCN6t3EiJw0bAY4uOi+etnq+jXqXW1SUJVWZKazcdJaXyxbBtFpRVMvXoEpx7V6YDtFm3cw5Wv/cIJfTsw9aoRB5xJAzz+5Wpe/WkTT/zmGK9nz8Vl5Vzx6i+sSM/hw5tHM7R724O2Wbsjl+veSGB7ThFhocI1o+O48/R+RLUMc5quElKZMmc9e/JLeHT8IK6qpl9kV24R23KKGOblNWrz31/T+P2Hy3jgnAFMODaWh2et4ssV2xnYtQ1DYqOYvWI7uUVltGvVnMz8Em4+pTcPnrM/4b+9aAt/nbmST287geE9oveVT/t5E5O/WM2ALpFcGt+di4fHEN2q9qQN8NnSdB787wrCw0KZctkwTu5/4M3W/vTxcj5dks4P959KTNsIAL5cvp3b3/uVv5x3NDee1HvftqrKjtwiNu3OZ9PufDZm5PP+4q20CQ/jtWviGRwT5TWG0vIKxr8wn4y9xXx77yl1qpXWVUAShIiEAuuBs4A0IAG4XFVXV7P9ncBwVb3eXd6rqq19fT1LEE3Hyz+msCkjn8cvHnzA2VpOQSljnvyeU/p35MUrjqWiQrlrxhK+WL6dpyYM4dLjuu/bVlVZmZ7LV6u28/WqnSTv2ktYqHDB0G7ccGIvBnWLoqi0nGfnrOfVnzbSrW0Ed53ej4y9xazbkcf6nXns3lvMRcNiuOGkXnSNcn4o5q7bxaS3k+jb0UkS0a2ao6qs3ZHHnNU7mbkknY278wkPC+GcwV25enTPA37YPL2/eCsP/ncFPdu35LGLBnNSP+eH6pOkNO77aBnXjO7JI+MHV/s57d5bzPgX5pNVUMKNJ/XmppN6ERnu/NDMT97NLW8n0bJFKP+8ZChfLt/Oh0mpREWEcdXxPfnfyh0k79rLyF7t+Mt5R/vcdFJXqsqt7/zK92t30bJFKAXF5dx9Zj8mndybsNAQisvK+WFtBjOXpCMCz18+/ICmn73FZYx6/FvOHtyFZy4dBsCClN1c9fpizhjQiZevHEFISN2bGJN37eX2d39l3c48xg3qwh/O7k/fTpEk79rL2Gd/5NoTevHQBQMPeB83TE9k0cY9PHzBIJIz9rIiLYeV23LIK9rfR9KiWQjHxbXj6UuH0rnNwbUTTyvTcxj/4nwmHBvDU5cMpaJC2Z1fTHpWIbv3lpCZX0xmfimZ+cW0b92i1pOg6gQqQYwGHlbVs93lBwFU9R/VbL8A+JuqznGXLUE0QB8mpLItp5C7z+jnl7b/dTvyOPf5nyivUK4e3ZNHLhy073WenbOe577bwP/uPomju7YBnEsZb5iewM/Ju4n2OKMvLasgr7iM0BBhVK92jB3YmU278/koKY2CknJG9WpHVkEJ63fu5fKRPfjzeUf7fJXKj+szuOmtRPp0bM2oXu2Ys3on6dmFiMBxce245NhYzjmmy74f65osSN7Nn2euZNPufC4a1o0Lhnbj1nd/Jb5nNNOvH1ljOzk4zVVPfLWWL5dvJ7plGLef1pc24WH8eeYKenVoxZvXjaSbexa8Znsuf5+9hp827KZ3h1Y8cM4AzhrY2e99OJn5JZz//E90bRvBkxOOoW+nyDrt/9eZK/kgMZVFD55BQUkZF74wn+iWYcy8fYxPn3F1CkvKmTpvI6/+tJGCkjIuGRHLztxiEjdnMu+Pp9G+Sm0zLauAsc/Oo6CknObNQji6SySDY6IY0LUNvTu0Iq5DK7q2Ca9Twnryq7W8NDeFnu1bsj2nyOtluS2ahTCqd3veun7kIb3PQCWIS4Bxqnqju3wVMEpV7/CybU9gERCrquVuWRmwFCgDnlDVmV72mwRMAujRo8eILVuqvbWqOQJSMws44+kfKSmv4PbT+nD/2QPqfAxVZe76DIbERB30H1BVufL1X1iRlsP5Q7vx3i9beej8gVx/Yi9yi0oZ88T3nNCnPa9cdeC/9fziMl7+MYXsgv1TQ4jA4Jgozjy6M+08mh5yCkv5IGEr0xc4/5Yev3jwQc0/vvhxfQaT3nJOWE7q14GzBnbm9AGd6Rh5cBNWbYpKy/nP3BRemptMabnSo11LPrt9jM9NJgDL07L559fr+Mm9Omp07/a8fNWIg/o3VJWtmQV0axtRa/KpT2XlFbW23Vdn3Y48zp4yj3vP7M+cNTvYsruAmXeMoU9Hn88va7RnbzH/mZvC2wu3UFJewd1n9OPes7x3/ifv2ktxWTn9O0fWy+dXVFrOA58sp6xCiYmOIKZtBN2iIujcJpzoVmG0b9XisC9nbggJ4k84yeFOj7IYVU0Xkd7A98AZqppS3etZDSLwbns3iR/WZnDmwM58vmwbf7tgINeN6eXz/qrK09+s54UfkhnQJZIPbxlNG48zwG9W7WDS20n87YKBXDM6jlvfTeKb1Tt59ap41mzP5ek56/nizhOrbdetC1U97DPnvKJSmoWE1Nt4hORde3n9503ccGJcnc+yK81P3s2ytGxuPLE3zZs1nqvcL31lIYs3OSO0X7s6njMHdq7310jLKuCbVTu5fGSPeh1jEmg1JQh//gtJB7p7LMe6Zd5MBN73LFDVdPfvRmAuMLz+QzT15ZeNe5i9Yge3nNKHKZcN4+xBnXnk89XMWrbNp/1VlSe/WscLPyRz2lEdSd61l9ve+XVflbq4rJzHvlxDv06tufL4noSECFMuG84xMVHcNWMJr/60kTMGdKqX5ADUS7NKZHhYvf6Q9O3Umn/8pu5NMJ7G9O3Abaf2bVTJAZzLZgHuPbO/X5IDQGx0S64/sVejSg618ee/kgSgn4j0EpHmOElgVtWNRGQAEA0s9CiLFpEW7vMOwBjAa+e2CbyKCuXRL1fTNSqcSSf3JjREeG7icEb2asd9Hy7lpw0ZNe6vqvx99hpe/jGFK0b14PVrjuOJCUP4OXk3D/53BarKtJ83szWzgIcuGLiv6h7RPJTXro6nbUQYuUVl3HlGvyPxdk0QOveYrnz7+1O464y+tW9sfOa3gXKqWiYidwBf41zmOk1VV4nIZCBRVSuTxURghh7Y1nU08IqIVOAksSequ/rJBN4nv6axMj2X5yYO23d2FR4WyqtXx3PZKwu59Z1f+d/dJ+2bosGTqjL5i9W8MX8z14zuycNup/MlI2JJzyrk2W/X07pFKB8npXHm0Z33XclTqVObcGZMGs3KbTmHdJmlaTz6dqqfPgeznw2UM4clv7iMU/81l5i2EXx62wkHNc2kZRVwznM/0b9zJB9MOv6gjsj/zE3mqa/Wcd2YOB46f+BBg53u/3g5HyelERYqzLn3FOJqGFlsjKm7QPVBmEZuV24Rj89eQ0ZeMQ9dMNBru31stHMNf9KWLF784cBrDOas3sk/v17HhUO7HZQcwOkH+MdvjuHS+Fj+ct5ASw7GHGE2F5PxmaoyP3kP363dyfzk3azf6Uy1fFl8d46tZrAXwPhhMfywdhfPf7+BE/t1YETPaNbuyOWeGUs4JiaKpy6pfr6ksNAQnrpkqF/ejzGmZpYgjE+25xTy15kr+XbNLlo0C2Fkr3ZMODaWMX07MNAdlFaTyRcNJmFzFvd+sJR3bhjFjdMTadWiGVOvij9oGgljTHCwBGFqVFGhvPPLFp76ah1lFRX8+dyjuWp0zzr/qLcJD2PKxGFc9spCzp4yjwp1poP2NhmaMSY4WIIwXhWXlfPdml28+tNGlmzN5qR+HXj8omN8nqnTm+Pi2nHHaX15/vtknps4zK46MibIWYIwB1iams3HSal8vmw7OYWldGkTzjOXDuXi4TH1Mnjs3rP6c8XxPWudqMwYE3iWIMw+z327gWe/XU+LZiGMG9xlXx9D6CHMhlkdEbHkYEwDYQnCAM4U0s9+u56Lh8fwyPhBB8yBZIxpmixBGBam7OGB/y7nhD7teXLCkEY3T48x5tDYL0EjllNYSnZBSY03r0/elcfNbycS174VL105wpKDMWYfq0E0Iqu25ZCwKZNlaTksTc1m0+58AMJChY6tW9AxsgUdI8PpEtWCLm3C6dQmnOe/20DzZqFMu/Y4r/c+NsY0XZYgGrjS8gr+t3IH037exNLUbAA6RbZgWPe2XDIilvCwUDLyitm9t5hdecWkZRWQuCVz381zIsJCmTHpeK8T6RljmjZLEA1UYUk50xduZvqCzWzPKaJXh1Y8cuEgxg7qvO/+yDUpKi1nZ24RkeFhB9xRzRhjKlmCaIB+XJ/BX2euZGtmAWP6tuexiwZz2lGd6nSv2/CwUHq2t8nvjDHVswTRgOzKK+LRL9bw+bJt9O7QivduGsUJfToEOixjTCNlCaKBWLwpkxunJ1BUWsE9Z/bj1lP70KKZTXJnjPEfSxANQGZ+CXe+/yvtW7fgtWvi6dPR7pxljPE/u+g9yKkq93+0jKz8Ul743XBLDsaYI8avCUJExonIOhFJFpEHvKx/VkSWuo/1IpLtse4aEdngPq7xZ5zB7I35m/lu7S7+79wBDOoWFehwjDFNiN+amEQkFHgROAtIAxJEZJaqrq7cRlXv9dj+TmC4+7wd8DcgHlAgyd03y1/xBqOV6Tk88b+1nHl0Z645IS7Q4Rhjmhh/1iBGAsmqulFVS4AZwPgatr8ceN99fjYwR1Uz3aQwBxjnx1iDTm5RKXe9v4R2rZrzzxpuyWmMMf7iz07qGCDVYzkNGOVtQxHpCfQCvq9h3xg/xBg0vlm1g/cXb2VHbjE7c4vIzC8hROC9m44n2gayGWMCIFiuYpoIfKyq5XXZSUQmAZMAevTo4Y+4joi8olLu+2gZrVs0Y1C3Nhzboy1d2oQTH9eO43u3D3R4xpgmyp8JIh3o7rEc65Z5MxG4vcq+p1bZd27VnVR1KjAVID4+vvopS4PcjMWp5BWV8c4Noxhqt+E0xgQJf/ZBJAD9RKSXiDTHSQKzqm4kIgOAaGChR/HXwFgRiRaRaGCsW9bolJZXMG3+Jo7v3c6SgzEmqPgtQahqGXAHzg/7GuBDVV0lIpNF5EKPTScCM9TjpgWqmgk8ipNkEoDJblmj8/mybWzPKeLmk/sEOhRjjDmA1HQzmYYkPj5eExMTAx1Gnagq5zz3E6rw1T0n2ZVKxpgjTkSSVDXe2zobSR1AP67PYO2OPG46ubclB2NM0LEEEUBT522kS5twLhzaLdChGGPMQSxBBMiKtBwWpOzh+hPj7D7QxpigZL9MAfLKvBQiWzTj8pENd/yGMaZxswQRAKmZBcxesZ3fjepBZHhYoMMxxhivLEEEwOs/byI0RLhuTK9Ah2KMMdWyBHGEZReU8EFCKhcOjaFLVHigwzHGmGpZgjjC3lm0hcLSciad3DvQoRhjTI0sQRxBRaXlvLlgC6f078hRXSIDHY4xxtSoxsn6RCQcOB84CegGFAIrgS9VdZX/w2tcPl2Szu69xdxstQdjTANQbYIQkUdwksNc4BdgFxAO9AeecJPHfaq6/AjE2eBVVCiv/rSRwTFtGN3HpvA2xgS/mmoQi1X1b9Wse0ZEOgF2Eb+Pvlu7i40Z+Tw3cZhNq2GMaRCqTRCq+mXVMrfW0FxVc1V1F06twtRCVZk6L4WYthGcd0zXQIdjjDE+8bmTWkRuBGYCn4jIP/wWUSP0UVIaCZuzuOmkXjQLtesCjDENQ7W/VlXu2QBwpqqOU9WzgHP9G1bjsW5HHg99tpIT+rTnqtFxgQ7HGGN8VtPp7DEi8pmIDHOXl4vIayLyKmBXMPkgv7iM295NonWLMKZMHEZoiPU9GGMajpr6IB4XkS7AZHF6Vf8KRAIRduVS7VSVv8xcyabd+bxz4yg6RdqoaWNMw1LjOAggH7gH6AdMBRKBp/wcU6PwYWIqny5J594z+3NCnw6BDscYY+qspj6Ix4BPgC+A01T1QmApMFtErj4y4TVMm3fn89BnqzixbwfuOL1voMMxxphDUlMfxPmqOhY4A7gaQFVnAWOBaF8OLiLjRGSdiCSLyAPVbHOpiKwWkVUi8p5HebmILHUfs3x+R0HghR+SEYFnLh1q/Q7GmAarpiamlSIyFYgAfqwsVNUy4LnaDiwiocCLwFlAGpAgIrNUdbXHNv2AB4ExqprlDr6rVKiqw+ryZoJBamYBny5J55rRcXRqY/0OxpiGq6ZO6itF5BigVFXXHsKxRwLJqroRQERmAOOB1R7b3AS8qKpZ7ms2+IF3L/+YQqiIzdZqjGnwauqDOFFVV1SXHESkjYgMruHYMUCqx3KaW+apP9BfROaLyCIRGeexLlxEEt3yi6qJYZK7TWJGRkYNoRwZO3KK+Cgxjd/Gx9q9HowxDV5NTUwTROQp4CsgCcjAmayvL3Aa0BO4rx5evx9wKhALzBORY1Q1G+ipquki0hv4XkRWqGqK586qOhXn6iri4+P1MGM5bK/MS6FclVtO6RPoUIwx5rDV1MR0r4i0AyYAvwW64kz3vQZ4RVV/ruXY6UB3j+VYt8xTGvCLqpYCm0RkPU7CSFDVdDeOjSIyFxgOpBCkMvKKeX/xVi4eHkP3di0DHY4xxhy2GsdBqGom8Kr7qKsEoJ+I9MJJDBOB31XZZiZwOfCGiHTAaXLaKCLRQIGqFrvlYwjy8Rev/7yJkrIKbjvVag/GmMahtoFyh0xVy0TkDuBrIBSYpqqrRGQykOheMvs1MFZEVgPlwP2qukdETgBeEZEKnH6SJzyvfgo22QUlvL1wM+cP6Ubvjq0DHY4xxtQLvyUIAFWdDcyuUvaQx3MFfu8+PLdZABzjz9jq06dL0skvKee206z2YIxpPGzu6XqwIGUPPdq1ZECXNoEOxRhj6k2tCUJEWorIX91ZXBGRfiJyvv9DaxgqKpTFmzI5vne7QIdijDH1ypcaxBtAMTDaXU4HHvNbRA3M2h155BSWcnxvu8+0MaZx8SVB9FHVp4BSAFUtAGyCIdeijXsAGGUJwhjTyPiSIEpEJAJQABHpg1OjMDgJoke7lsS0jQh0KMYYU698uYrpbzijqbuLyLs4YxKu9WdQDUVFhbJ4cyZnHd050KEYY0y9qzVBqOocEfkVOB6naeluVd3t98gagHU788gusP4HY0zjVGuCEJGT3ad57t+BIoKqzvNfWA3D/v4Hu4LJGNP4+NLEdL/H83CcabyTgNP9ElEDsmjjHrq3iyA22uZeMsY0Pr40MV3guSwi3YEp/gqooagc/3CG9T8YYxqpQxlJnQYcXd+BNDTrd+WRZf0PxphGzJc+iH/jXuKKk1CGAb/6MaYGYVGK2//Qy/ofjDGNky99EIkez8uA91V1vp/iaTAWbcwkNjrC7v1gjGm0fOmDmH4kAmlIKsc/nD6gU6BDMcYYv6k2QYjICvY3LR2wCmem7iF+iyrIbdi1l8z8EmteMsY0ajXVIGzG1mpUjn+wDmpjTGNW0z2ptxzJQBqShM2ZdI0Kt/4HY0yj5sv9II4XkQQR2SsiJSJSLiK5RyK4YLU0NZvhPdoGOgxjjPErX8ZBvABcDmwAIoAbgRf9GVQw2723mLSsQoZ1bxvoUIwxxq98GiinqslAqKqWq+obwDhf9hORcSKyTkSSReSBara5VERWi8gqEXnPo/waEdngPq7x5fWOhGWp2QAM6x4d2ECMMcbPfBkHUSAizYGlIvIUsB3fmqZCcWoaZ+GMvk4QkVmqutpjm37Ag8AYVc0SkU5ueTucacbjca6kSnL3zarb26t/S1OzCQ0RjomJCnQoxhjjV77UIK5yt7sDyAe6AxN82G8kkKyqG1W1BJgBjK+yzU3Ai5U//Kq6yy0/G5ijqpnuujn4WGvxt6Wp2RzVOZKI5qGBDsUYY/zKlwQxAmfcQ66qPqKqv3ebnGoTA6R6LKe5ZZ76A/1FZL6ILBKRcXXYFxGZJCKJIpKYkZHhQ0iHp6JCWZqazTDroDbGNAG+JIgLgPUi8raInC8ivjRL+aoZ0A84Facj/FURaevrzqo6VVXjVTW+Y8eO9RiWdxt355NXVMaw2LZ+fy1jjAm0WhOEql4H9AU+wvkRTxGR13w4djpOc1SlWLfMUxowS1VLVXUTsB4nYfiy7xG3tLKD2moQxpgmwNermEqB/+H0IyQBF/mwWwLQT0R6uZ3cE4FZVbaZiVN7QEQ64DQ5bQS+BsaKSLSIRANj3bKAWpqaResWzejTsXWgQzHGGL/z5Wqkc0TkTZxxEBOA14Aute2nqmU4HdtfA2uAD1V1lYhMFpEL3c2+BvaIyGrgB+B+Vd2jqpnAozhJJgGY7JYF1NLUbIbERhEaIoEOxRhj/M6X/oSrgQ+Am1W1uC4HV9XZwOwqZQ95PFfg9+6j6r7TgGl1eT1/KiotZ+32PCad3DvQoRhjzBHhy3Tflx+JQILdqm05lFWojaA2xjQZh3LL0SZpydZsAEsQxpgmwxKEj5amZtMtKpxObcIDHYoxxhwRvnRSXyAiTT6R2AA5Y0xT48sP/2XABhF5SkQG+DugYGQzuBpjmiJfBspdCQwHUoA3RWShO8VFpN+jCxJL9/U/2Ayuxpimw9eBcrnAxzgD5boCFwO/isidfowtaCxLsxlcjTFNjy99EBeKyKfAXCAMGKmq5wBDgfv8G15wWJaWQ3+bwdUY08T4MlBuAvCsqs7zLFTVAhG5wT9hBZfNu/MZEmu1B2NM0+JLE9PDwOLKBRGJEJE4AFX9zj9hBY/yCmVbdiHd27UMdCjGGHNE+ZIgPgIqPJbL3bImYXtOIWUVSvdoSxDGmKbFlwTRzL0jHADu8+b+Cym4pGYWAtDDahDGmCbGlwSR4TH7KiIyHtjtv5CCS2pWAQDd20UEOBJjjDmyfOmkvgV4V0ReAATnVqBX+zWqIJKWWUCIQLe2liCMMU2LL7O5pgDHi0hrd3mv36MKIqlZhXSNiiAstMnPNmKMaWJ8ur+0iJwHDALCRZyb5ajqZD/GFTRSMwuIjbbagzGm6fFloNzLOPMx3YnTxPRboKef4woaWzML7BJXY0yT5Eu7yQmqejWQpaqPAKNx7h3d6BWVlrMrr9gucTXGNEm+JIgi92+BiHQDSnHmY2r00rKcS1ztCiZjTFPkS4L4XETaAv8EfgU2A+/5cnARGSci60QkWUQe8LL+WhHJEJGl7uNGj3XlHuWzfHo39azyElcbA2GMaYpq7KR2bxT0napmA5+IyBdAuKrm1HZgEQkFXgTOAtKABBGZpaqrq2z6gare4eUQhao6zIf34DdpmZVjICxBGGOanhprEKpagfMjX7lc7EtycI0EklV1ozv6egYw/pAjDYDUrEKaNwuhY+sWgQ7FGGOOOF+amL4TkQlSeX2r72JwBtVVSnPLqpogIstF5GMR6e5RHi4iiSKySEQu8vYC7o2LEkUkMSMjo47h1a7yEteQkLq+dWOMafh8SRA340zOVywiuSKSJyK59fT6nwNxqjoEmANM91jXU1Xjgd8BU0SkT9WdVXWqqsaranzHjh3rKaT9tmYW2BVMxpgmy5dbjkaqaoiqNlfVNu5yGx+OnQ541ghi3TLPY+9R1WJ38TVghMe6dPfvRpybFQ334TXrVWpmgV3BZIxpsmodSS0iJ3srr3oDIS8SgH4i0gsnMUzEqQ14Hrurqm53Fy8E1rjl0UCBqhaLSAdgDPBUbbHWp5zCUnKLyqwGYYxpsnyZauN+j+fhOJ3PScDpNe2kqmUicgfwNRAKTFPVVSIyGUhU1VnAXe5MsWVAJnCtu/vRwCsiUoFTy3nCy9VPfpVqVzAZY5o4Xybru8Bz2e1InuLLwVV1NjC7StlDHs8fBB70st8C4BhfXsNf0mwMhDGmiTuUKUrTcM7wG7XKGwVZE5MxpqnypQ/i34C6iyHAMJwR1Y1aalYBkeHNiGoZFuhQjDEmIHzpg0j0eF4GvK+q8/0UT9CwS1yNMU2dLwniY6BIVcvBmUJDRFqqaoF/Qwus1MwC+nZqHegwjDEmYHwaSQ14DgaIAL71TzjBQVVJyyq0GoQxpknzJUGEe95m1H3eqH85M/KKKS6rsEtcjTFNmi8JIl9Ejq1cEJERQKH/Qgq8ymm+bRS1MaYp86UP4h7gIxHZhnPL0S44tyBttCovcbUxEMaYpsyXgXIJIjIAOMotWqeqpf4NK7AqR1HHWh+EMaYJq7WJSURuB1qp6kpVXQm0FpHb/B9a4GzNLKBjZAvCw0IDHYoxxgSML30QN7l3lANAVbOAm/wWURBIzSqge7T1PxhjmjZfEkSo582C3FuJNvdfSIGXllVoVzAZY5o8XzqpvwI+EJFX3OWb3bJGa/feYjpF2m1GjTFNmy8J4k/AJOBWd3kO8KrfIgqwotJyikoraNuyUVeSjDGmVr7cUa5CVV9W1UtU9RJgNfBv/4cWGNkFzgVabW2SPmNME+dLDQIRGQ5cDlwKbAL+68+gAimroASAaKtBGGOauGoThIj0x0kKlwO7gQ8AUdXTjlBsAbGvBhFhNQhjTNNWUw1iLfATcL6qJgOIyL1HJKoAyil0ahB2HwhjTFNXUx/Eb4DtwA8i8qqInIEz1YbPRGSciKwTkWQRecDL+mtFJENElrqPGz3WXSMiG9zHNXV53cOR5dYgrInJGNPUVVuDUNWZwEwRaQWMx5mTqZOIvAR8qqrf1HRgd7zEi8BZOLcpTRCRWaq6usqmH6jqHVX2bQf8DYjHuZtdkrtvVl3e3KGwTmpjjHH4chVTvqq+p6oXALHAEpxLX2szEkhW1Y2qWgLMwEk0vjgbmKOqmW5SmAOM83Hfw5JdUELzZiFE2DQbxpgmzpeR1PuoapaqTlXVM3zYPAZI9VhOc8uqmiAiy0XkYxHpXpd9RWSSiCSKSGJGRoaP76Jm2QWltI0Iw2PwuDHGNEl1ShB+8DkQp6pDcGoJ0+uys5us4lU1vmPHjvUSUHZhiTUvGWMM/k0Q6UB3j+VYt2wfVd2jqsXu4mvACF/39ZesglIbRW2MMfg3QSQA/USkl4g0ByYCszw3EJGuHosXAmvc518DY0UkWkSigbFumd/luE1MxhjT1Pk0kvpQqGqZiNyB88MeCkxT1VUiMhlIVNVZwF0iciFQBmQC17r7ZorIozhJBmCyqmb6K1ZP2YUlDG0ZdSReyhhjgprfEgSAqs4GZlcpe8jj+YPAg9XsOw2Y5s/4vLwmWQWlNgbCGGMIfCd1UCkqraCkrMJGURtjDJYgDmAT9RljzH6WIDzYRH3GGLOfJQgP2TZRnzHG7GMJwkO2TdRnjDH7WILwYBP1GWPMfpYgPFgntTHG7GcJwkNOYSktmoUQbjO5GmOMJQhP2QU2UZ8xxlSyBOHBRlEbY8x+liA85BSUEmVjIIwxBrAEcYDswhKrQRhjjMsShAfnXhBWgzDGGLAEsY+qOk1MliCMMQawBLFPQUk5JeUV1sRkjDEuSxCu7EKbqM8YYzxZgnBlu6Oo7X7UxhjjsAThsnmYjDHmQJYgXJYgjDHmQH5NECIyTkTWiUiyiDxQw3YTRERFJN5djhORQhFZ6j5e9mecsP9eENZJbYwxjmb+OrCIhAIvAmcBaUCCiMxS1dVVtosE7gZ+qXKIFFUd5q/4qqqsQdhIamOMcfizBjESSFbVjapaAswAxnvZ7lHgSaDIj7HUKrughIiwUJvJ1RhjXP5MEDFAqsdymlu2j4gcC3RX1S+97N9LRJaIyI8icpK3FxCRSSKSKCKJGRkZhxWsjaI2xpgDBayTWkRCgGeA+7ys3g70UNXhwO+B90SkTdWNVHWqqsaranzHjh0PK55sm6jPGGMO4M8EkQ5091iOdcsqRQKDgbkishk4HpglIvGqWqyqewBUNQlIAfr7MVZybKI+Y4w5gD8TRALQT0R6iUhzYCIwq3KlquaoagdVjVPVOGARcKGqJopIR7eTGxHpDfQDNvoxVmtiMsaYKvx2FZOqlonIHcDXQCgwTVVXichkIFFVZ9Ww+8nAZBEpBSqAW1Q101+xgtPEZKOojTFmP78lCABVnQ3MrlL2UDXbnurx/BPgE3/GVuW17XajxhhThY2kBvJLyimrUJuozxhjPFiCYP9EfdZJbYwx+1mCwGMUtTUxGWPMPpYg2J8grAZhjDH7WYJg/0R91kltjDH7WYLAGQMBdjc5Y4zxZAkCyHE7qa0Pwhhj9rMEgVODaNk8lBbNbCZXY4ypZAkCp5PaOqiNMeZAliBwJuqzmVyNMeZAliCwifqMMcYbSxA4I6mtickYYw5kCQL3ZkFWgzDGmAM0+QShqmQXltoYCGOMqaLJJ4i9xWWUV6g1MRljTBVNPkGUVyjnD+lK/y6RgQ7FGGOCil9vGNQQtG3ZnBd+d2ygwzDGmKDT5GsQxhhjvLMEYYwxxiu/JggRGSci60QkWUQeqGG7CSKiIhLvUfagu986ETnbn3EaY4w5mN/6IEQkFHgROAtIAxJEZJaqrq6yXSRwN/CLR9lAYCIwCOgGfCsi/VW13F/xGmOMOZA/axAjgWRV3aiqJcAMYLyX7R4FngSKPMrGAzNUtVhVNwHJ7vGMMcYcIf5MEDFAqsdymlu2j4gcC3RX1S/ruq+7/yQRSRSRxIyMjPqJ2hhjDBDATmoRCQGeAe471GOo6lRVjVfV+I4dO9ZfcMYYY/w6DiId6O6xHOuWVYoEBgNzRQSgCzBLRC70YV9jjDF+JqrqnwOLNAPWA2fg/LgnAL9T1VXVbD8X+IOqJorIIOA9nH6HbsB3QL+aOqlFJAPYchghdwB2H8b+R0JDiBEszvrUEGIEi7O+Hck4e6qq1yYYv9UgVLVMRO4AvgZCgWmqukpEJgOJqjqrhn1XiciHwGqgDLi9tiuYqnuDvhKRRFWNr33LwGkIMYLFWZ8aQoxgcda3YInTr1NtqOpsYHaVsoeq2fbUKsuPA4/7LThjjDE1spHUxhhjvLIEsd/UQAfgg4YQI1ic9akhxAgWZ30Lijj91kltjDGmYbMahDHGGK8sQRhjjPGqyScIX2ecPdJEZJqI7BKRlR5l7URkjohscP9GBzjG7iLyg4isFpFVInJ3kMYZLiKLRWSZG+cjbnkvEfnF/e4/EJGguO+siISKyBIR+cJdDro4RWSziKwQkaUikuiWBdv33lZEPhaRtSKyRkRGB2GMR7mfYeUjV0TuCZY4m3SC8Jhx9hxgIHC5O5NsMHgTGFel7AHgO1XthzN4MNAJrQy4T1UHAscDt7ufX7DFWQycrqpDgWHAOBE5HmeSyGdVtS+QBdwQuBAPcDewxmM5WOM8TVWHeVyvH2zf+3PAV6o6ABiK85kGVYyqus79DIcBI4AC4FOCJU5VbbIPYDTwtcfyg8CDgY7LI544YKXH8jqgq/u8K7Au0DFWifcznOndgzZOoCXwKzAKZ6RqM2//FgIYXyzOD8LpwBeABGmcm4EOVcqC5nsHooBNuBfiBGOMXmIeC8wPpjibdA0CH2eNDSKdVXW7+3wH0DmQwXgSkThgOM59PYIuTrfZZimwC5gDpADZqlrmbhIs3/0U4I9AhbvcnuCMU4FvRCRJRCa5ZcH0vfcCMoA33Oa610SkFcEVY1UTgffd50ERZ1NPEA2WOqcWQXGNsoi0Bj4B7lHVXM91wRKnqparU42PxZnja0BgIzqYiJwP7FLVpEDH4oMTVfVYnObZ20XkZM+VQfC9NwOOBV5S1eFAPlWaaYIgxn3cfqULgY+qrgtknE09QTS0WWN3ikhXAPfvrgDHg4iE4SSHd1X1v25x0MVZSVWzgR9wmmraupNKQnB892OAC0VkM84Ntk7HaUcPtjhR1XT37y6cNvORBNf3ngakqWrlnSo/xkkYwRSjp3OAX1V1p7scFHE29QSRAPRzrxJpjlPFq3YSwSAwC7jGfX4NTpt/wIgzT/vrwBpVfcZjVbDF2VFE2rrPI3D6SdbgJIpL3M0CHqeqPqiqsaoah/Nv8XtVvYIgi1NEWolzq2DcZpuxwEqC6HtX1R1Aqogc5RadgTP5Z9DEWMXl7G9egmCJM9AdM4F+AOfiTEueAvw50PF4xPU+sB0oxTkbugGnPfo7YAPwLdAuwDGeiFP1XQ4sdR/nBmGcQ4AlbpwrgYfc8t7AYpxb2n4EtAj09+4R86nAF8EYpxvPMvexqvL/TRB+78OARPd7nwlEB1uMbpytgD1AlEdZUMRpU20YY4zxqqk3MRljjKmGJQhjjDFeWYIwxhjjlSUIY4wxXlmCMMYY45UlCNNkiIiKyNMey38QkYfd59eJyIciMktERnjZ900RSReRFu5yB3dAmzGNliUI05QUA78RkQ5e1t2gqpcCt1D9zJnlwPX1HZTHKGljgoolCNOUlOHc6/deL+ukyl9vpgD3evtBF5H7RSRBRJZ73G8iTg68n4dnjWWuiExx76Vwt4ic4U4qt0Kce4FU1lQ2i8gjIvKru26AWz5SRBa6+yyoHDEsIoPEuffFUjeWfnX8jIzZxxKEaWpeBK4Qkagq5a+LyKc4CeTJavbdCvwMXOVZKCJjgX448xENA0ZUnbyuGs3VuZfCizj3/7hMVY/BmWjuVo/tdqszMd5LwB/csrXASepMRPcQ8He3/BbgOXUmJozHGYVvzCGxqq1pUlQ1V0TeAu4CCj3KpwHTfDjEP3DmxfnSo2ys+1jiLrfGSRhbaznWB+7fo4BNqrreXZ4O3I5TYwGonAQxCfiN+zwKmO7WEBQIc8sXAn8WkVjgv6q6wYf3ZIxXVoMwTdEUnLmtWlUWiMjjIjLDfVxR3Y7uD+5S4FKPYgH+oe6dwVS1r6q+jtOk5fl/LLzK4fJ9jLfY/VvO/pO6R4EfVHUwcEHlsVX1PZxpowuB2SJyuo+vYcxBLEGYJkdVM4EP8bh1p6r+WVUnuo93aznE4+xv6gH4GrjevS8GIhIjIp2AnUAnEWnv9imcX83x1gFxItLXXb4K+LGWGKLYP+33tZWFItIb2Kiqz+PUdIbUchxjqmUJwjRVTwPermaqlaquwrltaeXyN8B7wEIRWYFz74FIVS0FJuPMxDoHp9/A2/GKgOuAj9z9K4CXawnjKeAfIrKEA5uKLwVWunfPGwy8Vec3aIzLZnM1xhjjldUgjDHGeGUJwhhjjFeWIIwxxnhlCcIYY4xXliCMMcZ4ZQnCGGOMV5YgjDHGePX/BYybBcprrwQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(time_prediction)\n",
    "plt.title('Select correct Size Model')\n",
    "plt.ylabel('Tiempo de ejecución')\n",
    "plt.xlabel('Nº Neuronas')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(scores)\n",
    "plt.title('Select correct Batch Size')\n",
    "plt.ylabel('Accuracy value (%)')\n",
    "plt.xlabel('Nº Neuronas')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Combinación de varias optimizaciones\n",
    "Vamos a probar a utilizar varias de las optimizaciones vistas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_155\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_80 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_239 (Conv2D)          (None, 32, 32, 50)        1400      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_237 (MaxPoolin (None, 16, 16, 50)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 16, 16, 50)        200       \n",
      "_________________________________________________________________\n",
      "conv2d_240 (Conv2D)          (None, 16, 16, 100)       45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_238 (MaxPoolin (None, 8, 8, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 8, 8, 100)         400       \n",
      "_________________________________________________________________\n",
      "conv2d_241 (Conv2D)          (None, 8, 8, 200)         180200    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_239 (MaxPoolin (None, 4, 4, 200)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 4, 4, 200)         800       \n",
      "_________________________________________________________________\n",
      "flatten_79 (Flatten)         (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 2000)              6402000   \n",
      "_________________________________________________________________\n",
      "dense_155 (Dense)            (None, 10)                20010     \n",
      "=================================================================\n",
      "Total params: 6,650,110\n",
      "Trainable params: 6,649,410\n",
      "Non-trainable params: 700\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8b103e74d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8b103e74d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 996/1000 [============================>.] - ETA: 0s - loss: 1.6290 - accuracy: 0.4457WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b18717830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f8b18717830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.6275 - accuracy: 0.4460 - val_loss: 1.3062 - val_accuracy: 0.5313\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 1.2068 - accuracy: 0.5729 - val_loss: 1.1754 - val_accuracy: 0.6093\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 1.0697 - accuracy: 0.6253 - val_loss: 0.9487 - val_accuracy: 0.6707\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.9857 - accuracy: 0.6571 - val_loss: 0.8272 - val_accuracy: 0.7139\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.9321 - accuracy: 0.6753 - val_loss: 0.8687 - val_accuracy: 0.7012\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.8813 - accuracy: 0.6924 - val_loss: 0.8265 - val_accuracy: 0.7141\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.8538 - accuracy: 0.7046 - val_loss: 0.8550 - val_accuracy: 0.7148\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.8167 - accuracy: 0.7170 - val_loss: 0.8931 - val_accuracy: 0.7032\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7905 - accuracy: 0.7247 - val_loss: 0.7547 - val_accuracy: 0.7426\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7628 - accuracy: 0.7340 - val_loss: 0.8053 - val_accuracy: 0.7317\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7445 - accuracy: 0.7443 - val_loss: 0.7025 - val_accuracy: 0.7622\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7222 - accuracy: 0.7500 - val_loss: 0.6624 - val_accuracy: 0.7745\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7014 - accuracy: 0.7578 - val_loss: 0.6904 - val_accuracy: 0.7646\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6846 - accuracy: 0.7640 - val_loss: 0.6966 - val_accuracy: 0.7662\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6819 - accuracy: 0.7649 - val_loss: 0.6830 - val_accuracy: 0.7684\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6596 - accuracy: 0.7730 - val_loss: 0.6758 - val_accuracy: 0.7740\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6393 - accuracy: 0.7773 - val_loss: 0.6889 - val_accuracy: 0.7721\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6345 - accuracy: 0.7809 - val_loss: 0.5620 - val_accuracy: 0.8085\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6153 - accuracy: 0.7886 - val_loss: 0.5992 - val_accuracy: 0.7987\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6075 - accuracy: 0.7892 - val_loss: 0.6136 - val_accuracy: 0.7952\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.5926 - accuracy: 0.7964 - val_loss: 0.6929 - val_accuracy: 0.7735\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.5790 - accuracy: 0.7997 - val_loss: 0.6188 - val_accuracy: 0.7952\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.5773 - accuracy: 0.7984 - val_loss: 0.5963 - val_accuracy: 0.8033\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.5611 - accuracy: 0.8048 - val_loss: 0.6440 - val_accuracy: 0.7893\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.5551 - accuracy: 0.8089 - val_loss: 0.5837 - val_accuracy: 0.8047\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.5468 - accuracy: 0.8105 - val_loss: 0.5930 - val_accuracy: 0.7988\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.5379 - accuracy: 0.8151 - val_loss: 0.6209 - val_accuracy: 0.7963\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.5339 - accuracy: 0.8163 - val_loss: 0.5843 - val_accuracy: 0.8045\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.5277 - accuracy: 0.8179 - val_loss: 0.5774 - val_accuracy: 0.8135\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.5137 - accuracy: 0.8227 - val_loss: 0.5546 - val_accuracy: 0.8109\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.5139 - accuracy: 0.8228 - val_loss: 0.5255 - val_accuracy: 0.8215\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.5090 - accuracy: 0.8230 - val_loss: 0.7038 - val_accuracy: 0.7781\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.4996 - accuracy: 0.8270 - val_loss: 0.5786 - val_accuracy: 0.8072\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.4914 - accuracy: 0.8309 - val_loss: 0.6544 - val_accuracy: 0.7841\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.4795 - accuracy: 0.8335 - val_loss: 0.6564 - val_accuracy: 0.7841\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.4819 - accuracy: 0.8330 - val_loss: 0.6015 - val_accuracy: 0.7979\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.4710 - accuracy: 0.8365 - val_loss: 0.5677 - val_accuracy: 0.8137\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.4606 - accuracy: 0.8402 - val_loss: 0.5133 - val_accuracy: 0.8305\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.4643 - accuracy: 0.8380 - val_loss: 0.5284 - val_accuracy: 0.8213\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.4508 - accuracy: 0.8454 - val_loss: 0.6069 - val_accuracy: 0.8021\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.4498 - accuracy: 0.8448 - val_loss: 0.5051 - val_accuracy: 0.8322\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.4437 - accuracy: 0.8472 - val_loss: 0.5609 - val_accuracy: 0.8147\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.4414 - accuracy: 0.8454 - val_loss: 0.5742 - val_accuracy: 0.8096\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.4322 - accuracy: 0.8486 - val_loss: 0.5295 - val_accuracy: 0.8347\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.4332 - accuracy: 0.8491 - val_loss: 0.5419 - val_accuracy: 0.8203\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.4257 - accuracy: 0.8517 - val_loss: 0.5067 - val_accuracy: 0.8394\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.4157 - accuracy: 0.8569 - val_loss: 0.5797 - val_accuracy: 0.8118\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.4202 - accuracy: 0.8548 - val_loss: 0.5451 - val_accuracy: 0.8264\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.4075 - accuracy: 0.8593 - val_loss: 0.5211 - val_accuracy: 0.8321\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.4091 - accuracy: 0.8576 - val_loss: 0.5834 - val_accuracy: 0.8118\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.4067 - accuracy: 0.8611 - val_loss: 0.5914 - val_accuracy: 0.8171\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3985 - accuracy: 0.8623 - val_loss: 0.4799 - val_accuracy: 0.8421\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3920 - accuracy: 0.8646 - val_loss: 0.6032 - val_accuracy: 0.8140\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3910 - accuracy: 0.8628 - val_loss: 0.5313 - val_accuracy: 0.8328\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3921 - accuracy: 0.8635 - val_loss: 0.5680 - val_accuracy: 0.8232\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3850 - accuracy: 0.8654 - val_loss: 0.5107 - val_accuracy: 0.8358\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3883 - accuracy: 0.8669 - val_loss: 0.5908 - val_accuracy: 0.8056\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3835 - accuracy: 0.8674 - val_loss: 0.5017 - val_accuracy: 0.8459\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.3812 - accuracy: 0.8683 - val_loss: 0.6519 - val_accuracy: 0.7942\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.3710 - accuracy: 0.8709 - val_loss: 0.5044 - val_accuracy: 0.8386\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3717 - accuracy: 0.8710 - val_loss: 0.4875 - val_accuracy: 0.8413\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3732 - accuracy: 0.8703 - val_loss: 0.6054 - val_accuracy: 0.8167\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3668 - accuracy: 0.8733 - val_loss: 0.5054 - val_accuracy: 0.8436\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3568 - accuracy: 0.8758 - val_loss: 0.5043 - val_accuracy: 0.8398\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3601 - accuracy: 0.8742 - val_loss: 0.5576 - val_accuracy: 0.8214\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3480 - accuracy: 0.8797 - val_loss: 0.5219 - val_accuracy: 0.8361\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3511 - accuracy: 0.8770 - val_loss: 0.5377 - val_accuracy: 0.8325\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3456 - accuracy: 0.8802 - val_loss: 0.5656 - val_accuracy: 0.8212\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3428 - accuracy: 0.8792 - val_loss: 0.5440 - val_accuracy: 0.8304\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3408 - accuracy: 0.8813 - val_loss: 0.5293 - val_accuracy: 0.8409\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.3435 - accuracy: 0.8818 - val_loss: 0.5214 - val_accuracy: 0.8353\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.3370 - accuracy: 0.8829 - val_loss: 0.4731 - val_accuracy: 0.8488\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.3357 - accuracy: 0.8832 - val_loss: 0.4708 - val_accuracy: 0.8519\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.3319 - accuracy: 0.8859 - val_loss: 0.5037 - val_accuracy: 0.8406\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.3364 - accuracy: 0.8831 - val_loss: 0.6106 - val_accuracy: 0.8191\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.3261 - accuracy: 0.8878 - val_loss: 0.5188 - val_accuracy: 0.8411\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3285 - accuracy: 0.8853 - val_loss: 0.6409 - val_accuracy: 0.8102\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3239 - accuracy: 0.8877 - val_loss: 0.5296 - val_accuracy: 0.8398\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3176 - accuracy: 0.8899 - val_loss: 0.5299 - val_accuracy: 0.8437\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3203 - accuracy: 0.8896 - val_loss: 0.5515 - val_accuracy: 0.8323\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3179 - accuracy: 0.8909 - val_loss: 0.5699 - val_accuracy: 0.8283\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3157 - accuracy: 0.8903 - val_loss: 0.4972 - val_accuracy: 0.8451\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3089 - accuracy: 0.8928 - val_loss: 0.5235 - val_accuracy: 0.8413\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3129 - accuracy: 0.8912 - val_loss: 0.6475 - val_accuracy: 0.8035\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3127 - accuracy: 0.8920 - val_loss: 0.6881 - val_accuracy: 0.8060\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.3078 - accuracy: 0.8939 - val_loss: 0.4965 - val_accuracy: 0.8481\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.3043 - accuracy: 0.8952 - val_loss: 0.5180 - val_accuracy: 0.8412\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.3032 - accuracy: 0.8952 - val_loss: 0.6036 - val_accuracy: 0.8248\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.2967 - accuracy: 0.8971 - val_loss: 0.5250 - val_accuracy: 0.8405\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2962 - accuracy: 0.8969 - val_loss: 0.5362 - val_accuracy: 0.8418\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2925 - accuracy: 0.8982 - val_loss: 0.5048 - val_accuracy: 0.8542\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.2971 - accuracy: 0.8984 - val_loss: 0.5769 - val_accuracy: 0.8252\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.2879 - accuracy: 0.9006 - val_loss: 0.5407 - val_accuracy: 0.8389\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.2873 - accuracy: 0.9006 - val_loss: 0.5664 - val_accuracy: 0.8382\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.2879 - accuracy: 0.9019 - val_loss: 0.5502 - val_accuracy: 0.8414\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.2844 - accuracy: 0.9011 - val_loss: 0.5188 - val_accuracy: 0.8405\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.2840 - accuracy: 0.9013 - val_loss: 0.5912 - val_accuracy: 0.8316\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.2860 - accuracy: 0.9011 - val_loss: 0.5172 - val_accuracy: 0.8437\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.2853 - accuracy: 0.8999 - val_loss: 0.5324 - val_accuracy: 0.8392\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.2809 - accuracy: 0.9010 - val_loss: 0.5095 - val_accuracy: 0.8472\n"
     ]
    }
   ],
   "source": [
    "# capas de la red\n",
    "input = Input(shape=(32,32,3))\n",
    "layer = input\n",
    "layer = Conv2D(filters=50, kernel_size=3, strides=1, padding='same', activation='relu')(layer)\n",
    "layer = MaxPooling2D((2, 2))(layer)\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = Conv2D(filters=100, kernel_size=3, strides=1, padding='same', activation='relu')(layer)\n",
    "layer = MaxPooling2D((2, 2))(layer)\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = Conv2D(filters=200, kernel_size=3, strides=1, padding='same', activation='relu')(layer)\n",
    "layer = MaxPooling2D((2, 2))(layer)\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = Flatten()(layer)\n",
    "layer = Dropout(0.5)(layer)\n",
    "layer = Dense(units=2000, activation='relu')(layer)\n",
    "output = Dense(units=10, activation='softmax')(layer)\n",
    "\n",
    "# creamos el modelo\n",
    "model = Model(inputs=input, outputs=output)\n",
    "print(model.summary())\n",
    "\n",
    "# optimizador\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# función loss\n",
    "loss = SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "# métrica\n",
    "metrics = ['accuracy']\n",
    "\n",
    "# compilamos el modelo\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "history = model.fit(train_ds, batch_size=50, epochs=100,\n",
    "                    steps_per_epoch=1000, validation_data=val_ds, validation_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos obtenido un modelo robusto, sin overfiting y con un score de 85%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Reduce LR on Plateau\n",
    "Durante los entrenamiento podemos usar otro callback llamado Reduce LR on Plateau.\n",
    "Con dicha función podemos hacer que durante el entrenamiento el LR se reduzca por un factor para hacer que el modelo converja más rápido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 32, 32, 50)        1400      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 16, 16, 50)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 16, 16, 50)        200       \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 16, 16, 100)       45100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 8, 8, 100)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 8, 8, 100)         400       \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 8, 8, 200)         180200    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 4, 4, 200)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 4, 4, 200)         800       \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 2000)              6402000   \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                20010     \n",
      "=================================================================\n",
      "Total params: 6,650,110\n",
      "Trainable params: 6,649,410\n",
      "Non-trainable params: 700\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2bba26fa70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2bba26fa70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 992/1000 [============================>.] - ETA: 0s - loss: 1.6577 - accuracy: 0.4379WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2bba223440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f2bba223440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 1.6547 - accuracy: 0.4390 - val_loss: 1.4352 - val_accuracy: 0.5070\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 1.2274 - accuracy: 0.5643 - val_loss: 1.1534 - val_accuracy: 0.6018\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.0785 - accuracy: 0.6241 - val_loss: 1.1780 - val_accuracy: 0.6100\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.9908 - accuracy: 0.6557 - val_loss: 0.9642 - val_accuracy: 0.6660\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.9349 - accuracy: 0.6724 - val_loss: 0.9284 - val_accuracy: 0.6820\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.8810 - accuracy: 0.6925 - val_loss: 0.8618 - val_accuracy: 0.7030\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.8495 - accuracy: 0.7067 - val_loss: 0.8755 - val_accuracy: 0.7000\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.8166 - accuracy: 0.7165 - val_loss: 0.7431 - val_accuracy: 0.7492\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7845 - accuracy: 0.7288 - val_loss: 0.8010 - val_accuracy: 0.7372\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7685 - accuracy: 0.7335 - val_loss: 0.7790 - val_accuracy: 0.7314\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7443 - accuracy: 0.7416 - val_loss: 0.7262 - val_accuracy: 0.7576\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7201 - accuracy: 0.7502 - val_loss: 0.7327 - val_accuracy: 0.7612\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7071 - accuracy: 0.7553 - val_loss: 0.7366 - val_accuracy: 0.7576\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6936 - accuracy: 0.7583 - val_loss: 0.7744 - val_accuracy: 0.7336\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6729 - accuracy: 0.7672 - val_loss: 0.6746 - val_accuracy: 0.7804\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6532 - accuracy: 0.7748 - val_loss: 0.6681 - val_accuracy: 0.7780\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6462 - accuracy: 0.7750 - val_loss: 0.6280 - val_accuracy: 0.7962\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6334 - accuracy: 0.7809 - val_loss: 0.6470 - val_accuracy: 0.7856\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6208 - accuracy: 0.7858 - val_loss: 0.6209 - val_accuracy: 0.7924\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6036 - accuracy: 0.7923 - val_loss: 0.6997 - val_accuracy: 0.7726\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.5962 - accuracy: 0.7940 - val_loss: 0.6894 - val_accuracy: 0.7686\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.5857 - accuracy: 0.7984 - val_loss: 0.5913 - val_accuracy: 0.8002\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.5801 - accuracy: 0.7997 - val_loss: 0.5546 - val_accuracy: 0.8180\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.5657 - accuracy: 0.8038 - val_loss: 0.5997 - val_accuracy: 0.8068\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.5570 - accuracy: 0.8068 - val_loss: 0.5803 - val_accuracy: 0.8114\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.5515 - accuracy: 0.8091 - val_loss: 0.5954 - val_accuracy: 0.8010\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.5426 - accuracy: 0.8129 - val_loss: 0.5783 - val_accuracy: 0.8136\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.5286 - accuracy: 0.8161 - val_loss: 0.5972 - val_accuracy: 0.8032\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.5236 - accuracy: 0.8185 - val_loss: 0.6272 - val_accuracy: 0.7932\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.5186 - accuracy: 0.8202 - val_loss: 0.6075 - val_accuracy: 0.8074\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.5067 - accuracy: 0.8251 - val_loss: 0.5770 - val_accuracy: 0.8068\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.4986 - accuracy: 0.8255 - val_loss: 0.5914 - val_accuracy: 0.8076\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.4881 - accuracy: 0.8298 - val_loss: 0.6577 - val_accuracy: 0.7844\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.4508 - accuracy: 0.8433 - val_loss: 0.5177 - val_accuracy: 0.8334\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.4345 - accuracy: 0.8484 - val_loss: 0.6073 - val_accuracy: 0.8078\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.4309 - accuracy: 0.8505 - val_loss: 0.5146 - val_accuracy: 0.8358\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.4100 - accuracy: 0.8562 - val_loss: 0.5748 - val_accuracy: 0.8220\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.4086 - accuracy: 0.8594 - val_loss: 0.5551 - val_accuracy: 0.8262\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.4013 - accuracy: 0.8607 - val_loss: 0.5588 - val_accuracy: 0.8234\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3982 - accuracy: 0.8608 - val_loss: 0.5613 - val_accuracy: 0.8248\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3954 - accuracy: 0.8620 - val_loss: 0.5512 - val_accuracy: 0.8288\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3883 - accuracy: 0.8655 - val_loss: 0.5618 - val_accuracy: 0.8226\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3809 - accuracy: 0.8666 - val_loss: 0.5263 - val_accuracy: 0.8404\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3786 - accuracy: 0.8677 - val_loss: 0.5411 - val_accuracy: 0.8342\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3748 - accuracy: 0.8710 - val_loss: 0.5484 - val_accuracy: 0.8288\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.3690 - accuracy: 0.8715 - val_loss: 0.5269 - val_accuracy: 0.8324\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.3643 - accuracy: 0.8728 - val_loss: 0.5595 - val_accuracy: 0.8296\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.3602 - accuracy: 0.8758 - val_loss: 0.5189 - val_accuracy: 0.8390\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.3531 - accuracy: 0.8772 - val_loss: 0.5152 - val_accuracy: 0.8380\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.3514 - accuracy: 0.8761 - val_loss: 0.5282 - val_accuracy: 0.8374\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.3502 - accuracy: 0.8787 - val_loss: 0.5012 - val_accuracy: 0.8464\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.3483 - accuracy: 0.8777 - val_loss: 0.5215 - val_accuracy: 0.8348\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3404 - accuracy: 0.8833 - val_loss: 0.5612 - val_accuracy: 0.8302\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3436 - accuracy: 0.8805 - val_loss: 0.5208 - val_accuracy: 0.8428\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.3366 - accuracy: 0.8847 - val_loss: 0.5119 - val_accuracy: 0.8432\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.3311 - accuracy: 0.8851 - val_loss: 0.5201 - val_accuracy: 0.8440\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.3296 - accuracy: 0.8855 - val_loss: 0.5035 - val_accuracy: 0.8442\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.3226 - accuracy: 0.8871 - val_loss: 0.5997 - val_accuracy: 0.8246\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.3220 - accuracy: 0.8876 - val_loss: 0.5464 - val_accuracy: 0.8364\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.3238 - accuracy: 0.8865 - val_loss: 0.5333 - val_accuracy: 0.8362\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.3127 - accuracy: 0.8913 - val_loss: 0.5675 - val_accuracy: 0.8300\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2916 - accuracy: 0.8982 - val_loss: 0.5260 - val_accuracy: 0.8488\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2843 - accuracy: 0.9003 - val_loss: 0.5319 - val_accuracy: 0.8464\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.2787 - accuracy: 0.9019 - val_loss: 0.5015 - val_accuracy: 0.8546\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2745 - accuracy: 0.9040 - val_loss: 0.5528 - val_accuracy: 0.8368\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.2734 - accuracy: 0.9041 - val_loss: 0.5227 - val_accuracy: 0.8486\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.2709 - accuracy: 0.9053 - val_loss: 0.5595 - val_accuracy: 0.8316\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2700 - accuracy: 0.9052 - val_loss: 0.5373 - val_accuracy: 0.8464\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2665 - accuracy: 0.9069 - val_loss: 0.5297 - val_accuracy: 0.8482\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2652 - accuracy: 0.9078 - val_loss: 0.5846 - val_accuracy: 0.8340\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2630 - accuracy: 0.9084 - val_loss: 0.5238 - val_accuracy: 0.8462\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2619 - accuracy: 0.9082 - val_loss: 0.5553 - val_accuracy: 0.8396\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2576 - accuracy: 0.9113 - val_loss: 0.5129 - val_accuracy: 0.8494\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.2561 - accuracy: 0.9104 - val_loss: 0.5043 - val_accuracy: 0.8522\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.2445 - accuracy: 0.9153 - val_loss: 0.5365 - val_accuracy: 0.8454\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2418 - accuracy: 0.9161 - val_loss: 0.5219 - val_accuracy: 0.8446\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2435 - accuracy: 0.9145 - val_loss: 0.5207 - val_accuracy: 0.8474\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2306 - accuracy: 0.9197 - val_loss: 0.5439 - val_accuracy: 0.8418\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2309 - accuracy: 0.9196 - val_loss: 0.5270 - val_accuracy: 0.8526\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2317 - accuracy: 0.9185 - val_loss: 0.5388 - val_accuracy: 0.8460\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2327 - accuracy: 0.9188 - val_loss: 0.5152 - val_accuracy: 0.8504\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2313 - accuracy: 0.9197 - val_loss: 0.5397 - val_accuracy: 0.8456\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2258 - accuracy: 0.9213 - val_loss: 0.5237 - val_accuracy: 0.8480\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2231 - accuracy: 0.9220 - val_loss: 0.5424 - val_accuracy: 0.8480\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2176 - accuracy: 0.9229 - val_loss: 0.5187 - val_accuracy: 0.8532\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.2246 - accuracy: 0.9218 - val_loss: 0.5261 - val_accuracy: 0.8534\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.2163 - accuracy: 0.9244 - val_loss: 0.5371 - val_accuracy: 0.8480\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2167 - accuracy: 0.9251 - val_loss: 0.5199 - val_accuracy: 0.8512\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2173 - accuracy: 0.9234 - val_loss: 0.5218 - val_accuracy: 0.8498\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2133 - accuracy: 0.9257 - val_loss: 0.5341 - val_accuracy: 0.8514\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2176 - accuracy: 0.9247 - val_loss: 0.5258 - val_accuracy: 0.8486\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2102 - accuracy: 0.9264 - val_loss: 0.5320 - val_accuracy: 0.8502\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2102 - accuracy: 0.9259 - val_loss: 0.5441 - val_accuracy: 0.8482\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2106 - accuracy: 0.9266 - val_loss: 0.5202 - val_accuracy: 0.8508\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2092 - accuracy: 0.9282 - val_loss: 0.5210 - val_accuracy: 0.8500\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2049 - accuracy: 0.9285 - val_loss: 0.5365 - val_accuracy: 0.8478\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2111 - accuracy: 0.9262 - val_loss: 0.5174 - val_accuracy: 0.8528\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2046 - accuracy: 0.9288 - val_loss: 0.5265 - val_accuracy: 0.8512\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.2083 - accuracy: 0.9268 - val_loss: 0.5262 - val_accuracy: 0.8504\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2039 - accuracy: 0.9282 - val_loss: 0.5150 - val_accuracy: 0.8556\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "# capas de la red\n",
    "input = Input(shape=(32,32,3))\n",
    "layer = input\n",
    "layer = Conv2D(filters=50, kernel_size=3, strides=1, padding='same', activation='relu')(layer)\n",
    "layer = MaxPooling2D((2, 2))(layer)\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = Conv2D(filters=100, kernel_size=3, strides=1, padding='same', activation='relu')(layer)\n",
    "layer = MaxPooling2D((2, 2))(layer)\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = Conv2D(filters=200, kernel_size=3, strides=1, padding='same', activation='relu')(layer)\n",
    "layer = MaxPooling2D((2, 2))(layer)\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = Flatten()(layer)\n",
    "layer = Dropout(0.5)(layer)\n",
    "layer = Dense(units=2000, activation='relu')(layer)\n",
    "output = Dense(units=10, activation='softmax')(layer)\n",
    "\n",
    "# creamos el modelo\n",
    "model = Model(inputs=input, outputs=output)\n",
    "print(model.summary())\n",
    "\n",
    "# optimizador\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# función loss\n",
    "loss = SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "# métrica\n",
    "metrics = ['accuracy']\n",
    "\n",
    "# compilamos el modelo\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "# Podemos decidir que score queremos monitorizar, cuantas epochs esperar después del mejor score y si queremos que nos devuelva el mejor modelo.\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=10, mode='max')\n",
    "\n",
    "history = model.fit(train_ds, batch_size=50, epochs=100,\n",
    "                    steps_per_epoch=1000, validation_data=val_ds, validation_steps=100, callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Si comparamos esta grafica con la anterior, podemos ver que el validation_accuracy es mucho mas estable usando Reduce LR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practica 3\n",
    "Usando el dataset CIFAR 100:\n",
    "- Implementar una red convolucional con las optimizaciones vistas para obtener el mejor score posible."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
